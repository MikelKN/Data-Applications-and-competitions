{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, We will predict Diabetes on Pima Indians database from https://www.kaggle.com/uciml/pima-indians-diabetes-database. We will use some machine learning algorithms to train our model, get the best model and from it, get a performance baseline using accuracy and ROC_AUC_curve. We will then use the Keras packages to build and train a Neural Network, and compare the performances\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The machine learning algorithms we will use are:\n",
    "\n",
    "1- Logistic Regression\n",
    "2- Support Vector Machine (LinearSVC and SVM with RBF kernel)\n",
    "3- Random Forest Classifier\n",
    "4- Neural nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTLINE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1- Loading and visualizing our dataset.\n",
    "2- Details about the attributes on the dataset***\n",
    "3- Performing Data analysis on the dataset\n",
    "4- Standardizing and Modelling(without k-fold cross validation) without features selection\n",
    "5- Modelling(using k-fold cross validaion) without features selection\n",
    "6- Calculate and compare the accuracies of 4 and 5 above \n",
    "7- Feature selection/extraction using correlation Matrix and Random Forest classifier\n",
    "8- Standardize the 4 most important Features(Using StandardScaler)\n",
    "9- Modelling(without k-fold cross validaion) after features selection\n",
    "10-MOdelling(using cross-validation) after Feature selection\n",
    "11- Calculate and compare the accuracies of 9 and 10 above\n",
    "12- Pick the best model \n",
    "13- Make a final prediction(using the test set) on the best model overall\n",
    "14- CONCLUSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Data Loading and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the data\n",
    "diabetes = pd.read_csv(r\"C:\\Users\\NICKEL\\OneDrive\\Data Science\\related papers to my project\\data sets + research papers on Pima Diabetes\\diabetes.csv\")\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we check to see that there are no nans or missing data. \n",
    "diabetes.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data contains no missing values. So we can safely start some data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- DATA ANALYSIS AND VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.651042\n",
       "1    0.348958\n",
       "Name: Outcome, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.Outcome.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEFCAYAAADuT+DpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABiOEACA4f4PkWRgmsqcmC4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x478682e400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'Outcome', data = diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that about 35 percent of the population in this dataset have diabetes while the remaining 65 percent do not. This means even without modelling(just declaring that no one has diabetes), we can have an accuracy of about 65 percent. Lets see if we get that accuracy after modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAK4CAYAAACYglA6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x478691c160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetes.hist(figsize = (12, 12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This above diagrams shows kweness in most of the features.We will handle that in the next section. Now Lets consider only the diabetic patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsUAAAK4CAYAAACcd4AHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4786f986a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetic_patients = diabetes[diabetes['Outcome']==1]\n",
    "diabetic_patients.hist(figsize = (12, 12));"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OBSERVATION:\n",
    "    Those with Diabestes are mostly between the ages 21 to 45 years\n",
    "    Most of them have had between 1 to 5 pregnancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 111\n",
       "Glucose                       5\n",
       "BloodPressure                35\n",
       "SkinThickness               227\n",
       "Insulin                     374\n",
       "BMI                          11\n",
       "DiabetesPedigreeFunction      0\n",
       "Age                           0\n",
       "Outcome                     500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We find the number of zeros per column in the dataset\n",
    "count_zeros = (diabetes == 0).astype(int).sum(axis =0)\n",
    "count_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command show that we have zeros in pregnancies, Glucose, Bloodpressure, skin thickness, insulin and BMi. Come to think of it, it does not make a lot of sense for someone to have a glucose level of zero or a BMI of zero. So I presume theses zero values, except for pregnancy, are values that were not keyed in. So i will replace them with the mean.(Except pregancies of course) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0      148             72             35        0  33.6   \n",
       "1       85             66             29        0  26.6   \n",
       "2      183             64              0        0  23.3   \n",
       "3       89             66             23       94  28.1   \n",
       "4      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_no_pregnancy = diabetes.drop(['Pregnancies'], axis = 1)\n",
    "diabetes_no_pregnancy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_columns = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "for i in impute_columns:\n",
    "    diabetes.loc[(diabetes[i]==0, i)] = diabetes[i].mean()\n",
    "\n",
    "#we will use the sklearn function imputer\n",
    "# from sklearn.preprocessing import Imputer\n",
    "\n",
    "# imputer = Imputer(missing_values = 0, strategy = \"mean\")\n",
    "\n",
    "# diabetes = imputer.fit_transform(diabetes_no_pregnancy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 111\n",
       "Glucose                       0\n",
       "BloodPressure                 0\n",
       "SkinThickness                 0\n",
       "Insulin                       0\n",
       "BMI                           0\n",
       "DiabetesPedigreeFunction      0\n",
       "Age                           0\n",
       "Outcome                     500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any_zeros = (diabetes == 0).astype(int).sum(axis =0)\n",
    "any_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>121.681605</td>\n",
       "      <td>72.254807</td>\n",
       "      <td>26.606479</td>\n",
       "      <td>118.660163</td>\n",
       "      <td>32.450805</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>30.436016</td>\n",
       "      <td>12.115932</td>\n",
       "      <td>9.631241</td>\n",
       "      <td>93.080358</td>\n",
       "      <td>6.875374</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.750000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  121.681605      72.254807      26.606479  118.660163   \n",
       "std       3.369578   30.436016      12.115932       9.631241   93.080358   \n",
       "min       0.000000   44.000000      24.000000       7.000000   14.000000   \n",
       "25%       1.000000   99.750000      64.000000      20.536458   79.799479   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   79.799479   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    32.450805                  0.471876   33.240885    0.348958  \n",
       "std      6.875374                  0.331329   11.760232    0.476951  \n",
       "min     18.200000                  0.078000   21.000000    0.000000  \n",
       "25%     27.500000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we take a look at our original data set\n",
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive modelling 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We split the data into train, validation and test set.\n",
    "#We use the StratifiedShuffleSplit from Sklearn to maintain the same ratio of predictors classes\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "feature_cols = diabetes.columns[:-1]\n",
    "# Get the split indexes\n",
    "strat_shuf_split = StratifiedShuffleSplit(n_splits=1, \n",
    "                                          test_size=0.3, \n",
    "                                          random_state=42)\n",
    "\n",
    "train_idx, test_idx = next(strat_shuf_split.split(diabetes[feature_cols], diabetes.Outcome))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframes\n",
    "X_train_1 = diabetes.loc[train_idx, feature_cols]\n",
    "y_train = diabetes.loc[train_idx, 'Outcome']\n",
    "\n",
    "X_test_1  = diabetes.loc[test_idx, feature_cols]\n",
    "y_test  = diabetes.loc[test_idx, 'Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First lets standardize the data except the Outcome column\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = StandardScaler().fit_transform(X_train_1)\n",
    "X_test = StandardScaler().fit_transform(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 8)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 8)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.651769\n",
       "1    0.348231\n",
       "Name: Outcome, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comparing the ratios of classes in both splits. Very representative of the whole data set\n",
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.649351\n",
       "1    0.350649\n",
       "Name: Outcome, dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a 65 percent non-diabetic data representation and a 35 percent diabetic data representation justlike the whole data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, roc_auc_score, roc_curve\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define our plot roc_auc_curve\n",
    "\n",
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlabel = 'False positive Rate', ylabel = 'True positive rate',\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define a plot_multiple_roc to visualise all the model curves together\n",
    "\n",
    "def plot_multiple_roc(y_preds, y_test, model_names):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    \n",
    "    for i in range (0, len(y_preds)):\n",
    "        false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, y_preds[i])\n",
    "        label = \"\"\n",
    "        if len(model_names) > i:\n",
    "            label = model_names[i]\n",
    "        ax.plot(false_positive_rate, true_positive_rate, label=label)\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    ax.set(title='ROC Curves for PIMA diabetes problem',\n",
    "           xlabel = 'False positive Rate', ylabel = 'True positive rate')\n",
    "        \n",
    "    if len(model_names) > 0:\n",
    "        plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not have a enough data to creat a validation set so we will use k fold cross validation to pick the best model\n",
    "cv_results = []\n",
    "\n",
    "labels = ['log_reg', 'linear_svc', 'svc_rbf', 'Random_forest']\n",
    "\n",
    "models = [LogisticRegression(), LinearSVC(), SVC(kernel = 'rbf'), \n",
    "            RandomForestClassifier(n_estimators = 200)]\n",
    "\n",
    "kf = KFold(n_splits=10, random_state = 42)\n",
    "\n",
    "for i in models:\n",
    "    result_cv = cross_val_score(i, X_train, y_train, cv= kf, scoring = 'accuracy')\n",
    "   \n",
    "    cv_results.append(result_cv.mean()* 100)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Models with their corresponding cross validation means\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cross validation means b4 feat_sels(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log_reg</th>\n",
       "      <td>77.638015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_svc</th>\n",
       "      <td>77.456324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_rbf</th>\n",
       "      <td>75.974843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_forest</th>\n",
       "      <td>75.433263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cross validation means b4 feat_sels(%)\n",
       "log_reg                                     77.638015\n",
       "linear_svc                                  77.456324\n",
       "svc_rbf                                     75.974843\n",
       "Random_forest                               75.433263"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_df = pd.Series(cv_results, index = labels).sort_values(ascending=False).to_frame()\n",
    "cross_val_df.rename(columns = {0: 'cross validation means b4 feat_sels(%)'}, inplace = True)\n",
    "print('\\nModels with their corresponding cross validation means')\n",
    "cross_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_probs = []\n",
    "models_names = ['log_reg', 'linear_svc', 'svc_rbf', 'Random_forest']\n",
    "\n",
    "for i in [LogisticRegression(),RandomForestClassifier(n_estimators = 200)]:\n",
    "    i.fit(X_train, y_train)\n",
    "    validation_probabilities = i.predict_proba(X_test)\n",
    "    validation_probs.append(validation_probabilities[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in [LinearSVC(), SVC(kernel = 'rbf')]:\n",
    "    j.fit(X_train, y_train)\n",
    "    svc_probabilities = j.decision_function(X_test)\n",
    "    validation_probs.append(svc_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preliminaries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a single layered neural network\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(15, input_shape = (8,),activation = 'relu'))\n",
    "#nn_model.add(Dropout(0.1))\n",
    "nn_model.add(Dense(1, activation ='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 15)                135       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat a training and validation set from the training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_nn, x_val, y_train_nn, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 429 samples, validate on 108 samples\n",
      "Epoch 1/900\n",
      "429/429 [==============================] - 7s 16ms/step - loss: 0.8629 - acc: 0.4988 - val_loss: 0.8366 - val_acc: 0.5185\n",
      "Epoch 2/900\n",
      "429/429 [==============================] - 0s 118us/step - loss: 0.8449 - acc: 0.5221 - val_loss: 0.8214 - val_acc: 0.5370\n",
      "Epoch 3/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.8278 - acc: 0.5385 - val_loss: 0.8074 - val_acc: 0.5370\n",
      "Epoch 4/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.8120 - acc: 0.5594 - val_loss: 0.7941 - val_acc: 0.5648\n",
      "Epoch 5/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.7967 - acc: 0.5781 - val_loss: 0.7817 - val_acc: 0.5833\n",
      "Epoch 6/900\n",
      "429/429 [==============================] - 0s 77us/step - loss: 0.7825 - acc: 0.5991 - val_loss: 0.7701 - val_acc: 0.5926\n",
      "Epoch 7/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.7301 - acc: 0.593 - 0s 98us/step - loss: 0.7693 - acc: 0.6154 - val_loss: 0.7595 - val_acc: 0.6019\n",
      "Epoch 8/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.7573 - acc: 0.6317 - val_loss: 0.7492 - val_acc: 0.6296\n",
      "Epoch 9/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.7454 - acc: 0.6457 - val_loss: 0.7397 - val_acc: 0.6296\n",
      "Epoch 10/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.7342 - acc: 0.6597 - val_loss: 0.7308 - val_acc: 0.6111\n",
      "Epoch 11/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.7237 - acc: 0.6620 - val_loss: 0.7223 - val_acc: 0.6111\n",
      "Epoch 12/900\n",
      "429/429 [==============================] - 0s 77us/step - loss: 0.7137 - acc: 0.6690 - val_loss: 0.7144 - val_acc: 0.6111\n",
      "Epoch 13/900\n",
      "429/429 [==============================] - 0s 430us/step - loss: 0.7045 - acc: 0.6737 - val_loss: 0.7069 - val_acc: 0.6111\n",
      "Epoch 14/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.6957 - acc: 0.6760 - val_loss: 0.6999 - val_acc: 0.6111\n",
      "Epoch 15/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.6874 - acc: 0.6783 - val_loss: 0.6932 - val_acc: 0.6296\n",
      "Epoch 16/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.6793 - acc: 0.6783 - val_loss: 0.6870 - val_acc: 0.6481\n",
      "Epoch 17/900\n",
      "429/429 [==============================] - 0s 70us/step - loss: 0.6718 - acc: 0.6783 - val_loss: 0.6813 - val_acc: 0.6481\n",
      "Epoch 18/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.6649 - acc: 0.6783 - val_loss: 0.6758 - val_acc: 0.6481\n",
      "Epoch 19/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.6582 - acc: 0.6783 - val_loss: 0.6706 - val_acc: 0.6481\n",
      "Epoch 20/900\n",
      "429/429 [==============================] - 0s 72us/step - loss: 0.6519 - acc: 0.6783 - val_loss: 0.6655 - val_acc: 0.6574\n",
      "Epoch 21/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.6458 - acc: 0.6807 - val_loss: 0.6606 - val_acc: 0.6574\n",
      "Epoch 22/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.6401 - acc: 0.6807 - val_loss: 0.6560 - val_acc: 0.6574\n",
      "Epoch 23/900\n",
      "429/429 [==============================] - 0s 77us/step - loss: 0.6343 - acc: 0.6830 - val_loss: 0.6516 - val_acc: 0.6574\n",
      "Epoch 24/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.6291 - acc: 0.6807 - val_loss: 0.6474 - val_acc: 0.6667\n",
      "Epoch 25/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.6240 - acc: 0.6807 - val_loss: 0.6433 - val_acc: 0.6574\n",
      "Epoch 26/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.6192 - acc: 0.6807 - val_loss: 0.6397 - val_acc: 0.6574\n",
      "Epoch 27/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.6148 - acc: 0.6853 - val_loss: 0.6365 - val_acc: 0.6574\n",
      "Epoch 28/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.6107 - acc: 0.6853 - val_loss: 0.6333 - val_acc: 0.6574\n",
      "Epoch 29/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.6066 - acc: 0.6853 - val_loss: 0.6302 - val_acc: 0.6481\n",
      "Epoch 30/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.6026 - acc: 0.6853 - val_loss: 0.6271 - val_acc: 0.6481\n",
      "Epoch 31/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.5987 - acc: 0.6830 - val_loss: 0.6243 - val_acc: 0.6574\n",
      "Epoch 32/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.5950 - acc: 0.6807 - val_loss: 0.6215 - val_acc: 0.6574\n",
      "Epoch 33/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.5914 - acc: 0.6830 - val_loss: 0.6188 - val_acc: 0.6574\n",
      "Epoch 34/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.5880 - acc: 0.6830 - val_loss: 0.6163 - val_acc: 0.6667\n",
      "Epoch 35/900\n",
      "429/429 [==============================] - 0s 114us/step - loss: 0.5847 - acc: 0.6830 - val_loss: 0.6138 - val_acc: 0.6667\n",
      "Epoch 36/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.5815 - acc: 0.6876 - val_loss: 0.6113 - val_acc: 0.6667\n",
      "Epoch 37/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.5784 - acc: 0.6830 - val_loss: 0.6089 - val_acc: 0.6667\n",
      "Epoch 38/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.5755 - acc: 0.6853 - val_loss: 0.6066 - val_acc: 0.6667\n",
      "Epoch 39/900\n",
      "429/429 [==============================] - 0s 77us/step - loss: 0.5726 - acc: 0.6876 - val_loss: 0.6044 - val_acc: 0.6759\n",
      "Epoch 40/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.5699 - acc: 0.6876 - val_loss: 0.6023 - val_acc: 0.6759\n",
      "Epoch 41/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.5672 - acc: 0.6876 - val_loss: 0.6002 - val_acc: 0.6759\n",
      "Epoch 42/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.5645 - acc: 0.6853 - val_loss: 0.5982 - val_acc: 0.6759\n",
      "Epoch 43/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.5620 - acc: 0.6853 - val_loss: 0.5963 - val_acc: 0.6759\n",
      "Epoch 44/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.5595 - acc: 0.6853 - val_loss: 0.5944 - val_acc: 0.6759\n",
      "Epoch 45/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.5571 - acc: 0.6876 - val_loss: 0.5928 - val_acc: 0.6759\n",
      "Epoch 46/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.5550 - acc: 0.6876 - val_loss: 0.5913 - val_acc: 0.6759\n",
      "Epoch 47/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.5528 - acc: 0.6853 - val_loss: 0.5897 - val_acc: 0.6759\n",
      "Epoch 48/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.5507 - acc: 0.6900 - val_loss: 0.5882 - val_acc: 0.6759\n",
      "Epoch 49/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.5487 - acc: 0.6900 - val_loss: 0.5867 - val_acc: 0.6759\n",
      "Epoch 50/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.5851 - acc: 0.718 - 0s 135us/step - loss: 0.5466 - acc: 0.6876 - val_loss: 0.5853 - val_acc: 0.6759\n",
      "Epoch 51/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.5447 - acc: 0.6923 - val_loss: 0.5840 - val_acc: 0.6759\n",
      "Epoch 52/900\n",
      "429/429 [==============================] - 0s 240us/step - loss: 0.5428 - acc: 0.6923 - val_loss: 0.5827 - val_acc: 0.6759\n",
      "Epoch 53/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.5410 - acc: 0.6946 - val_loss: 0.5815 - val_acc: 0.6759\n",
      "Epoch 54/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.5393 - acc: 0.6993 - val_loss: 0.5803 - val_acc: 0.6759\n",
      "Epoch 55/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.5375 - acc: 0.6970 - val_loss: 0.5791 - val_acc: 0.6759\n",
      "Epoch 56/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.5358 - acc: 0.6993 - val_loss: 0.5779 - val_acc: 0.6759\n",
      "Epoch 57/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.5341 - acc: 0.7016 - val_loss: 0.5768 - val_acc: 0.6759\n",
      "Epoch 58/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.5325 - acc: 0.7063 - val_loss: 0.5757 - val_acc: 0.6759\n",
      "Epoch 59/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.5309 - acc: 0.7063 - val_loss: 0.5748 - val_acc: 0.6759\n",
      "Epoch 60/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.5295 - acc: 0.7063 - val_loss: 0.5738 - val_acc: 0.6759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.5762 - acc: 0.656 - 0s 106us/step - loss: 0.5280 - acc: 0.7110 - val_loss: 0.5729 - val_acc: 0.6759\n",
      "Epoch 62/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.5266 - acc: 0.7110 - val_loss: 0.5719 - val_acc: 0.6759\n",
      "Epoch 63/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.5252 - acc: 0.7110 - val_loss: 0.5710 - val_acc: 0.6759\n",
      "Epoch 64/900\n",
      "429/429 [==============================] - 0s 111us/step - loss: 0.5238 - acc: 0.7156 - val_loss: 0.5702 - val_acc: 0.6759\n",
      "Epoch 65/900\n",
      "429/429 [==============================] - 0s 113us/step - loss: 0.5224 - acc: 0.7203 - val_loss: 0.5695 - val_acc: 0.6759\n",
      "Epoch 66/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.5211 - acc: 0.7203 - val_loss: 0.5688 - val_acc: 0.6759\n",
      "Epoch 67/900\n",
      "429/429 [==============================] - 0s 117us/step - loss: 0.5198 - acc: 0.7203 - val_loss: 0.5681 - val_acc: 0.6759\n",
      "Epoch 68/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.5186 - acc: 0.7226 - val_loss: 0.5674 - val_acc: 0.6759\n",
      "Epoch 69/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.5173 - acc: 0.7249 - val_loss: 0.5666 - val_acc: 0.6759\n",
      "Epoch 70/900\n",
      "429/429 [==============================] - 0s 99us/step - loss: 0.5161 - acc: 0.7249 - val_loss: 0.5660 - val_acc: 0.6759\n",
      "Epoch 71/900\n",
      "429/429 [==============================] - 0s 90us/step - loss: 0.5149 - acc: 0.7249 - val_loss: 0.5654 - val_acc: 0.6852\n",
      "Epoch 72/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.5138 - acc: 0.7203 - val_loss: 0.5647 - val_acc: 0.7037\n",
      "Epoch 73/900\n",
      "429/429 [==============================] - 0s 99us/step - loss: 0.5126 - acc: 0.7226 - val_loss: 0.5640 - val_acc: 0.7037\n",
      "Epoch 74/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.5115 - acc: 0.7249 - val_loss: 0.5634 - val_acc: 0.7037\n",
      "Epoch 75/900\n",
      "429/429 [==============================] - 0s 117us/step - loss: 0.5104 - acc: 0.7249 - val_loss: 0.5628 - val_acc: 0.7130\n",
      "Epoch 76/900\n",
      "429/429 [==============================] - 0s 117us/step - loss: 0.5093 - acc: 0.7273 - val_loss: 0.5622 - val_acc: 0.7130\n",
      "Epoch 77/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.5083 - acc: 0.7296 - val_loss: 0.5616 - val_acc: 0.7130\n",
      "Epoch 78/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.5073 - acc: 0.7273 - val_loss: 0.5611 - val_acc: 0.7130\n",
      "Epoch 79/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.5062 - acc: 0.7249 - val_loss: 0.5606 - val_acc: 0.7130\n",
      "Epoch 80/900\n",
      "429/429 [==============================] - 0s 117us/step - loss: 0.5053 - acc: 0.7296 - val_loss: 0.5600 - val_acc: 0.7222\n",
      "Epoch 81/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.5043 - acc: 0.7249 - val_loss: 0.5594 - val_acc: 0.7222\n",
      "Epoch 82/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.5033 - acc: 0.7249 - val_loss: 0.5589 - val_acc: 0.7222\n",
      "Epoch 83/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.5024 - acc: 0.7226 - val_loss: 0.5584 - val_acc: 0.7222\n",
      "Epoch 84/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.5014 - acc: 0.7249 - val_loss: 0.5580 - val_acc: 0.7315\n",
      "Epoch 85/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.5006 - acc: 0.7226 - val_loss: 0.5575 - val_acc: 0.7315\n",
      "Epoch 86/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4998 - acc: 0.7226 - val_loss: 0.5571 - val_acc: 0.7315\n",
      "Epoch 87/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4989 - acc: 0.7203 - val_loss: 0.5568 - val_acc: 0.7315\n",
      "Epoch 88/900\n",
      "429/429 [==============================] - 0s 102us/step - loss: 0.4981 - acc: 0.7203 - val_loss: 0.5563 - val_acc: 0.7315\n",
      "Epoch 89/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4972 - acc: 0.7203 - val_loss: 0.5558 - val_acc: 0.7407\n",
      "Epoch 90/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4964 - acc: 0.7203 - val_loss: 0.5555 - val_acc: 0.7407\n",
      "Epoch 91/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4956 - acc: 0.7249 - val_loss: 0.5552 - val_acc: 0.7407\n",
      "Epoch 92/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4948 - acc: 0.7226 - val_loss: 0.5548 - val_acc: 0.7315\n",
      "Epoch 93/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4940 - acc: 0.7249 - val_loss: 0.5545 - val_acc: 0.7315\n",
      "Epoch 94/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4932 - acc: 0.7273 - val_loss: 0.5541 - val_acc: 0.7315\n",
      "Epoch 95/900\n",
      "429/429 [==============================] - 0s 99us/step - loss: 0.4924 - acc: 0.7273 - val_loss: 0.5538 - val_acc: 0.7315\n",
      "Epoch 96/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4917 - acc: 0.7226 - val_loss: 0.5535 - val_acc: 0.7315\n",
      "Epoch 97/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4909 - acc: 0.7273 - val_loss: 0.5531 - val_acc: 0.7315\n",
      "Epoch 98/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4902 - acc: 0.7343 - val_loss: 0.5528 - val_acc: 0.7315\n",
      "Epoch 99/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4895 - acc: 0.7389 - val_loss: 0.5524 - val_acc: 0.7315\n",
      "Epoch 100/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4887 - acc: 0.7436 - val_loss: 0.5521 - val_acc: 0.7315\n",
      "Epoch 101/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4880 - acc: 0.7459 - val_loss: 0.5518 - val_acc: 0.7407\n",
      "Epoch 102/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4873 - acc: 0.7459 - val_loss: 0.5516 - val_acc: 0.7407\n",
      "Epoch 103/900\n",
      "429/429 [==============================] - 0s 94us/step - loss: 0.4866 - acc: 0.7483 - val_loss: 0.5512 - val_acc: 0.7407\n",
      "Epoch 104/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4860 - acc: 0.7459 - val_loss: 0.5509 - val_acc: 0.7407\n",
      "Epoch 105/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4853 - acc: 0.7459 - val_loss: 0.5507 - val_acc: 0.7407\n",
      "Epoch 106/900\n",
      "429/429 [==============================] - 0s 99us/step - loss: 0.4846 - acc: 0.7483 - val_loss: 0.5504 - val_acc: 0.7407\n",
      "Epoch 107/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4840 - acc: 0.7459 - val_loss: 0.5501 - val_acc: 0.7407\n",
      "Epoch 108/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4834 - acc: 0.7506 - val_loss: 0.5497 - val_acc: 0.7500\n",
      "Epoch 109/900\n",
      "429/429 [==============================] - 0s 111us/step - loss: 0.4828 - acc: 0.7506 - val_loss: 0.5495 - val_acc: 0.7407\n",
      "Epoch 110/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.4821 - acc: 0.7529 - val_loss: 0.5492 - val_acc: 0.7407\n",
      "Epoch 111/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.5191 - acc: 0.750 - 0s 110us/step - loss: 0.4816 - acc: 0.7506 - val_loss: 0.5490 - val_acc: 0.7407\n",
      "Epoch 112/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4810 - acc: 0.7506 - val_loss: 0.5488 - val_acc: 0.7315\n",
      "Epoch 113/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.4507 - acc: 0.718 - 0s 108us/step - loss: 0.4805 - acc: 0.7483 - val_loss: 0.5486 - val_acc: 0.7315\n",
      "Epoch 114/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4799 - acc: 0.7506 - val_loss: 0.5484 - val_acc: 0.7315\n",
      "Epoch 115/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4794 - acc: 0.7506 - val_loss: 0.5482 - val_acc: 0.7315\n",
      "Epoch 116/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4788 - acc: 0.7506 - val_loss: 0.5481 - val_acc: 0.7315\n",
      "Epoch 117/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4783 - acc: 0.7506 - val_loss: 0.5479 - val_acc: 0.7315\n",
      "Epoch 118/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4778 - acc: 0.7483 - val_loss: 0.5477 - val_acc: 0.7315\n",
      "Epoch 119/900\n",
      "429/429 [==============================] - 0s 159us/step - loss: 0.4772 - acc: 0.7483 - val_loss: 0.5475 - val_acc: 0.7315\n",
      "Epoch 120/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.4767 - acc: 0.7483 - val_loss: 0.5473 - val_acc: 0.7315\n",
      "Epoch 121/900\n",
      "429/429 [==============================] - 0s 92us/step - loss: 0.4761 - acc: 0.7459 - val_loss: 0.5471 - val_acc: 0.7315\n",
      "Epoch 122/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4755 - acc: 0.7483 - val_loss: 0.5469 - val_acc: 0.7315\n",
      "Epoch 123/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4750 - acc: 0.7483 - val_loss: 0.5468 - val_acc: 0.7315\n",
      "Epoch 124/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4745 - acc: 0.7506 - val_loss: 0.5467 - val_acc: 0.7315\n",
      "Epoch 125/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4741 - acc: 0.7483 - val_loss: 0.5464 - val_acc: 0.7315\n",
      "Epoch 126/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.4736 - acc: 0.7552 - val_loss: 0.5462 - val_acc: 0.7315\n",
      "Epoch 127/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4731 - acc: 0.7552 - val_loss: 0.5461 - val_acc: 0.7315\n",
      "Epoch 128/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4726 - acc: 0.7552 - val_loss: 0.5459 - val_acc: 0.7315\n",
      "Epoch 129/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4721 - acc: 0.7552 - val_loss: 0.5457 - val_acc: 0.7315\n",
      "Epoch 130/900\n",
      "429/429 [==============================] - 0s 140us/step - loss: 0.4716 - acc: 0.7599 - val_loss: 0.5456 - val_acc: 0.7315\n",
      "Epoch 131/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.4712 - acc: 0.7576 - val_loss: 0.5454 - val_acc: 0.7315\n",
      "Epoch 132/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.4707 - acc: 0.7622 - val_loss: 0.5451 - val_acc: 0.7315\n",
      "Epoch 133/900\n",
      "429/429 [==============================] - 0s 108us/step - loss: 0.4702 - acc: 0.7622 - val_loss: 0.5450 - val_acc: 0.7315\n",
      "Epoch 134/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4698 - acc: 0.7622 - val_loss: 0.5448 - val_acc: 0.7315\n",
      "Epoch 135/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4693 - acc: 0.7622 - val_loss: 0.5448 - val_acc: 0.7407\n",
      "Epoch 136/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.4689 - acc: 0.7622 - val_loss: 0.5447 - val_acc: 0.7407\n",
      "Epoch 137/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4684 - acc: 0.7622 - val_loss: 0.5446 - val_acc: 0.7407\n",
      "Epoch 138/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4679 - acc: 0.7622 - val_loss: 0.5445 - val_acc: 0.7500\n",
      "Epoch 139/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4675 - acc: 0.7646 - val_loss: 0.5444 - val_acc: 0.7500\n",
      "Epoch 140/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4671 - acc: 0.7646 - val_loss: 0.5443 - val_acc: 0.7500\n",
      "Epoch 141/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.4667 - acc: 0.7646 - val_loss: 0.5441 - val_acc: 0.7500\n",
      "Epoch 142/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.3391 - acc: 0.843 - 0s 112us/step - loss: 0.4662 - acc: 0.7646 - val_loss: 0.5441 - val_acc: 0.7500\n",
      "Epoch 143/900\n",
      "429/429 [==============================] - 0s 121us/step - loss: 0.4658 - acc: 0.7646 - val_loss: 0.5439 - val_acc: 0.7500\n",
      "Epoch 144/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4654 - acc: 0.7646 - val_loss: 0.5438 - val_acc: 0.7500\n",
      "Epoch 145/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4650 - acc: 0.7669 - val_loss: 0.5437 - val_acc: 0.7500\n",
      "Epoch 146/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4645 - acc: 0.7669 - val_loss: 0.5436 - val_acc: 0.7500\n",
      "Epoch 147/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4641 - acc: 0.7669 - val_loss: 0.5436 - val_acc: 0.7593\n",
      "Epoch 148/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4638 - acc: 0.7669 - val_loss: 0.5434 - val_acc: 0.7593\n",
      "Epoch 149/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4633 - acc: 0.7669 - val_loss: 0.5433 - val_acc: 0.7593\n",
      "Epoch 150/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4629 - acc: 0.7669 - val_loss: 0.5432 - val_acc: 0.7593\n",
      "Epoch 151/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4625 - acc: 0.7692 - val_loss: 0.5431 - val_acc: 0.7593\n",
      "Epoch 152/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4621 - acc: 0.7669 - val_loss: 0.5430 - val_acc: 0.7593\n",
      "Epoch 153/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4617 - acc: 0.7646 - val_loss: 0.5429 - val_acc: 0.7593\n",
      "Epoch 154/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4614 - acc: 0.7669 - val_loss: 0.5428 - val_acc: 0.7593\n",
      "Epoch 155/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4610 - acc: 0.7669 - val_loss: 0.5427 - val_acc: 0.7593\n",
      "Epoch 156/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4607 - acc: 0.7669 - val_loss: 0.5427 - val_acc: 0.7593\n",
      "Epoch 157/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4603 - acc: 0.7669 - val_loss: 0.5426 - val_acc: 0.7593\n",
      "Epoch 158/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4599 - acc: 0.7646 - val_loss: 0.5425 - val_acc: 0.7593\n",
      "Epoch 159/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4596 - acc: 0.7646 - val_loss: 0.5424 - val_acc: 0.7593\n",
      "Epoch 160/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4592 - acc: 0.7622 - val_loss: 0.5423 - val_acc: 0.7593\n",
      "Epoch 161/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4589 - acc: 0.7646 - val_loss: 0.5422 - val_acc: 0.7593\n",
      "Epoch 162/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4586 - acc: 0.7646 - val_loss: 0.5421 - val_acc: 0.7593\n",
      "Epoch 163/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4582 - acc: 0.7622 - val_loss: 0.5421 - val_acc: 0.7593\n",
      "Epoch 164/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4579 - acc: 0.7622 - val_loss: 0.5420 - val_acc: 0.7593\n",
      "Epoch 165/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4575 - acc: 0.7622 - val_loss: 0.5419 - val_acc: 0.7593\n",
      "Epoch 166/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4572 - acc: 0.7622 - val_loss: 0.5417 - val_acc: 0.7593\n",
      "Epoch 167/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4568 - acc: 0.7669 - val_loss: 0.5416 - val_acc: 0.7593\n",
      "Epoch 168/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4565 - acc: 0.7669 - val_loss: 0.5415 - val_acc: 0.7593\n",
      "Epoch 169/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4562 - acc: 0.7646 - val_loss: 0.5414 - val_acc: 0.7593\n",
      "Epoch 170/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4559 - acc: 0.7669 - val_loss: 0.5412 - val_acc: 0.7593\n",
      "Epoch 171/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4556 - acc: 0.7669 - val_loss: 0.5411 - val_acc: 0.7593\n",
      "Epoch 172/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4553 - acc: 0.7669 - val_loss: 0.5410 - val_acc: 0.7593\n",
      "Epoch 173/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4549 - acc: 0.7669 - val_loss: 0.5410 - val_acc: 0.7593\n",
      "Epoch 174/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4546 - acc: 0.7669 - val_loss: 0.5410 - val_acc: 0.7593\n",
      "Epoch 175/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4544 - acc: 0.7669 - val_loss: 0.5407 - val_acc: 0.7593\n",
      "Epoch 176/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4541 - acc: 0.7646 - val_loss: 0.5407 - val_acc: 0.7685\n",
      "Epoch 177/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4538 - acc: 0.7646 - val_loss: 0.5407 - val_acc: 0.7685\n",
      "Epoch 178/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4535 - acc: 0.7646 - val_loss: 0.5407 - val_acc: 0.7685\n",
      "Epoch 179/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4532 - acc: 0.7646 - val_loss: 0.5406 - val_acc: 0.7685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4529 - acc: 0.7622 - val_loss: 0.5405 - val_acc: 0.7685\n",
      "Epoch 181/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4526 - acc: 0.7622 - val_loss: 0.5405 - val_acc: 0.7685\n",
      "Epoch 182/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4523 - acc: 0.7622 - val_loss: 0.5404 - val_acc: 0.7685\n",
      "Epoch 183/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4521 - acc: 0.7646 - val_loss: 0.5402 - val_acc: 0.7685\n",
      "Epoch 184/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4518 - acc: 0.7669 - val_loss: 0.5402 - val_acc: 0.7685\n",
      "Epoch 185/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.4516 - acc: 0.7669 - val_loss: 0.5401 - val_acc: 0.7685\n",
      "Epoch 186/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4513 - acc: 0.7669 - val_loss: 0.5401 - val_acc: 0.7685\n",
      "Epoch 187/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4510 - acc: 0.7669 - val_loss: 0.5400 - val_acc: 0.7685\n",
      "Epoch 188/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4507 - acc: 0.7692 - val_loss: 0.5399 - val_acc: 0.7685\n",
      "Epoch 189/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4505 - acc: 0.7692 - val_loss: 0.5398 - val_acc: 0.7685\n",
      "Epoch 190/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4502 - acc: 0.7692 - val_loss: 0.5398 - val_acc: 0.7685\n",
      "Epoch 191/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4500 - acc: 0.7692 - val_loss: 0.5397 - val_acc: 0.7685\n",
      "Epoch 192/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4497 - acc: 0.7692 - val_loss: 0.5396 - val_acc: 0.7685\n",
      "Epoch 193/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4494 - acc: 0.7692 - val_loss: 0.5395 - val_acc: 0.7685\n",
      "Epoch 194/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4492 - acc: 0.7716 - val_loss: 0.5394 - val_acc: 0.7685\n",
      "Epoch 195/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4489 - acc: 0.7716 - val_loss: 0.5393 - val_acc: 0.7685\n",
      "Epoch 196/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4487 - acc: 0.7716 - val_loss: 0.5391 - val_acc: 0.7685\n",
      "Epoch 197/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4484 - acc: 0.7716 - val_loss: 0.5391 - val_acc: 0.7685\n",
      "Epoch 198/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4481 - acc: 0.7716 - val_loss: 0.5390 - val_acc: 0.7685\n",
      "Epoch 199/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4479 - acc: 0.7716 - val_loss: 0.5389 - val_acc: 0.7685\n",
      "Epoch 200/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4476 - acc: 0.7716 - val_loss: 0.5389 - val_acc: 0.7685\n",
      "Epoch 201/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4474 - acc: 0.7739 - val_loss: 0.5387 - val_acc: 0.7685\n",
      "Epoch 202/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4472 - acc: 0.7739 - val_loss: 0.5386 - val_acc: 0.7685\n",
      "Epoch 203/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4469 - acc: 0.7716 - val_loss: 0.5386 - val_acc: 0.7685\n",
      "Epoch 204/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4467 - acc: 0.7739 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 205/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4465 - acc: 0.7739 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 206/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4462 - acc: 0.7739 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 207/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4460 - acc: 0.7739 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 208/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4457 - acc: 0.7739 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 209/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4455 - acc: 0.7739 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 210/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4453 - acc: 0.7739 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 211/900\n",
      "429/429 [==============================] - 0s 131us/step - loss: 0.4450 - acc: 0.7739 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 212/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4449 - acc: 0.7739 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 213/900\n",
      "429/429 [==============================] - 0s 108us/step - loss: 0.4446 - acc: 0.7739 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 214/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4444 - acc: 0.7739 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 215/900\n",
      "429/429 [==============================] - 0s 111us/step - loss: 0.4442 - acc: 0.7739 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 216/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4439 - acc: 0.7739 - val_loss: 0.5378 - val_acc: 0.7778\n",
      "Epoch 217/900\n",
      "429/429 [==============================] - 0s 113us/step - loss: 0.4437 - acc: 0.7739 - val_loss: 0.5379 - val_acc: 0.7778\n",
      "Epoch 218/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4434 - acc: 0.7739 - val_loss: 0.5379 - val_acc: 0.7778\n",
      "Epoch 219/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4433 - acc: 0.7739 - val_loss: 0.5380 - val_acc: 0.7778\n",
      "Epoch 220/900\n",
      "429/429 [==============================] - 0s 108us/step - loss: 0.4431 - acc: 0.7739 - val_loss: 0.5380 - val_acc: 0.7778\n",
      "Epoch 221/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4429 - acc: 0.7739 - val_loss: 0.5379 - val_acc: 0.7778\n",
      "Epoch 222/900\n",
      "429/429 [==============================] - 0s 113us/step - loss: 0.4426 - acc: 0.7739 - val_loss: 0.5379 - val_acc: 0.7778\n",
      "Epoch 223/900\n",
      "429/429 [==============================] - 0s 120us/step - loss: 0.4424 - acc: 0.7739 - val_loss: 0.5378 - val_acc: 0.7778\n",
      "Epoch 224/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4422 - acc: 0.7739 - val_loss: 0.5378 - val_acc: 0.7778\n",
      "Epoch 225/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4420 - acc: 0.7739 - val_loss: 0.5375 - val_acc: 0.7778\n",
      "Epoch 226/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4418 - acc: 0.7739 - val_loss: 0.5374 - val_acc: 0.7778\n",
      "Epoch 227/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4416 - acc: 0.7762 - val_loss: 0.5373 - val_acc: 0.7778\n",
      "Epoch 228/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4414 - acc: 0.7762 - val_loss: 0.5371 - val_acc: 0.7778\n",
      "Epoch 229/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4412 - acc: 0.7762 - val_loss: 0.5370 - val_acc: 0.7778\n",
      "Epoch 230/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4410 - acc: 0.7786 - val_loss: 0.5371 - val_acc: 0.7778\n",
      "Epoch 231/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4407 - acc: 0.7786 - val_loss: 0.5369 - val_acc: 0.7778\n",
      "Epoch 232/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4405 - acc: 0.7786 - val_loss: 0.5369 - val_acc: 0.7778\n",
      "Epoch 233/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4404 - acc: 0.7786 - val_loss: 0.5368 - val_acc: 0.7778\n",
      "Epoch 234/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4402 - acc: 0.7786 - val_loss: 0.5368 - val_acc: 0.7778\n",
      "Epoch 235/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4400 - acc: 0.7786 - val_loss: 0.5368 - val_acc: 0.7778\n",
      "Epoch 236/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4397 - acc: 0.7786 - val_loss: 0.5367 - val_acc: 0.7778\n",
      "Epoch 237/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4396 - acc: 0.7786 - val_loss: 0.5366 - val_acc: 0.7778\n",
      "Epoch 238/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4394 - acc: 0.7786 - val_loss: 0.5365 - val_acc: 0.7778\n",
      "Epoch 239/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4392 - acc: 0.7786 - val_loss: 0.5364 - val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4390 - acc: 0.7786 - val_loss: 0.5364 - val_acc: 0.7778\n",
      "Epoch 241/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.4388 - acc: 0.7786 - val_loss: 0.5364 - val_acc: 0.7778\n",
      "Epoch 242/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.4386 - acc: 0.7786 - val_loss: 0.5363 - val_acc: 0.7778\n",
      "Epoch 243/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4384 - acc: 0.7786 - val_loss: 0.5362 - val_acc: 0.7778\n",
      "Epoch 244/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4383 - acc: 0.7786 - val_loss: 0.5361 - val_acc: 0.7778\n",
      "Epoch 245/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4381 - acc: 0.7786 - val_loss: 0.5362 - val_acc: 0.7778\n",
      "Epoch 246/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4379 - acc: 0.7786 - val_loss: 0.5361 - val_acc: 0.7778\n",
      "Epoch 247/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4377 - acc: 0.7786 - val_loss: 0.5360 - val_acc: 0.7778\n",
      "Epoch 248/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4375 - acc: 0.7786 - val_loss: 0.5361 - val_acc: 0.7778\n",
      "Epoch 249/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4374 - acc: 0.7786 - val_loss: 0.5360 - val_acc: 0.7778\n",
      "Epoch 250/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4371 - acc: 0.7786 - val_loss: 0.5359 - val_acc: 0.7778\n",
      "Epoch 251/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4370 - acc: 0.7786 - val_loss: 0.5358 - val_acc: 0.7778\n",
      "Epoch 252/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4368 - acc: 0.7786 - val_loss: 0.5358 - val_acc: 0.7778\n",
      "Epoch 253/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4366 - acc: 0.7786 - val_loss: 0.5358 - val_acc: 0.7778\n",
      "Epoch 254/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4365 - acc: 0.7786 - val_loss: 0.5358 - val_acc: 0.7778\n",
      "Epoch 255/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4363 - acc: 0.7786 - val_loss: 0.5357 - val_acc: 0.7778\n",
      "Epoch 256/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4361 - acc: 0.7786 - val_loss: 0.5355 - val_acc: 0.7778\n",
      "Epoch 257/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4360 - acc: 0.7786 - val_loss: 0.5355 - val_acc: 0.7778\n",
      "Epoch 258/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4358 - acc: 0.7786 - val_loss: 0.5355 - val_acc: 0.7778\n",
      "Epoch 259/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4357 - acc: 0.7786 - val_loss: 0.5355 - val_acc: 0.7778\n",
      "Epoch 260/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4354 - acc: 0.7786 - val_loss: 0.5355 - val_acc: 0.7778\n",
      "Epoch 261/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4353 - acc: 0.7786 - val_loss: 0.5354 - val_acc: 0.7778\n",
      "Epoch 262/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4351 - acc: 0.7786 - val_loss: 0.5353 - val_acc: 0.7778\n",
      "Epoch 263/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4350 - acc: 0.7786 - val_loss: 0.5353 - val_acc: 0.7778\n",
      "Epoch 264/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4349 - acc: 0.7786 - val_loss: 0.5354 - val_acc: 0.7778\n",
      "Epoch 265/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4346 - acc: 0.7809 - val_loss: 0.5353 - val_acc: 0.7778\n",
      "Epoch 266/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4345 - acc: 0.7809 - val_loss: 0.5351 - val_acc: 0.7778\n",
      "Epoch 267/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.4343 - acc: 0.7786 - val_loss: 0.5351 - val_acc: 0.7778\n",
      "Epoch 268/900\n",
      "429/429 [==============================] - 0s 124us/step - loss: 0.4342 - acc: 0.7809 - val_loss: 0.5350 - val_acc: 0.7778\n",
      "Epoch 269/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.4378 - acc: 0.750 - 0s 96us/step - loss: 0.4340 - acc: 0.7809 - val_loss: 0.5350 - val_acc: 0.7778\n",
      "Epoch 270/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4339 - acc: 0.7786 - val_loss: 0.5350 - val_acc: 0.7778\n",
      "Epoch 271/900\n",
      "429/429 [==============================] - 0s 180us/step - loss: 0.4337 - acc: 0.7786 - val_loss: 0.5349 - val_acc: 0.7778\n",
      "Epoch 272/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4335 - acc: 0.7786 - val_loss: 0.5349 - val_acc: 0.7778\n",
      "Epoch 273/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4334 - acc: 0.7786 - val_loss: 0.5348 - val_acc: 0.7778\n",
      "Epoch 274/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.4333 - acc: 0.7786 - val_loss: 0.5348 - val_acc: 0.7778\n",
      "Epoch 275/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4331 - acc: 0.7809 - val_loss: 0.5348 - val_acc: 0.7778\n",
      "Epoch 276/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4329 - acc: 0.7809 - val_loss: 0.5347 - val_acc: 0.7778\n",
      "Epoch 277/900\n",
      "429/429 [==============================] - 0s 94us/step - loss: 0.4328 - acc: 0.7809 - val_loss: 0.5344 - val_acc: 0.7778\n",
      "Epoch 278/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4326 - acc: 0.7809 - val_loss: 0.5344 - val_acc: 0.7778\n",
      "Epoch 279/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4325 - acc: 0.7809 - val_loss: 0.5344 - val_acc: 0.7778\n",
      "Epoch 280/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4323 - acc: 0.7809 - val_loss: 0.5344 - val_acc: 0.7778\n",
      "Epoch 281/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4322 - acc: 0.7809 - val_loss: 0.5344 - val_acc: 0.7778\n",
      "Epoch 282/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4321 - acc: 0.7809 - val_loss: 0.5343 - val_acc: 0.7778\n",
      "Epoch 283/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4319 - acc: 0.7809 - val_loss: 0.5343 - val_acc: 0.7870\n",
      "Epoch 284/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4317 - acc: 0.7832 - val_loss: 0.5341 - val_acc: 0.7778\n",
      "Epoch 285/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4316 - acc: 0.7809 - val_loss: 0.5340 - val_acc: 0.7778\n",
      "Epoch 286/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4315 - acc: 0.7832 - val_loss: 0.5340 - val_acc: 0.7778\n",
      "Epoch 287/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4313 - acc: 0.7832 - val_loss: 0.5339 - val_acc: 0.7778\n",
      "Epoch 288/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4312 - acc: 0.7855 - val_loss: 0.5338 - val_acc: 0.7870\n",
      "Epoch 289/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4311 - acc: 0.7855 - val_loss: 0.5339 - val_acc: 0.7778\n",
      "Epoch 290/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4309 - acc: 0.7855 - val_loss: 0.5339 - val_acc: 0.7870\n",
      "Epoch 291/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4308 - acc: 0.7855 - val_loss: 0.5339 - val_acc: 0.7870\n",
      "Epoch 292/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4306 - acc: 0.7855 - val_loss: 0.5340 - val_acc: 0.7870\n",
      "Epoch 293/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4305 - acc: 0.7832 - val_loss: 0.5340 - val_acc: 0.7870\n",
      "Epoch 294/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4304 - acc: 0.7855 - val_loss: 0.5339 - val_acc: 0.7870\n",
      "Epoch 295/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4302 - acc: 0.7855 - val_loss: 0.5338 - val_acc: 0.7870\n",
      "Epoch 296/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4301 - acc: 0.7855 - val_loss: 0.5337 - val_acc: 0.7870\n",
      "Epoch 297/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4300 - acc: 0.7855 - val_loss: 0.5337 - val_acc: 0.7870\n",
      "Epoch 298/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4298 - acc: 0.7879 - val_loss: 0.5336 - val_acc: 0.7870\n",
      "Epoch 299/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4296 - acc: 0.7855 - val_loss: 0.5336 - val_acc: 0.7870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4296 - acc: 0.7855 - val_loss: 0.5336 - val_acc: 0.7870\n",
      "Epoch 301/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4294 - acc: 0.7879 - val_loss: 0.5335 - val_acc: 0.7778\n",
      "Epoch 302/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4292 - acc: 0.7855 - val_loss: 0.5335 - val_acc: 0.7870\n",
      "Epoch 303/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4291 - acc: 0.7855 - val_loss: 0.5335 - val_acc: 0.7870\n",
      "Epoch 304/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4290 - acc: 0.7855 - val_loss: 0.5334 - val_acc: 0.7870\n",
      "Epoch 305/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4289 - acc: 0.7855 - val_loss: 0.5334 - val_acc: 0.7778\n",
      "Epoch 306/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4287 - acc: 0.7879 - val_loss: 0.5333 - val_acc: 0.7685\n",
      "Epoch 307/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4286 - acc: 0.7879 - val_loss: 0.5333 - val_acc: 0.7778\n",
      "Epoch 308/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4284 - acc: 0.7879 - val_loss: 0.5333 - val_acc: 0.7778\n",
      "Epoch 309/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4283 - acc: 0.7879 - val_loss: 0.5333 - val_acc: 0.7778\n",
      "Epoch 310/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4282 - acc: 0.7879 - val_loss: 0.5333 - val_acc: 0.7778\n",
      "Epoch 311/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4281 - acc: 0.7879 - val_loss: 0.5333 - val_acc: 0.7778\n",
      "Epoch 312/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4280 - acc: 0.7879 - val_loss: 0.5333 - val_acc: 0.7778\n",
      "Epoch 313/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4278 - acc: 0.7879 - val_loss: 0.5333 - val_acc: 0.7778\n",
      "Epoch 314/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4277 - acc: 0.7879 - val_loss: 0.5332 - val_acc: 0.7870\n",
      "Epoch 315/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4276 - acc: 0.7879 - val_loss: 0.5332 - val_acc: 0.7870\n",
      "Epoch 316/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4274 - acc: 0.7902 - val_loss: 0.5332 - val_acc: 0.7870\n",
      "Epoch 317/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4273 - acc: 0.7902 - val_loss: 0.5333 - val_acc: 0.7870\n",
      "Epoch 318/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.4272 - acc: 0.7902 - val_loss: 0.5334 - val_acc: 0.7870\n",
      "Epoch 319/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4271 - acc: 0.7902 - val_loss: 0.5333 - val_acc: 0.7870\n",
      "Epoch 320/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4270 - acc: 0.7902 - val_loss: 0.5334 - val_acc: 0.7870\n",
      "Epoch 321/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4269 - acc: 0.7902 - val_loss: 0.5334 - val_acc: 0.7870\n",
      "Epoch 322/900\n",
      "429/429 [==============================] - 0s 92us/step - loss: 0.4267 - acc: 0.7902 - val_loss: 0.5333 - val_acc: 0.7870\n",
      "Epoch 323/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4267 - acc: 0.7902 - val_loss: 0.5333 - val_acc: 0.7870\n",
      "Epoch 324/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4265 - acc: 0.7925 - val_loss: 0.5332 - val_acc: 0.7870\n",
      "Epoch 325/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4264 - acc: 0.7925 - val_loss: 0.5331 - val_acc: 0.7870\n",
      "Epoch 326/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4264 - acc: 0.7949 - val_loss: 0.5332 - val_acc: 0.7870\n",
      "Epoch 327/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4262 - acc: 0.7949 - val_loss: 0.5333 - val_acc: 0.7870\n",
      "Epoch 328/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4260 - acc: 0.7949 - val_loss: 0.5332 - val_acc: 0.7870\n",
      "Epoch 329/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4260 - acc: 0.7949 - val_loss: 0.5332 - val_acc: 0.7870\n",
      "Epoch 330/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4259 - acc: 0.7949 - val_loss: 0.5332 - val_acc: 0.7870\n",
      "Epoch 331/900\n",
      "429/429 [==============================] - 0s 119us/step - loss: 0.4257 - acc: 0.7972 - val_loss: 0.5333 - val_acc: 0.7870\n",
      "Epoch 332/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4256 - acc: 0.7972 - val_loss: 0.5333 - val_acc: 0.7870\n",
      "Epoch 333/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4255 - acc: 0.7949 - val_loss: 0.5332 - val_acc: 0.7870\n",
      "Epoch 334/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4254 - acc: 0.7972 - val_loss: 0.5331 - val_acc: 0.7778\n",
      "Epoch 335/900\n",
      "429/429 [==============================] - 0s 113us/step - loss: 0.4253 - acc: 0.7972 - val_loss: 0.5332 - val_acc: 0.7778\n",
      "Epoch 336/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4252 - acc: 0.7972 - val_loss: 0.5332 - val_acc: 0.7778\n",
      "Epoch 337/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4250 - acc: 0.7972 - val_loss: 0.5332 - val_acc: 0.7778\n",
      "Epoch 338/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4249 - acc: 0.7972 - val_loss: 0.5332 - val_acc: 0.7778\n",
      "Epoch 339/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4248 - acc: 0.7995 - val_loss: 0.5331 - val_acc: 0.7778\n",
      "Epoch 340/900\n",
      "429/429 [==============================] - 0s 99us/step - loss: 0.4247 - acc: 0.7995 - val_loss: 0.5331 - val_acc: 0.7778\n",
      "Epoch 341/900\n",
      "429/429 [==============================] - 0s 111us/step - loss: 0.4246 - acc: 0.7995 - val_loss: 0.5331 - val_acc: 0.7778\n",
      "Epoch 342/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4245 - acc: 0.7995 - val_loss: 0.5331 - val_acc: 0.7778\n",
      "Epoch 343/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4244 - acc: 0.7995 - val_loss: 0.5330 - val_acc: 0.7778\n",
      "Epoch 344/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4243 - acc: 0.7995 - val_loss: 0.5327 - val_acc: 0.7778\n",
      "Epoch 345/900\n",
      "429/429 [==============================] - 0s 111us/step - loss: 0.4242 - acc: 0.7995 - val_loss: 0.5326 - val_acc: 0.7778\n",
      "Epoch 346/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4240 - acc: 0.7995 - val_loss: 0.5325 - val_acc: 0.7778\n",
      "Epoch 347/900\n",
      "429/429 [==============================] - 0s 108us/step - loss: 0.4239 - acc: 0.7995 - val_loss: 0.5326 - val_acc: 0.7778\n",
      "Epoch 348/900\n",
      "429/429 [==============================] - 0s 117us/step - loss: 0.4238 - acc: 0.7995 - val_loss: 0.5325 - val_acc: 0.7778\n",
      "Epoch 349/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4237 - acc: 0.7995 - val_loss: 0.5324 - val_acc: 0.7778\n",
      "Epoch 350/900\n",
      "429/429 [==============================] - 0s 187us/step - loss: 0.4236 - acc: 0.7995 - val_loss: 0.5324 - val_acc: 0.7778\n",
      "Epoch 351/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4235 - acc: 0.7995 - val_loss: 0.5322 - val_acc: 0.7778\n",
      "Epoch 352/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4235 - acc: 0.8019 - val_loss: 0.5323 - val_acc: 0.7778\n",
      "Epoch 353/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4233 - acc: 0.7995 - val_loss: 0.5322 - val_acc: 0.7778\n",
      "Epoch 354/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4232 - acc: 0.8019 - val_loss: 0.5323 - val_acc: 0.7778\n",
      "Epoch 355/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4232 - acc: 0.7995 - val_loss: 0.5323 - val_acc: 0.7778\n",
      "Epoch 356/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4231 - acc: 0.8019 - val_loss: 0.5322 - val_acc: 0.7778\n",
      "Epoch 357/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4229 - acc: 0.8019 - val_loss: 0.5322 - val_acc: 0.7778\n",
      "Epoch 358/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4228 - acc: 0.8019 - val_loss: 0.5321 - val_acc: 0.7778\n",
      "Epoch 359/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4228 - acc: 0.8019 - val_loss: 0.5321 - val_acc: 0.7685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4227 - acc: 0.8019 - val_loss: 0.5321 - val_acc: 0.7685\n",
      "Epoch 361/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4225 - acc: 0.8019 - val_loss: 0.5322 - val_acc: 0.7685\n",
      "Epoch 362/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4224 - acc: 0.8019 - val_loss: 0.5321 - val_acc: 0.7685\n",
      "Epoch 363/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4224 - acc: 0.8019 - val_loss: 0.5319 - val_acc: 0.7685\n",
      "Epoch 364/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4223 - acc: 0.8019 - val_loss: 0.5318 - val_acc: 0.7685\n",
      "Epoch 365/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4222 - acc: 0.8019 - val_loss: 0.5315 - val_acc: 0.7685\n",
      "Epoch 366/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4221 - acc: 0.8019 - val_loss: 0.5315 - val_acc: 0.7685\n",
      "Epoch 367/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.4220 - acc: 0.8019 - val_loss: 0.5317 - val_acc: 0.7685\n",
      "Epoch 368/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4219 - acc: 0.8019 - val_loss: 0.5316 - val_acc: 0.7685\n",
      "Epoch 369/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4218 - acc: 0.8019 - val_loss: 0.5316 - val_acc: 0.7685\n",
      "Epoch 370/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.4217 - acc: 0.8019 - val_loss: 0.5316 - val_acc: 0.7685\n",
      "Epoch 371/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4216 - acc: 0.8019 - val_loss: 0.5316 - val_acc: 0.7685\n",
      "Epoch 372/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4215 - acc: 0.8019 - val_loss: 0.5316 - val_acc: 0.7685\n",
      "Epoch 373/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4215 - acc: 0.8042 - val_loss: 0.5316 - val_acc: 0.7685\n",
      "Epoch 374/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4213 - acc: 0.8042 - val_loss: 0.5317 - val_acc: 0.7685\n",
      "Epoch 375/900\n",
      "429/429 [==============================] - 0s 114us/step - loss: 0.4212 - acc: 0.8042 - val_loss: 0.5317 - val_acc: 0.7685\n",
      "Epoch 376/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4212 - acc: 0.8042 - val_loss: 0.5316 - val_acc: 0.7685\n",
      "Epoch 377/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4211 - acc: 0.8042 - val_loss: 0.5316 - val_acc: 0.7685\n",
      "Epoch 378/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4210 - acc: 0.8042 - val_loss: 0.5315 - val_acc: 0.7685\n",
      "Epoch 379/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4209 - acc: 0.8042 - val_loss: 0.5315 - val_acc: 0.7685\n",
      "Epoch 380/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4207 - acc: 0.8042 - val_loss: 0.5315 - val_acc: 0.7685\n",
      "Epoch 381/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4207 - acc: 0.8042 - val_loss: 0.5314 - val_acc: 0.7685\n",
      "Epoch 382/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4206 - acc: 0.8042 - val_loss: 0.5314 - val_acc: 0.7685\n",
      "Epoch 383/900\n",
      "429/429 [==============================] - 0s 117us/step - loss: 0.4205 - acc: 0.8042 - val_loss: 0.5313 - val_acc: 0.7685\n",
      "Epoch 384/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4204 - acc: 0.8042 - val_loss: 0.5313 - val_acc: 0.7685\n",
      "Epoch 385/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4203 - acc: 0.8042 - val_loss: 0.5312 - val_acc: 0.7685\n",
      "Epoch 386/900\n",
      "429/429 [==============================] - 0s 114us/step - loss: 0.4202 - acc: 0.8042 - val_loss: 0.5312 - val_acc: 0.7685\n",
      "Epoch 387/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.4743 - acc: 0.718 - 0s 114us/step - loss: 0.4201 - acc: 0.8042 - val_loss: 0.5312 - val_acc: 0.7685\n",
      "Epoch 388/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4200 - acc: 0.8042 - val_loss: 0.5310 - val_acc: 0.7685\n",
      "Epoch 389/900\n",
      "429/429 [==============================] - 0s 111us/step - loss: 0.4200 - acc: 0.8019 - val_loss: 0.5310 - val_acc: 0.7685\n",
      "Epoch 390/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4199 - acc: 0.8042 - val_loss: 0.5310 - val_acc: 0.7685\n",
      "Epoch 391/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4197 - acc: 0.8042 - val_loss: 0.5310 - val_acc: 0.7685\n",
      "Epoch 392/900\n",
      "429/429 [==============================] - 0s 99us/step - loss: 0.4197 - acc: 0.8042 - val_loss: 0.5310 - val_acc: 0.7685\n",
      "Epoch 393/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4196 - acc: 0.8042 - val_loss: 0.5310 - val_acc: 0.7685\n",
      "Epoch 394/900\n",
      "429/429 [==============================] - 0s 108us/step - loss: 0.4195 - acc: 0.8042 - val_loss: 0.5310 - val_acc: 0.7685\n",
      "Epoch 395/900\n",
      "429/429 [==============================] - 0s 114us/step - loss: 0.4194 - acc: 0.8042 - val_loss: 0.5308 - val_acc: 0.7685\n",
      "Epoch 396/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.4194 - acc: 0.8042 - val_loss: 0.5307 - val_acc: 0.7685\n",
      "Epoch 397/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4192 - acc: 0.8042 - val_loss: 0.5307 - val_acc: 0.7685\n",
      "Epoch 398/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4191 - acc: 0.8019 - val_loss: 0.5306 - val_acc: 0.7685\n",
      "Epoch 399/900\n",
      "429/429 [==============================] - 0s 111us/step - loss: 0.4190 - acc: 0.8019 - val_loss: 0.5306 - val_acc: 0.7685\n",
      "Epoch 400/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4189 - acc: 0.8019 - val_loss: 0.5307 - val_acc: 0.7685\n",
      "Epoch 401/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4188 - acc: 0.8019 - val_loss: 0.5307 - val_acc: 0.7685\n",
      "Epoch 402/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4187 - acc: 0.8019 - val_loss: 0.5307 - val_acc: 0.7685\n",
      "Epoch 403/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.4186 - acc: 0.8019 - val_loss: 0.5305 - val_acc: 0.7685\n",
      "Epoch 404/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4186 - acc: 0.8019 - val_loss: 0.5305 - val_acc: 0.7685\n",
      "Epoch 405/900\n",
      "429/429 [==============================] - 0s 113us/step - loss: 0.4184 - acc: 0.8019 - val_loss: 0.5303 - val_acc: 0.7685\n",
      "Epoch 406/900\n",
      "429/429 [==============================] - 0s 118us/step - loss: 0.4184 - acc: 0.8019 - val_loss: 0.5302 - val_acc: 0.7685\n",
      "Epoch 407/900\n",
      "429/429 [==============================] - 0s 119us/step - loss: 0.4183 - acc: 0.8019 - val_loss: 0.5302 - val_acc: 0.7685\n",
      "Epoch 408/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.4182 - acc: 0.8019 - val_loss: 0.5301 - val_acc: 0.7685\n",
      "Epoch 409/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.4181 - acc: 0.8019 - val_loss: 0.5300 - val_acc: 0.7685\n",
      "Epoch 410/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4180 - acc: 0.8019 - val_loss: 0.5301 - val_acc: 0.7685\n",
      "Epoch 411/900\n",
      "429/429 [==============================] - 0s 117us/step - loss: 0.4179 - acc: 0.8019 - val_loss: 0.5301 - val_acc: 0.7685\n",
      "Epoch 412/900\n",
      "429/429 [==============================] - 0s 114us/step - loss: 0.4178 - acc: 0.8019 - val_loss: 0.5302 - val_acc: 0.7685\n",
      "Epoch 413/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4177 - acc: 0.8042 - val_loss: 0.5302 - val_acc: 0.7685\n",
      "Epoch 414/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.4176 - acc: 0.8042 - val_loss: 0.5301 - val_acc: 0.7685\n",
      "Epoch 415/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4176 - acc: 0.8042 - val_loss: 0.5301 - val_acc: 0.7685\n",
      "Epoch 416/900\n",
      "429/429 [==============================] - 0s 115us/step - loss: 0.4175 - acc: 0.8042 - val_loss: 0.5302 - val_acc: 0.7685\n",
      "Epoch 417/900\n",
      "429/429 [==============================] - 0s 111us/step - loss: 0.4174 - acc: 0.8042 - val_loss: 0.5301 - val_acc: 0.7685\n",
      "Epoch 418/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.4173 - acc: 0.8042 - val_loss: 0.5302 - val_acc: 0.7685\n",
      "Epoch 419/900\n",
      "429/429 [==============================] - 0s 111us/step - loss: 0.4172 - acc: 0.8042 - val_loss: 0.5301 - val_acc: 0.7685\n",
      "Epoch 420/900\n",
      "429/429 [==============================] - 0s 108us/step - loss: 0.4171 - acc: 0.8042 - val_loss: 0.5301 - val_acc: 0.7685\n",
      "Epoch 421/900\n",
      "429/429 [==============================] - 0s 120us/step - loss: 0.4170 - acc: 0.8042 - val_loss: 0.5300 - val_acc: 0.7685\n",
      "Epoch 422/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4169 - acc: 0.8042 - val_loss: 0.5298 - val_acc: 0.7685\n",
      "Epoch 423/900\n",
      "429/429 [==============================] - 0s 108us/step - loss: 0.4168 - acc: 0.8042 - val_loss: 0.5298 - val_acc: 0.7685\n",
      "Epoch 424/900\n",
      "429/429 [==============================] - 0s 108us/step - loss: 0.4167 - acc: 0.8042 - val_loss: 0.5297 - val_acc: 0.7685\n",
      "Epoch 425/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.3952 - acc: 0.906 - 0s 111us/step - loss: 0.4166 - acc: 0.8042 - val_loss: 0.5296 - val_acc: 0.7685\n",
      "Epoch 426/900\n",
      "429/429 [==============================] - 0s 115us/step - loss: 0.4166 - acc: 0.8042 - val_loss: 0.5296 - val_acc: 0.7685\n",
      "Epoch 427/900\n",
      "429/429 [==============================] - 0s 108us/step - loss: 0.4164 - acc: 0.8042 - val_loss: 0.5297 - val_acc: 0.7685\n",
      "Epoch 428/900\n",
      "429/429 [==============================] - 0s 113us/step - loss: 0.4163 - acc: 0.8042 - val_loss: 0.5297 - val_acc: 0.7685\n",
      "Epoch 429/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.4163 - acc: 0.8042 - val_loss: 0.5296 - val_acc: 0.7685\n",
      "Epoch 430/900\n",
      "429/429 [==============================] - 0s 108us/step - loss: 0.4162 - acc: 0.8042 - val_loss: 0.5294 - val_acc: 0.7685\n",
      "Epoch 431/900\n",
      "429/429 [==============================] - 0s 115us/step - loss: 0.4161 - acc: 0.8042 - val_loss: 0.5295 - val_acc: 0.7685\n",
      "Epoch 432/900\n",
      "429/429 [==============================] - 0s 108us/step - loss: 0.4160 - acc: 0.8042 - val_loss: 0.5292 - val_acc: 0.7685\n",
      "Epoch 433/900\n",
      "429/429 [==============================] - 0s 111us/step - loss: 0.4159 - acc: 0.8042 - val_loss: 0.5292 - val_acc: 0.7685\n",
      "Epoch 434/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.4158 - acc: 0.8042 - val_loss: 0.5293 - val_acc: 0.7685\n",
      "Epoch 435/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4158 - acc: 0.8042 - val_loss: 0.5292 - val_acc: 0.7685\n",
      "Epoch 436/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.3996 - acc: 0.781 - 0s 105us/step - loss: 0.4156 - acc: 0.8065 - val_loss: 0.5292 - val_acc: 0.7685\n",
      "Epoch 437/900\n",
      "429/429 [==============================] - 0s 108us/step - loss: 0.4156 - acc: 0.8042 - val_loss: 0.5290 - val_acc: 0.7685\n",
      "Epoch 438/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.4155 - acc: 0.8042 - val_loss: 0.5289 - val_acc: 0.7685\n",
      "Epoch 439/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4154 - acc: 0.8065 - val_loss: 0.5289 - val_acc: 0.7685\n",
      "Epoch 440/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4153 - acc: 0.8065 - val_loss: 0.5290 - val_acc: 0.7685\n",
      "Epoch 441/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4152 - acc: 0.8065 - val_loss: 0.5289 - val_acc: 0.7685\n",
      "Epoch 442/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4151 - acc: 0.8065 - val_loss: 0.5288 - val_acc: 0.7685\n",
      "Epoch 443/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4150 - acc: 0.8065 - val_loss: 0.5289 - val_acc: 0.7685\n",
      "Epoch 444/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.4150 - acc: 0.8065 - val_loss: 0.5288 - val_acc: 0.7685\n",
      "Epoch 445/900\n",
      "429/429 [==============================] - 0s 113us/step - loss: 0.4149 - acc: 0.8065 - val_loss: 0.5288 - val_acc: 0.7685\n",
      "Epoch 446/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4148 - acc: 0.8065 - val_loss: 0.5288 - val_acc: 0.7685\n",
      "Epoch 447/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4147 - acc: 0.8065 - val_loss: 0.5287 - val_acc: 0.7685\n",
      "Epoch 448/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4146 - acc: 0.8065 - val_loss: 0.5288 - val_acc: 0.7685\n",
      "Epoch 449/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4146 - acc: 0.8065 - val_loss: 0.5289 - val_acc: 0.7685\n",
      "Epoch 450/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4145 - acc: 0.8065 - val_loss: 0.5289 - val_acc: 0.7685\n",
      "Epoch 451/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4145 - acc: 0.8065 - val_loss: 0.5289 - val_acc: 0.7685\n",
      "Epoch 452/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4144 - acc: 0.8065 - val_loss: 0.5287 - val_acc: 0.7685\n",
      "Epoch 453/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4143 - acc: 0.8065 - val_loss: 0.5287 - val_acc: 0.7685\n",
      "Epoch 454/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.4142 - acc: 0.8065 - val_loss: 0.5286 - val_acc: 0.7685\n",
      "Epoch 455/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4141 - acc: 0.8065 - val_loss: 0.5286 - val_acc: 0.7685\n",
      "Epoch 456/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4141 - acc: 0.8065 - val_loss: 0.5286 - val_acc: 0.7685\n",
      "Epoch 457/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4139 - acc: 0.8065 - val_loss: 0.5286 - val_acc: 0.7685\n",
      "Epoch 458/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4139 - acc: 0.8065 - val_loss: 0.5284 - val_acc: 0.7685\n",
      "Epoch 459/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4138 - acc: 0.8065 - val_loss: 0.5285 - val_acc: 0.7685\n",
      "Epoch 460/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4137 - acc: 0.8065 - val_loss: 0.5285 - val_acc: 0.7685\n",
      "Epoch 461/900\n",
      "429/429 [==============================] - 0s 113us/step - loss: 0.4137 - acc: 0.8065 - val_loss: 0.5285 - val_acc: 0.7685\n",
      "Epoch 462/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4136 - acc: 0.8065 - val_loss: 0.5285 - val_acc: 0.7685\n",
      "Epoch 463/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4135 - acc: 0.8065 - val_loss: 0.5285 - val_acc: 0.7685\n",
      "Epoch 464/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4134 - acc: 0.8065 - val_loss: 0.5283 - val_acc: 0.7685\n",
      "Epoch 465/900\n",
      "429/429 [==============================] - 0s 113us/step - loss: 0.4134 - acc: 0.8065 - val_loss: 0.5283 - val_acc: 0.7685\n",
      "Epoch 466/900\n",
      "429/429 [==============================] - 0s 99us/step - loss: 0.4132 - acc: 0.8065 - val_loss: 0.5284 - val_acc: 0.7685\n",
      "Epoch 467/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4132 - acc: 0.8065 - val_loss: 0.5282 - val_acc: 0.7685\n",
      "Epoch 468/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4132 - acc: 0.8065 - val_loss: 0.5282 - val_acc: 0.7685\n",
      "Epoch 469/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4131 - acc: 0.8065 - val_loss: 0.5282 - val_acc: 0.7685\n",
      "Epoch 470/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4130 - acc: 0.8065 - val_loss: 0.5281 - val_acc: 0.7685\n",
      "Epoch 471/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4130 - acc: 0.8065 - val_loss: 0.5280 - val_acc: 0.7685\n",
      "Epoch 472/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.4741 - acc: 0.687 - 0s 124us/step - loss: 0.4128 - acc: 0.8065 - val_loss: 0.5280 - val_acc: 0.7685\n",
      "Epoch 473/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.4004 - acc: 0.812 - 0s 98us/step - loss: 0.4128 - acc: 0.8065 - val_loss: 0.5278 - val_acc: 0.7685\n",
      "Epoch 474/900\n",
      "429/429 [==============================] - 0s 111us/step - loss: 0.4128 - acc: 0.8065 - val_loss: 0.5278 - val_acc: 0.7685\n",
      "Epoch 475/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4127 - acc: 0.8065 - val_loss: 0.5280 - val_acc: 0.7685\n",
      "Epoch 476/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4126 - acc: 0.8065 - val_loss: 0.5281 - val_acc: 0.7685\n",
      "Epoch 477/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4125 - acc: 0.8065 - val_loss: 0.5280 - val_acc: 0.7685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4125 - acc: 0.8065 - val_loss: 0.5280 - val_acc: 0.7685\n",
      "Epoch 479/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4124 - acc: 0.8065 - val_loss: 0.5278 - val_acc: 0.7685\n",
      "Epoch 480/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4124 - acc: 0.8065 - val_loss: 0.5278 - val_acc: 0.7685\n",
      "Epoch 481/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4122 - acc: 0.8065 - val_loss: 0.5279 - val_acc: 0.7685\n",
      "Epoch 482/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4122 - acc: 0.8089 - val_loss: 0.5279 - val_acc: 0.7685\n",
      "Epoch 483/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.4121 - acc: 0.8089 - val_loss: 0.5279 - val_acc: 0.7685\n",
      "Epoch 484/900\n",
      "429/429 [==============================] - 0s 114us/step - loss: 0.4120 - acc: 0.8089 - val_loss: 0.5279 - val_acc: 0.7685\n",
      "Epoch 485/900\n",
      "429/429 [==============================] - 0s 114us/step - loss: 0.4120 - acc: 0.8089 - val_loss: 0.5280 - val_acc: 0.7685\n",
      "Epoch 486/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.4119 - acc: 0.8089 - val_loss: 0.5280 - val_acc: 0.7685\n",
      "Epoch 487/900\n",
      "429/429 [==============================] - 0s 119us/step - loss: 0.4118 - acc: 0.8089 - val_loss: 0.5280 - val_acc: 0.7685\n",
      "Epoch 488/900\n",
      "429/429 [==============================] - 0s 111us/step - loss: 0.4118 - acc: 0.8089 - val_loss: 0.5280 - val_acc: 0.7685\n",
      "Epoch 489/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.4117 - acc: 0.8089 - val_loss: 0.5279 - val_acc: 0.7685\n",
      "Epoch 490/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4116 - acc: 0.8089 - val_loss: 0.5279 - val_acc: 0.7685\n",
      "Epoch 491/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4116 - acc: 0.8089 - val_loss: 0.5280 - val_acc: 0.7685\n",
      "Epoch 492/900\n",
      "429/429 [==============================] - 0s 111us/step - loss: 0.4115 - acc: 0.8089 - val_loss: 0.5278 - val_acc: 0.7685\n",
      "Epoch 493/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4115 - acc: 0.8089 - val_loss: 0.5276 - val_acc: 0.7685\n",
      "Epoch 494/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4114 - acc: 0.8089 - val_loss: 0.5275 - val_acc: 0.7685\n",
      "Epoch 495/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4113 - acc: 0.8112 - val_loss: 0.5276 - val_acc: 0.7685\n",
      "Epoch 496/900\n",
      "429/429 [==============================] - 0s 108us/step - loss: 0.4113 - acc: 0.8089 - val_loss: 0.5275 - val_acc: 0.7685\n",
      "Epoch 497/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4112 - acc: 0.8112 - val_loss: 0.5274 - val_acc: 0.7685\n",
      "Epoch 498/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4112 - acc: 0.8112 - val_loss: 0.5273 - val_acc: 0.7685\n",
      "Epoch 499/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4111 - acc: 0.8112 - val_loss: 0.5273 - val_acc: 0.7685\n",
      "Epoch 500/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4110 - acc: 0.8112 - val_loss: 0.5272 - val_acc: 0.7685\n",
      "Epoch 501/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4110 - acc: 0.8112 - val_loss: 0.5272 - val_acc: 0.7685\n",
      "Epoch 502/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4109 - acc: 0.8112 - val_loss: 0.5273 - val_acc: 0.7685\n",
      "Epoch 503/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4108 - acc: 0.8112 - val_loss: 0.5272 - val_acc: 0.7685\n",
      "Epoch 504/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4108 - acc: 0.8112 - val_loss: 0.5273 - val_acc: 0.7685\n",
      "Epoch 505/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4107 - acc: 0.8135 - val_loss: 0.5273 - val_acc: 0.7685\n",
      "Epoch 506/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4106 - acc: 0.8112 - val_loss: 0.5274 - val_acc: 0.7685\n",
      "Epoch 507/900\n",
      "429/429 [==============================] - 0s 108us/step - loss: 0.4106 - acc: 0.8135 - val_loss: 0.5274 - val_acc: 0.7685\n",
      "Epoch 508/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4105 - acc: 0.8135 - val_loss: 0.5272 - val_acc: 0.7685\n",
      "Epoch 509/900\n",
      "429/429 [==============================] - 0s 94us/step - loss: 0.4104 - acc: 0.8135 - val_loss: 0.5272 - val_acc: 0.7685\n",
      "Epoch 510/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4104 - acc: 0.8135 - val_loss: 0.5271 - val_acc: 0.7685\n",
      "Epoch 511/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4103 - acc: 0.8135 - val_loss: 0.5271 - val_acc: 0.7685\n",
      "Epoch 512/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4102 - acc: 0.8135 - val_loss: 0.5270 - val_acc: 0.7685\n",
      "Epoch 513/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4102 - acc: 0.8135 - val_loss: 0.5268 - val_acc: 0.7685\n",
      "Epoch 514/900\n",
      "429/429 [==============================] - 0s 92us/step - loss: 0.4101 - acc: 0.8135 - val_loss: 0.5266 - val_acc: 0.7685\n",
      "Epoch 515/900\n",
      "429/429 [==============================] - 0s 92us/step - loss: 0.4101 - acc: 0.8135 - val_loss: 0.5266 - val_acc: 0.7685\n",
      "Epoch 516/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4100 - acc: 0.8135 - val_loss: 0.5267 - val_acc: 0.7685\n",
      "Epoch 517/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4099 - acc: 0.8135 - val_loss: 0.5267 - val_acc: 0.7685\n",
      "Epoch 518/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4098 - acc: 0.8135 - val_loss: 0.5267 - val_acc: 0.7685\n",
      "Epoch 519/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4098 - acc: 0.8135 - val_loss: 0.5267 - val_acc: 0.7685\n",
      "Epoch 520/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4097 - acc: 0.8135 - val_loss: 0.5264 - val_acc: 0.7685\n",
      "Epoch 521/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4097 - acc: 0.8135 - val_loss: 0.5263 - val_acc: 0.7685\n",
      "Epoch 522/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4096 - acc: 0.8135 - val_loss: 0.5262 - val_acc: 0.7685\n",
      "Epoch 523/900\n",
      "429/429 [==============================] - 0s 99us/step - loss: 0.4095 - acc: 0.8135 - val_loss: 0.5261 - val_acc: 0.7685\n",
      "Epoch 524/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4095 - acc: 0.8112 - val_loss: 0.5261 - val_acc: 0.7685\n",
      "Epoch 525/900\n",
      "429/429 [==============================] - 0s 94us/step - loss: 0.4094 - acc: 0.8135 - val_loss: 0.5260 - val_acc: 0.7685\n",
      "Epoch 526/900\n",
      "429/429 [==============================] - 0s 92us/step - loss: 0.4093 - acc: 0.8135 - val_loss: 0.5261 - val_acc: 0.7685\n",
      "Epoch 527/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4093 - acc: 0.8135 - val_loss: 0.5260 - val_acc: 0.7685\n",
      "Epoch 528/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4092 - acc: 0.8135 - val_loss: 0.5260 - val_acc: 0.7685\n",
      "Epoch 529/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4092 - acc: 0.8112 - val_loss: 0.5261 - val_acc: 0.7685\n",
      "Epoch 530/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4091 - acc: 0.8159 - val_loss: 0.5260 - val_acc: 0.7685\n",
      "Epoch 531/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4091 - acc: 0.8135 - val_loss: 0.5257 - val_acc: 0.7685\n",
      "Epoch 532/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4090 - acc: 0.8112 - val_loss: 0.5258 - val_acc: 0.7685\n",
      "Epoch 533/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4090 - acc: 0.8112 - val_loss: 0.5259 - val_acc: 0.7685\n",
      "Epoch 534/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4089 - acc: 0.8112 - val_loss: 0.5259 - val_acc: 0.7685\n",
      "Epoch 535/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4088 - acc: 0.8135 - val_loss: 0.5260 - val_acc: 0.7685\n",
      "Epoch 536/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4088 - acc: 0.8135 - val_loss: 0.5260 - val_acc: 0.7685\n",
      "Epoch 537/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4087 - acc: 0.8135 - val_loss: 0.5260 - val_acc: 0.7685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 538/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4086 - acc: 0.8135 - val_loss: 0.5260 - val_acc: 0.7685\n",
      "Epoch 539/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4086 - acc: 0.8135 - val_loss: 0.5260 - val_acc: 0.7685\n",
      "Epoch 540/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4085 - acc: 0.8135 - val_loss: 0.5261 - val_acc: 0.7685\n",
      "Epoch 541/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4084 - acc: 0.8135 - val_loss: 0.5259 - val_acc: 0.7685\n",
      "Epoch 542/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4083 - acc: 0.8135 - val_loss: 0.5260 - val_acc: 0.7685\n",
      "Epoch 543/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4083 - acc: 0.8159 - val_loss: 0.5260 - val_acc: 0.7778\n",
      "Epoch 544/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4082 - acc: 0.8135 - val_loss: 0.5259 - val_acc: 0.7778\n",
      "Epoch 545/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4082 - acc: 0.8135 - val_loss: 0.5257 - val_acc: 0.7778\n",
      "Epoch 546/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4081 - acc: 0.8159 - val_loss: 0.5257 - val_acc: 0.7778\n",
      "Epoch 547/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4080 - acc: 0.8135 - val_loss: 0.5258 - val_acc: 0.7778\n",
      "Epoch 548/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4080 - acc: 0.8159 - val_loss: 0.5258 - val_acc: 0.7778\n",
      "Epoch 549/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4079 - acc: 0.8135 - val_loss: 0.5257 - val_acc: 0.7778\n",
      "Epoch 550/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4079 - acc: 0.8135 - val_loss: 0.5257 - val_acc: 0.7778\n",
      "Epoch 551/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4078 - acc: 0.8159 - val_loss: 0.5258 - val_acc: 0.7778\n",
      "Epoch 552/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4078 - acc: 0.8159 - val_loss: 0.5258 - val_acc: 0.7778\n",
      "Epoch 553/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4077 - acc: 0.8159 - val_loss: 0.5256 - val_acc: 0.7778\n",
      "Epoch 554/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4077 - acc: 0.8159 - val_loss: 0.5258 - val_acc: 0.7778\n",
      "Epoch 555/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4076 - acc: 0.8182 - val_loss: 0.5259 - val_acc: 0.7778\n",
      "Epoch 556/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4075 - acc: 0.8159 - val_loss: 0.5259 - val_acc: 0.7778\n",
      "Epoch 557/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4074 - acc: 0.8182 - val_loss: 0.5257 - val_acc: 0.7778\n",
      "Epoch 558/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4074 - acc: 0.8182 - val_loss: 0.5256 - val_acc: 0.7778\n",
      "Epoch 559/900\n",
      "429/429 [==============================] - 0s 77us/step - loss: 0.4074 - acc: 0.8182 - val_loss: 0.5256 - val_acc: 0.7778\n",
      "Epoch 560/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4073 - acc: 0.8159 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 561/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4073 - acc: 0.8182 - val_loss: 0.5255 - val_acc: 0.7778\n",
      "Epoch 562/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4073 - acc: 0.8182 - val_loss: 0.5255 - val_acc: 0.7778\n",
      "Epoch 563/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4072 - acc: 0.8159 - val_loss: 0.5255 - val_acc: 0.7778\n",
      "Epoch 564/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4071 - acc: 0.8182 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 565/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4070 - acc: 0.8159 - val_loss: 0.5253 - val_acc: 0.7778\n",
      "Epoch 566/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4070 - acc: 0.8182 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 567/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4069 - acc: 0.8182 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 568/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4069 - acc: 0.8182 - val_loss: 0.5256 - val_acc: 0.7778\n",
      "Epoch 569/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4068 - acc: 0.8182 - val_loss: 0.5253 - val_acc: 0.7778\n",
      "Epoch 570/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4068 - acc: 0.8182 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 571/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4067 - acc: 0.8182 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 572/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4067 - acc: 0.8182 - val_loss: 0.5255 - val_acc: 0.7778\n",
      "Epoch 573/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4066 - acc: 0.8182 - val_loss: 0.5257 - val_acc: 0.7778\n",
      "Epoch 574/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4066 - acc: 0.8159 - val_loss: 0.5257 - val_acc: 0.7778\n",
      "Epoch 575/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4065 - acc: 0.8182 - val_loss: 0.5257 - val_acc: 0.7778\n",
      "Epoch 576/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4064 - acc: 0.8182 - val_loss: 0.5257 - val_acc: 0.7778\n",
      "Epoch 577/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4064 - acc: 0.8159 - val_loss: 0.5257 - val_acc: 0.7778\n",
      "Epoch 578/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4063 - acc: 0.8159 - val_loss: 0.5258 - val_acc: 0.7778\n",
      "Epoch 579/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4062 - acc: 0.8159 - val_loss: 0.5258 - val_acc: 0.7778\n",
      "Epoch 580/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4062 - acc: 0.8159 - val_loss: 0.5259 - val_acc: 0.7778\n",
      "Epoch 581/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4062 - acc: 0.8159 - val_loss: 0.5258 - val_acc: 0.7778\n",
      "Epoch 582/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4060 - acc: 0.8159 - val_loss: 0.5259 - val_acc: 0.7685\n",
      "Epoch 583/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4060 - acc: 0.8159 - val_loss: 0.5259 - val_acc: 0.7778\n",
      "Epoch 584/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4060 - acc: 0.8159 - val_loss: 0.5257 - val_acc: 0.7778\n",
      "Epoch 585/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4059 - acc: 0.8159 - val_loss: 0.5257 - val_acc: 0.7778\n",
      "Epoch 586/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4058 - acc: 0.8159 - val_loss: 0.5257 - val_acc: 0.7778\n",
      "Epoch 587/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4058 - acc: 0.8159 - val_loss: 0.5256 - val_acc: 0.7778\n",
      "Epoch 588/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4058 - acc: 0.8159 - val_loss: 0.5255 - val_acc: 0.7778\n",
      "Epoch 589/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4058 - acc: 0.8159 - val_loss: 0.5253 - val_acc: 0.7778\n",
      "Epoch 590/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4057 - acc: 0.8182 - val_loss: 0.5253 - val_acc: 0.7778\n",
      "Epoch 591/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4056 - acc: 0.8159 - val_loss: 0.5253 - val_acc: 0.7778\n",
      "Epoch 592/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4056 - acc: 0.8205 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 593/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4055 - acc: 0.8182 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 594/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4054 - acc: 0.8182 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 595/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4054 - acc: 0.8182 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 596/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4053 - acc: 0.8182 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 597/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4053 - acc: 0.8182 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 598/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4053 - acc: 0.8182 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 599/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4052 - acc: 0.8182 - val_loss: 0.5255 - val_acc: 0.7685\n",
      "Epoch 600/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4051 - acc: 0.8182 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 601/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4051 - acc: 0.8182 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 602/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4051 - acc: 0.8182 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 603/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4050 - acc: 0.8182 - val_loss: 0.5250 - val_acc: 0.7685\n",
      "Epoch 604/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4050 - acc: 0.8182 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 605/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4049 - acc: 0.8182 - val_loss: 0.5250 - val_acc: 0.7685\n",
      "Epoch 606/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4049 - acc: 0.8182 - val_loss: 0.5250 - val_acc: 0.7685\n",
      "Epoch 607/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4048 - acc: 0.8182 - val_loss: 0.5249 - val_acc: 0.7685\n",
      "Epoch 608/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4048 - acc: 0.8205 - val_loss: 0.5248 - val_acc: 0.7685\n",
      "Epoch 609/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4047 - acc: 0.8205 - val_loss: 0.5249 - val_acc: 0.7685\n",
      "Epoch 610/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4047 - acc: 0.8205 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 611/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4046 - acc: 0.8182 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 612/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4046 - acc: 0.8182 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 613/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4045 - acc: 0.8182 - val_loss: 0.5250 - val_acc: 0.7685\n",
      "Epoch 614/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4045 - acc: 0.8182 - val_loss: 0.5249 - val_acc: 0.7685\n",
      "Epoch 615/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4044 - acc: 0.8182 - val_loss: 0.5246 - val_acc: 0.7685\n",
      "Epoch 616/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4044 - acc: 0.8182 - val_loss: 0.5245 - val_acc: 0.7685\n",
      "Epoch 617/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4043 - acc: 0.8182 - val_loss: 0.5245 - val_acc: 0.7685\n",
      "Epoch 618/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4043 - acc: 0.8182 - val_loss: 0.5246 - val_acc: 0.7685\n",
      "Epoch 619/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4043 - acc: 0.8205 - val_loss: 0.5245 - val_acc: 0.7685\n",
      "Epoch 620/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4043 - acc: 0.8205 - val_loss: 0.5245 - val_acc: 0.7685\n",
      "Epoch 621/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4042 - acc: 0.8205 - val_loss: 0.5247 - val_acc: 0.7685\n",
      "Epoch 622/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4041 - acc: 0.8205 - val_loss: 0.5249 - val_acc: 0.7778\n",
      "Epoch 623/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4041 - acc: 0.8182 - val_loss: 0.5248 - val_acc: 0.7778\n",
      "Epoch 624/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4041 - acc: 0.8205 - val_loss: 0.5248 - val_acc: 0.7778\n",
      "Epoch 625/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4040 - acc: 0.8205 - val_loss: 0.5248 - val_acc: 0.7778\n",
      "Epoch 626/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4040 - acc: 0.8205 - val_loss: 0.5246 - val_acc: 0.7778\n",
      "Epoch 627/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4040 - acc: 0.8205 - val_loss: 0.5247 - val_acc: 0.7778\n",
      "Epoch 628/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4039 - acc: 0.8228 - val_loss: 0.5246 - val_acc: 0.7778\n",
      "Epoch 629/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4039 - acc: 0.8228 - val_loss: 0.5248 - val_acc: 0.7778\n",
      "Epoch 630/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4038 - acc: 0.8205 - val_loss: 0.5248 - val_acc: 0.7778\n",
      "Epoch 631/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4038 - acc: 0.8205 - val_loss: 0.5248 - val_acc: 0.7778\n",
      "Epoch 632/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4037 - acc: 0.8228 - val_loss: 0.5250 - val_acc: 0.7778\n",
      "Epoch 633/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4037 - acc: 0.8205 - val_loss: 0.5248 - val_acc: 0.7778\n",
      "Epoch 634/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4036 - acc: 0.8205 - val_loss: 0.5247 - val_acc: 0.7778\n",
      "Epoch 635/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4036 - acc: 0.8228 - val_loss: 0.5244 - val_acc: 0.7778\n",
      "Epoch 636/900\n",
      "429/429 [==============================] - 0s 77us/step - loss: 0.4036 - acc: 0.8252 - val_loss: 0.5244 - val_acc: 0.7778\n",
      "Epoch 637/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4036 - acc: 0.8252 - val_loss: 0.5245 - val_acc: 0.7778\n",
      "Epoch 638/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4035 - acc: 0.8252 - val_loss: 0.5246 - val_acc: 0.7778\n",
      "Epoch 639/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4035 - acc: 0.8252 - val_loss: 0.5247 - val_acc: 0.7778\n",
      "Epoch 640/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4034 - acc: 0.8228 - val_loss: 0.5246 - val_acc: 0.7778\n",
      "Epoch 641/900\n",
      "429/429 [==============================] - 0s 77us/step - loss: 0.4034 - acc: 0.8228 - val_loss: 0.5245 - val_acc: 0.7778\n",
      "Epoch 642/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4033 - acc: 0.8228 - val_loss: 0.5244 - val_acc: 0.7778\n",
      "Epoch 643/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4033 - acc: 0.8252 - val_loss: 0.5243 - val_acc: 0.7778\n",
      "Epoch 644/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4032 - acc: 0.8252 - val_loss: 0.5241 - val_acc: 0.7778\n",
      "Epoch 645/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4032 - acc: 0.8228 - val_loss: 0.5241 - val_acc: 0.7778\n",
      "Epoch 646/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4032 - acc: 0.8228 - val_loss: 0.5238 - val_acc: 0.7778\n",
      "Epoch 647/900\n",
      "429/429 [==============================] - 0s 77us/step - loss: 0.4031 - acc: 0.8252 - val_loss: 0.5239 - val_acc: 0.7778\n",
      "Epoch 648/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4031 - acc: 0.8252 - val_loss: 0.5240 - val_acc: 0.7778\n",
      "Epoch 649/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4031 - acc: 0.8252 - val_loss: 0.5243 - val_acc: 0.7778\n",
      "Epoch 650/900\n",
      "429/429 [==============================] - 0s 77us/step - loss: 0.4030 - acc: 0.8228 - val_loss: 0.5243 - val_acc: 0.7778\n",
      "Epoch 651/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4030 - acc: 0.8252 - val_loss: 0.5243 - val_acc: 0.7778\n",
      "Epoch 652/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4030 - acc: 0.8252 - val_loss: 0.5243 - val_acc: 0.7778\n",
      "Epoch 653/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4029 - acc: 0.8228 - val_loss: 0.5244 - val_acc: 0.7778\n",
      "Epoch 654/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.4029 - acc: 0.8252 - val_loss: 0.5245 - val_acc: 0.7778\n",
      "Epoch 655/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4028 - acc: 0.8252 - val_loss: 0.5246 - val_acc: 0.7778\n",
      "Epoch 656/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4028 - acc: 0.8252 - val_loss: 0.5246 - val_acc: 0.7778\n",
      "Epoch 657/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4027 - acc: 0.8252 - val_loss: 0.5244 - val_acc: 0.7778\n",
      "Epoch 658/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 91us/step - loss: 0.4027 - acc: 0.8252 - val_loss: 0.5244 - val_acc: 0.7778\n",
      "Epoch 659/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4027 - acc: 0.8252 - val_loss: 0.5244 - val_acc: 0.7778\n",
      "Epoch 660/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4026 - acc: 0.8252 - val_loss: 0.5242 - val_acc: 0.7778\n",
      "Epoch 661/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4026 - acc: 0.8252 - val_loss: 0.5243 - val_acc: 0.7778\n",
      "Epoch 662/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4026 - acc: 0.8252 - val_loss: 0.5244 - val_acc: 0.7778\n",
      "Epoch 663/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4025 - acc: 0.8252 - val_loss: 0.5244 - val_acc: 0.7778\n",
      "Epoch 664/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4025 - acc: 0.8228 - val_loss: 0.5245 - val_acc: 0.7778\n",
      "Epoch 665/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4025 - acc: 0.8228 - val_loss: 0.5246 - val_acc: 0.7778\n",
      "Epoch 666/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4024 - acc: 0.8252 - val_loss: 0.5247 - val_acc: 0.7778\n",
      "Epoch 667/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4024 - acc: 0.8252 - val_loss: 0.5246 - val_acc: 0.7778\n",
      "Epoch 668/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4024 - acc: 0.8252 - val_loss: 0.5245 - val_acc: 0.7778\n",
      "Epoch 669/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4023 - acc: 0.8252 - val_loss: 0.5244 - val_acc: 0.7778\n",
      "Epoch 670/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.2732 - acc: 0.875 - 0s 89us/step - loss: 0.4023 - acc: 0.8252 - val_loss: 0.5243 - val_acc: 0.7778\n",
      "Epoch 671/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4023 - acc: 0.8252 - val_loss: 0.5244 - val_acc: 0.7778\n",
      "Epoch 672/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4022 - acc: 0.8252 - val_loss: 0.5245 - val_acc: 0.7778\n",
      "Epoch 673/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4022 - acc: 0.8275 - val_loss: 0.5246 - val_acc: 0.7778\n",
      "Epoch 674/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4021 - acc: 0.8252 - val_loss: 0.5249 - val_acc: 0.7778\n",
      "Epoch 675/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4021 - acc: 0.8252 - val_loss: 0.5249 - val_acc: 0.7778\n",
      "Epoch 676/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4022 - acc: 0.8252 - val_loss: 0.5248 - val_acc: 0.7778\n",
      "Epoch 677/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4021 - acc: 0.8252 - val_loss: 0.5246 - val_acc: 0.7778\n",
      "Epoch 678/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4021 - acc: 0.8252 - val_loss: 0.5246 - val_acc: 0.7778\n",
      "Epoch 679/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4020 - acc: 0.8252 - val_loss: 0.5245 - val_acc: 0.7778\n",
      "Epoch 680/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4020 - acc: 0.8275 - val_loss: 0.5245 - val_acc: 0.7778\n",
      "Epoch 681/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4020 - acc: 0.8275 - val_loss: 0.5245 - val_acc: 0.7778\n",
      "Epoch 682/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.4019 - acc: 0.8252 - val_loss: 0.5241 - val_acc: 0.7778\n",
      "Epoch 683/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4019 - acc: 0.8275 - val_loss: 0.5242 - val_acc: 0.7778\n",
      "Epoch 684/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4019 - acc: 0.8275 - val_loss: 0.5240 - val_acc: 0.7778\n",
      "Epoch 685/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4018 - acc: 0.8275 - val_loss: 0.5242 - val_acc: 0.7778\n",
      "Epoch 686/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.4018 - acc: 0.8275 - val_loss: 0.5240 - val_acc: 0.7778\n",
      "Epoch 687/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4018 - acc: 0.8275 - val_loss: 0.5241 - val_acc: 0.7778\n",
      "Epoch 688/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4017 - acc: 0.8275 - val_loss: 0.5242 - val_acc: 0.7778\n",
      "Epoch 689/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4017 - acc: 0.8275 - val_loss: 0.5244 - val_acc: 0.7778\n",
      "Epoch 690/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4016 - acc: 0.8275 - val_loss: 0.5242 - val_acc: 0.7778\n",
      "Epoch 691/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4016 - acc: 0.8275 - val_loss: 0.5244 - val_acc: 0.7778\n",
      "Epoch 692/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4016 - acc: 0.8275 - val_loss: 0.5244 - val_acc: 0.7778\n",
      "Epoch 693/900\n",
      "429/429 [==============================] - 0s 77us/step - loss: 0.4016 - acc: 0.8275 - val_loss: 0.5245 - val_acc: 0.7778\n",
      "Epoch 694/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4015 - acc: 0.8275 - val_loss: 0.5243 - val_acc: 0.7778\n",
      "Epoch 695/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4015 - acc: 0.8275 - val_loss: 0.5242 - val_acc: 0.7778\n",
      "Epoch 696/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4015 - acc: 0.8275 - val_loss: 0.5242 - val_acc: 0.7778\n",
      "Epoch 697/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4015 - acc: 0.8275 - val_loss: 0.5242 - val_acc: 0.7778\n",
      "Epoch 698/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4014 - acc: 0.8275 - val_loss: 0.5242 - val_acc: 0.7778\n",
      "Epoch 699/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4014 - acc: 0.8275 - val_loss: 0.5241 - val_acc: 0.7778\n",
      "Epoch 700/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4014 - acc: 0.8275 - val_loss: 0.5242 - val_acc: 0.7778\n",
      "Epoch 701/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4014 - acc: 0.8275 - val_loss: 0.5242 - val_acc: 0.7778\n",
      "Epoch 702/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4013 - acc: 0.8275 - val_loss: 0.5241 - val_acc: 0.7778\n",
      "Epoch 703/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4013 - acc: 0.8275 - val_loss: 0.5242 - val_acc: 0.7778\n",
      "Epoch 704/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4012 - acc: 0.8275 - val_loss: 0.5242 - val_acc: 0.7778\n",
      "Epoch 705/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4013 - acc: 0.8275 - val_loss: 0.5241 - val_acc: 0.7778\n",
      "Epoch 706/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4012 - acc: 0.8252 - val_loss: 0.5242 - val_acc: 0.7778\n",
      "Epoch 707/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4011 - acc: 0.8275 - val_loss: 0.5242 - val_acc: 0.7778\n",
      "Epoch 708/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.4676 - acc: 0.812 - 0s 93us/step - loss: 0.4011 - acc: 0.8275 - val_loss: 0.5244 - val_acc: 0.7778\n",
      "Epoch 709/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4011 - acc: 0.8275 - val_loss: 0.5245 - val_acc: 0.7778\n",
      "Epoch 710/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4011 - acc: 0.8275 - val_loss: 0.5247 - val_acc: 0.7778\n",
      "Epoch 711/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4011 - acc: 0.8275 - val_loss: 0.5248 - val_acc: 0.7778\n",
      "Epoch 712/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.4010 - acc: 0.8275 - val_loss: 0.5250 - val_acc: 0.7778\n",
      "Epoch 713/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.4009 - acc: 0.8275 - val_loss: 0.5250 - val_acc: 0.7778\n",
      "Epoch 714/900\n",
      "429/429 [==============================] - 0s 77us/step - loss: 0.4010 - acc: 0.8275 - val_loss: 0.5250 - val_acc: 0.7778\n",
      "Epoch 715/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4009 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7778\n",
      "Epoch 716/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4009 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7778\n",
      "Epoch 717/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.4009 - acc: 0.8275 - val_loss: 0.5250 - val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 718/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.4009 - acc: 0.8275 - val_loss: 0.5249 - val_acc: 0.7778\n",
      "Epoch 719/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4008 - acc: 0.8275 - val_loss: 0.5249 - val_acc: 0.7778\n",
      "Epoch 720/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4008 - acc: 0.8275 - val_loss: 0.5248 - val_acc: 0.7778\n",
      "Epoch 721/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4008 - acc: 0.8275 - val_loss: 0.5247 - val_acc: 0.7778\n",
      "Epoch 722/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4008 - acc: 0.8275 - val_loss: 0.5246 - val_acc: 0.7778\n",
      "Epoch 723/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4007 - acc: 0.8275 - val_loss: 0.5245 - val_acc: 0.7778\n",
      "Epoch 724/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4008 - acc: 0.8275 - val_loss: 0.5245 - val_acc: 0.7778\n",
      "Epoch 725/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.4007 - acc: 0.8275 - val_loss: 0.5247 - val_acc: 0.7778\n",
      "Epoch 726/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4007 - acc: 0.8275 - val_loss: 0.5248 - val_acc: 0.7778\n",
      "Epoch 727/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4006 - acc: 0.8275 - val_loss: 0.5247 - val_acc: 0.7778\n",
      "Epoch 728/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.4006 - acc: 0.8275 - val_loss: 0.5246 - val_acc: 0.7778\n",
      "Epoch 729/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.4006 - acc: 0.8275 - val_loss: 0.5247 - val_acc: 0.7778\n",
      "Epoch 730/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4005 - acc: 0.8275 - val_loss: 0.5247 - val_acc: 0.7778\n",
      "Epoch 731/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4005 - acc: 0.8275 - val_loss: 0.5247 - val_acc: 0.7778\n",
      "Epoch 732/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4005 - acc: 0.8275 - val_loss: 0.5248 - val_acc: 0.7778\n",
      "Epoch 733/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4005 - acc: 0.8275 - val_loss: 0.5246 - val_acc: 0.7778\n",
      "Epoch 734/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4005 - acc: 0.8275 - val_loss: 0.5247 - val_acc: 0.7778\n",
      "Epoch 735/900\n",
      "429/429 [==============================] - 0s 117us/step - loss: 0.4004 - acc: 0.8275 - val_loss: 0.5247 - val_acc: 0.7778\n",
      "Epoch 736/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.3522 - acc: 0.843 - 0s 117us/step - loss: 0.4004 - acc: 0.8275 - val_loss: 0.5248 - val_acc: 0.7778\n",
      "Epoch 737/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4003 - acc: 0.8275 - val_loss: 0.5249 - val_acc: 0.7778\n",
      "Epoch 738/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4004 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7778\n",
      "Epoch 739/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4003 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7778\n",
      "Epoch 740/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4003 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7778\n",
      "Epoch 741/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4003 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7778\n",
      "Epoch 742/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.4003 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7778\n",
      "Epoch 743/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4002 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7778\n",
      "Epoch 744/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4002 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7778\n",
      "Epoch 745/900\n",
      "429/429 [==============================] - 0s 111us/step - loss: 0.4002 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7778\n",
      "Epoch 746/900\n",
      "429/429 [==============================] - 0s 108us/step - loss: 0.4001 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7778\n",
      "Epoch 747/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4001 - acc: 0.8275 - val_loss: 0.5250 - val_acc: 0.7778\n",
      "Epoch 748/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.4001 - acc: 0.8275 - val_loss: 0.5250 - val_acc: 0.7778\n",
      "Epoch 749/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.4001 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7778\n",
      "Epoch 750/900\n",
      "429/429 [==============================] - 0s 128us/step - loss: 0.4000 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7778\n",
      "Epoch 751/900\n",
      "429/429 [==============================] - 0s 117us/step - loss: 0.4001 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7778\n",
      "Epoch 752/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.4000 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7778\n",
      "Epoch 753/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4000 - acc: 0.8275 - val_loss: 0.5250 - val_acc: 0.7778\n",
      "Epoch 754/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.4000 - acc: 0.8275 - val_loss: 0.5250 - val_acc: 0.7778\n",
      "Epoch 755/900\n",
      "429/429 [==============================] - 0s 99us/step - loss: 0.3999 - acc: 0.8275 - val_loss: 0.5250 - val_acc: 0.7778\n",
      "Epoch 756/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.3999 - acc: 0.8275 - val_loss: 0.5250 - val_acc: 0.7778\n",
      "Epoch 757/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.3999 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7778\n",
      "Epoch 758/900\n",
      "429/429 [==============================] - 0s 104us/step - loss: 0.3999 - acc: 0.8275 - val_loss: 0.5253 - val_acc: 0.7778\n",
      "Epoch 759/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.3998 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7778\n",
      "Epoch 760/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.3998 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7778\n",
      "Epoch 761/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.3998 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 762/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.4275 - acc: 0.750 - 0s 107us/step - loss: 0.3997 - acc: 0.8275 - val_loss: 0.5255 - val_acc: 0.7778\n",
      "Epoch 763/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.3997 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 764/900\n",
      "429/429 [==============================] - 0s 111us/step - loss: 0.3997 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 765/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.3997 - acc: 0.8275 - val_loss: 0.5255 - val_acc: 0.7778\n",
      "Epoch 766/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.3996 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 767/900\n",
      "429/429 [==============================] - 0s 106us/step - loss: 0.3996 - acc: 0.8275 - val_loss: 0.5255 - val_acc: 0.7778\n",
      "Epoch 768/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.3996 - acc: 0.8275 - val_loss: 0.5256 - val_acc: 0.7778\n",
      "Epoch 769/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3995 - acc: 0.8275 - val_loss: 0.5255 - val_acc: 0.7778\n",
      "Epoch 770/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.3995 - acc: 0.8275 - val_loss: 0.5253 - val_acc: 0.7778\n",
      "Epoch 771/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.3995 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 772/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3995 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 773/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.3994 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 774/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3994 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7778\n",
      "Epoch 775/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.3994 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 776/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.3994 - acc: 0.8275 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 777/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.3994 - acc: 0.8275 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 778/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.3994 - acc: 0.8275 - val_loss: 0.5255 - val_acc: 0.7778\n",
      "Epoch 779/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.3993 - acc: 0.8275 - val_loss: 0.5253 - val_acc: 0.7778\n",
      "Epoch 780/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.3993 - acc: 0.8275 - val_loss: 0.5255 - val_acc: 0.7778\n",
      "Epoch 781/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.3993 - acc: 0.8275 - val_loss: 0.5255 - val_acc: 0.7778\n",
      "Epoch 782/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3992 - acc: 0.8275 - val_loss: 0.5256 - val_acc: 0.7778\n",
      "Epoch 783/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.3992 - acc: 0.8275 - val_loss: 0.5255 - val_acc: 0.7778\n",
      "Epoch 784/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3992 - acc: 0.8275 - val_loss: 0.5256 - val_acc: 0.7778\n",
      "Epoch 785/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.3992 - acc: 0.8275 - val_loss: 0.5256 - val_acc: 0.7778\n",
      "Epoch 786/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.3991 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7778\n",
      "Epoch 787/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3991 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 788/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.3991 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 789/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.3991 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 790/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.3990 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 791/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3991 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 792/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.3990 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 793/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.3990 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 794/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3989 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 795/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.3989 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 796/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.3989 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 797/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.3989 - acc: 0.8275 - val_loss: 0.5250 - val_acc: 0.7685\n",
      "Epoch 798/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.3989 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 799/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.3988 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 800/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3988 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 801/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.3988 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 802/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.3988 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 803/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.3987 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 804/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.3987 - acc: 0.8275 - val_loss: 0.5250 - val_acc: 0.7685\n",
      "Epoch 805/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.3987 - acc: 0.8298 - val_loss: 0.5249 - val_acc: 0.7685\n",
      "Epoch 806/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3987 - acc: 0.8275 - val_loss: 0.5248 - val_acc: 0.7685\n",
      "Epoch 807/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.3986 - acc: 0.8298 - val_loss: 0.5249 - val_acc: 0.7685\n",
      "Epoch 808/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.3986 - acc: 0.8298 - val_loss: 0.5248 - val_acc: 0.7685\n",
      "Epoch 809/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.3986 - acc: 0.8298 - val_loss: 0.5250 - val_acc: 0.7685\n",
      "Epoch 810/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.3986 - acc: 0.8275 - val_loss: 0.5250 - val_acc: 0.7685\n",
      "Epoch 811/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.3986 - acc: 0.8298 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 812/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.3986 - acc: 0.8298 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 813/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.3985 - acc: 0.8298 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 814/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.3985 - acc: 0.8298 - val_loss: 0.5250 - val_acc: 0.7685\n",
      "Epoch 815/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3985 - acc: 0.8298 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 816/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3984 - acc: 0.8298 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 817/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.3984 - acc: 0.8298 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 818/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.3984 - acc: 0.8298 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 819/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.3983 - acc: 0.8298 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 820/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3983 - acc: 0.8298 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 821/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.3983 - acc: 0.8298 - val_loss: 0.5256 - val_acc: 0.7685\n",
      "Epoch 822/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.3983 - acc: 0.8298 - val_loss: 0.5255 - val_acc: 0.7685\n",
      "Epoch 823/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.3982 - acc: 0.8275 - val_loss: 0.5256 - val_acc: 0.7685\n",
      "Epoch 824/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.3982 - acc: 0.8298 - val_loss: 0.5257 - val_acc: 0.7685\n",
      "Epoch 825/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.3982 - acc: 0.8298 - val_loss: 0.5256 - val_acc: 0.7685\n",
      "Epoch 826/900\n",
      "429/429 [==============================] - 0s 110us/step - loss: 0.3982 - acc: 0.8298 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 827/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3982 - acc: 0.8298 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 828/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.3981 - acc: 0.8298 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 829/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.3981 - acc: 0.8298 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 830/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.3981 - acc: 0.8298 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 831/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.3981 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 832/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.3980 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 833/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.3980 - acc: 0.8298 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 834/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.3980 - acc: 0.8298 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 835/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.3980 - acc: 0.8298 - val_loss: 0.5255 - val_acc: 0.7685\n",
      "Epoch 836/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.3979 - acc: 0.8298 - val_loss: 0.5256 - val_acc: 0.7685\n",
      "Epoch 837/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 75us/step - loss: 0.3979 - acc: 0.8298 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 838/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.3979 - acc: 0.8298 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 839/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.3978 - acc: 0.8298 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 840/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.3978 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 841/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.3978 - acc: 0.8298 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 842/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.3977 - acc: 0.8275 - val_loss: 0.5255 - val_acc: 0.7685\n",
      "Epoch 843/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.3977 - acc: 0.8298 - val_loss: 0.5257 - val_acc: 0.7685\n",
      "Epoch 844/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.3977 - acc: 0.8298 - val_loss: 0.5257 - val_acc: 0.7685\n",
      "Epoch 845/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.3977 - acc: 0.8298 - val_loss: 0.5258 - val_acc: 0.7685\n",
      "Epoch 846/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.3976 - acc: 0.8298 - val_loss: 0.5259 - val_acc: 0.7685\n",
      "Epoch 847/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.3976 - acc: 0.8298 - val_loss: 0.5258 - val_acc: 0.7685\n",
      "Epoch 848/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.3976 - acc: 0.8298 - val_loss: 0.5258 - val_acc: 0.7685\n",
      "Epoch 849/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.3976 - acc: 0.8298 - val_loss: 0.5255 - val_acc: 0.7685\n",
      "Epoch 850/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.3975 - acc: 0.8298 - val_loss: 0.5255 - val_acc: 0.7685\n",
      "Epoch 851/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.3976 - acc: 0.8298 - val_loss: 0.5255 - val_acc: 0.7685\n",
      "Epoch 852/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3975 - acc: 0.8298 - val_loss: 0.5256 - val_acc: 0.7685\n",
      "Epoch 853/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3975 - acc: 0.8275 - val_loss: 0.5256 - val_acc: 0.7685\n",
      "Epoch 854/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.3975 - acc: 0.8298 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 855/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3974 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 856/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.3974 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 857/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.3974 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 858/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.3974 - acc: 0.8275 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 859/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.3973 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 860/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.3973 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 861/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.3974 - acc: 0.8275 - val_loss: 0.5255 - val_acc: 0.7685\n",
      "Epoch 862/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.3973 - acc: 0.8275 - val_loss: 0.5255 - val_acc: 0.7685\n",
      "Epoch 863/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.3972 - acc: 0.8275 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 864/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.3973 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 865/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.3972 - acc: 0.8275 - val_loss: 0.5248 - val_acc: 0.7685\n",
      "Epoch 866/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.5211 - acc: 0.812 - 0s 86us/step - loss: 0.3972 - acc: 0.8275 - val_loss: 0.5248 - val_acc: 0.7685\n",
      "Epoch 867/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.3971 - acc: 0.8252 - val_loss: 0.5250 - val_acc: 0.7685\n",
      "Epoch 868/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.3971 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 869/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.3971 - acc: 0.8275 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 870/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.3971 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 871/900\n",
      "429/429 [==============================] - 0s 82us/step - loss: 0.3971 - acc: 0.8275 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 872/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.3970 - acc: 0.8275 - val_loss: 0.5252 - val_acc: 0.7685\n",
      "Epoch 873/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.3970 - acc: 0.8275 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 874/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.3969 - acc: 0.8252 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 875/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.3970 - acc: 0.8275 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 876/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.3969 - acc: 0.8275 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 877/900\n",
      "429/429 [==============================] - 0s 107us/step - loss: 0.3969 - acc: 0.8275 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 878/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.3968 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 879/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.3969 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 880/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.3968 - acc: 0.8275 - val_loss: 0.5251 - val_acc: 0.7685\n",
      "Epoch 881/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.3968 - acc: 0.8252 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 882/900\n",
      "429/429 [==============================] - 0s 105us/step - loss: 0.3968 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 883/900\n",
      "429/429 [==============================] - 0s 119us/step - loss: 0.3967 - acc: 0.8275 - val_loss: 0.5253 - val_acc: 0.7685\n",
      "Epoch 884/900\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.3967 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 885/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.3967 - acc: 0.8275 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 886/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.3967 - acc: 0.8252 - val_loss: 0.5255 - val_acc: 0.7685\n",
      "Epoch 887/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.3966 - acc: 0.8275 - val_loss: 0.5255 - val_acc: 0.7685\n",
      "Epoch 888/900\n",
      "429/429 [==============================] - 0s 100us/step - loss: 0.3966 - acc: 0.8275 - val_loss: 0.5257 - val_acc: 0.7685\n",
      "Epoch 889/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.3966 - acc: 0.8275 - val_loss: 0.5258 - val_acc: 0.7685\n",
      "Epoch 890/900\n",
      "429/429 [==============================] - 0s 112us/step - loss: 0.3966 - acc: 0.8252 - val_loss: 0.5256 - val_acc: 0.7685\n",
      "Epoch 891/900\n",
      "429/429 [==============================] - 0s 96us/step - loss: 0.3965 - acc: 0.8275 - val_loss: 0.5256 - val_acc: 0.7685\n",
      "Epoch 892/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.3965 - acc: 0.8252 - val_loss: 0.5257 - val_acc: 0.7685\n",
      "Epoch 893/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.3965 - acc: 0.8252 - val_loss: 0.5257 - val_acc: 0.7685\n",
      "Epoch 894/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.3964 - acc: 0.8252 - val_loss: 0.5257 - val_acc: 0.7685\n",
      "Epoch 895/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.3964 - acc: 0.8252 - val_loss: 0.5257 - val_acc: 0.7685\n",
      "Epoch 896/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.3964 - acc: 0.8252 - val_loss: 0.5257 - val_acc: 0.7685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/900\n",
      "429/429 [==============================] - 0s 79us/step - loss: 0.3964 - acc: 0.8252 - val_loss: 0.5255 - val_acc: 0.7685\n",
      "Epoch 898/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.3963 - acc: 0.8252 - val_loss: 0.5256 - val_acc: 0.7685\n",
      "Epoch 899/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.3963 - acc: 0.8252 - val_loss: 0.5254 - val_acc: 0.7685\n",
      "Epoch 900/900\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.2815 - acc: 0.906 - 0s 100us/step - loss: 0.3963 - acc: 0.8252 - val_loss: 0.5253 - val_acc: 0.7685\n"
     ]
    }
   ],
   "source": [
    "#fitting and compiling the model with SGD optimizer\n",
    "nn_model.compile(SGD(lr = 0.005), 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = nn_model.fit(x_train_nn, y_train_nn, validation_data = (x_val, y_val), epochs = 900, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_predict = nn_model.predict_classes(X_test)\n",
    "nn_proba_predict = nn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets take a look\n",
    "nn_predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3149966 ],\n",
       "       [0.45327353],\n",
       "       [0.7358982 ],\n",
       "       [0.70846164],\n",
       "       [0.66553164],\n",
       "       [0.01756994],\n",
       "       [0.6503652 ],\n",
       "       [0.05534679],\n",
       "       [0.00500213],\n",
       "       [0.3886146 ]], dtype=float32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_proba_predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Neural network is 0.740\n",
      "The roc-auc for the Neural network is 0.821\n"
     ]
    }
   ],
   "source": [
    "accuracy_nn = accuracy_score(y_test,nn_predict)\n",
    "\n",
    "print('The accuracy for the Neural network is {:.3f}'.format(accuracy_nn))\n",
    "print('The roc-auc for the Neural network is {:.3f}'.format(roc_auc_score(y_test,nn_proba_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets take a look at the run history\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can use the history to plot the training loss and the validation loss over the different epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x4786eb5978>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD3CAYAAAAALt/WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xl8U1Xex/FPkpu2SdOVlrKWvbWy\ndSqCKKBYEdQHx3FBXNAZUcHH/cEZFRfAqQjjLCoC6ojoIOMLd8URERCtoKJTqFgGCwiFYStLC226\n0NzkPn+Epg1d0iVtepPf+/Wal8m9WU5/E745Offccw2apmkIIYTQLWOgGyCEEKJ1JMiFEELnJMiF\nEELnJMiFEELnJMiFEELnlPZ+w6NHS1v83Lg4K8XF5X5sjb5JPbxJPWpILbwFQz0SE6Ma3KerHrmi\nmALdhA5F6uFN6lFDauEt2OuhqyAXQghRlwS5EELonAS5EELonAS5EELonAS5EELonAS5EELonH6C\n3G6HTZvc/xVCCOGhjyC324m/aCScdx5x4y+SMBdCiFra/czOllDyt2Pat9d9e+cOlPztqOecG+BW\nCSH8YcGCv5Gfv52iouNUVlbSrVt3YmPjyMqa7/O5O3fms2FDNr/73R0+H/v007PJzLyU88473x/N\n7lB0EeRqahquuHiMxUU4e/RETU0LdJOECG12u7tDlZoGNlurXureex8E4NNPV7J3bwF33XVvk587\nYEAqAwaktur9g4EughybjYqpdxL553mUZs1r9QdHCFG/yNmPE77yw8Yf5HJhLDyMQVXRFAVXUhcw\nNjxKe2riVZTNzmp2WzZv/jeLFy/AbDZz5ZW/ITw8nPfff4fqi5plZf2J3bt38dFH7zFnzjNMnvwb\nBg8eyr59e4mPjycr60+YTHVPzVdVlWeemcOBAwdwOp1MnnwTmZmX8v7777Bq1ScYjUaGDEnn7rvv\n56uvvuDNN99AURS6du3G44/PwdjI3xooHa9FDdDi4gAwOF0BbokQIc7hwKCqAO7/Ohxt9lZVVVUs\nWvQqEyZcwX//u49nn32eF198heTkXnz//bdejz148AC33z6dl19eyokTxWzf/p96X/Ojj94jJiaW\nl156jeefX8Tf/76YEydO8OmnK7n//od4+eWldOvWHVVVWbNmNddffyOLFy/h3HNHUFZW1mZ/a2vo\no0cOaJHuXrihTA50CtFWymZn+e492+3Ejb8IZecO1AEpFK/+ss1+JScn9/LcjouLJytrFlarlb17\nCxg0aIjXY2NiYklK6gJA585JVFWdqvc1CwoKGDZsOABWayS9e/fhwIH9zJz5JG+99SYvvbSAgQMH\nA+5hn2XLXufDD9+jV6/ejBlzURv8la2nmx65yyZBLkSHYLNRvPpLileta9MQBzAaDQDY7XaWLHmZ\nOXPm8vDDjxMeHs6Z1403GAxNes3evXuzdesWAMrLy/jll1/o1q0bH3/8IQ899CgvvvgKO3fm89NP\nP/Lxxx8wdeqdvPjiK2iaRnb2l379+/xFNz1yIiMBMO3Id08/lHFyIQLHZmvXmWORkZEMHjyU2267\nGYvFQlRUFMeOHaVr127Nfq0rr7ya+fOzuOuuqZw6dYrbbruDuLh4+vXrzx133EJsbByJiYmcffYg\nysrKeOCBu4mJicFqtXL++aPa4K9rPYN25tdaG2vphSWU9V8Qd/1VAG3+c04vEhOjWnWhjmAj9agh\ntfAWDPUIigtLGI8Wem5XzyUXQgihoyA/kdqXTd3BHubukctcciGEcNPFGLndYefi3KkU3AGpZRZW\n3f4vbCE+rCKEENV00SPPL9pOQdk+9+3ICvKr9gW4RUII0XHoIshT49OIC48HILkijNR4GVYRQohq\nughym9nGHUOmA/Dspjhs9c/zF0KIkKSLIAfoZHRPvXEeK5SlbIUIInfffQc5OT94bXvuuT+zsoE1\nXw4dOsidd/4WgFmzHsVxxhIB3333DU8/PbvB9zt16pTntT/9dCUbNnzV4rZv3vxvZs16tMXP9xfd\nBHnssRIASsJl+qEQgWZ32Mkp/AG7o/Udqiuv/A2fffYvz32Hw8HGjV9zySXjfT53zpxnMJvNzXq/\noqLjniC//PKJjBp1YfMa3AHpYtYKQGSvs+AX+KkznEjrL9MPhWgDs795nJW/NL76oUtzUVh+GNWl\nohgVkqxdMBoa7hNO7HcVs89veP2Wiy7K5JVXFlFZWUlERARff/0Vw4ePwGKxsGVLDkuX/h2AyspK\nHn98jldwX3vtRJYvf5dDhw7yzDNPERFhwWKJICoqGoD33lvBV1+tx2DQCA+38PTTz/KPf7xGQcEe\nli79Oy6Xi06dOnHVVdeyYMHf2Lo1F4Bx4yYwadINPP30bMxmM4cPH+L48WPMnDmb1NSz6v07Pv98\nFW+//RZms5mePZP5wx8e4+DBA8ydOwdFUTCZTDz++BwUxcysWY/icrlwOlUeemgm/fr1b7Tmvuim\nR65Y3UMrC0fA8DvAHh7gBgkRohwuB6rLvfqh6lJxuFq3+mF4eDijR19IdvZ6AD799GOuvPJqAPbs\n2c2TT/6RF154iVGjxrB+/dp6X+PVVxdz++3TeP75RZ7FtFwuFydPnuS55xbxz3/+E1VV2b59G7fc\nchu9e/fxuhjFxo1fc+jQQV555XUWL17CmjWf8csvuwDo0qUrf/3ri1xzzfV8/PH79b7/yZMnWLLk\nZV54YTGLFy/BZrPx0Ufv8cMPm0hNPYvnnlvELbfcRmlpCdu3byMy0sZf/vIC99//e8r8sH6Ubnrk\nxyuOeW7vLNlFftF2zkmSqwQJ4U+zz89qtPcM7mGV8e9cxM4TOxgQm8Lq677EZm7deR0TJ/6GhQuf\nJyNjGKWlpZ5eb2JiIs899ywWi5WjR48wePDQep+/Z89u0tIGATB4cDp79xZgNBoxm83Mnv0YcXHR\nHDlyBPX08rtn2rt3D0OHpmMwGFAUhYEDB1NQsBvAc+GKzp2T+OmnH+t9/sGDB+jTpy9Wq3tNqKFD\nM/jhh++4997/Y/nyN5gx414iI21Mm3Y35513Pvv37+ORR2agKAq33jq15YU7TTc98kEJNUtWDojq\nK1MQhQgQm9nG6uu+ZNU16/wS4gD9+vWnoqKMt99+iyuuuNKzff78LGbOnMVjj80mISGxwecnJ/cm\nL28rAD//vA2AXbt2kp39JU899QxPPPEEmua+loHBYPTcrtarVx/PsIqqquTlbaVHj+TTj/e9qmLX\nrt0pKNhDRUUFALm5m+nZM5kNG75i6NBf8fzzixk7NpPly99gy5YcOnVK4G9/W8itt07l5ZcXNrVM\nDdJNj7xLpHud4TF7YNnNL2Hxw4dHCNEyNrPN77+Ir7jiShYufIH33vvEs238+Mu5887fEhUVRVxc\nJ44dO1rvc2fMeIRZsx7lrbeWERsbS1hYOD169MRisTB16hSs1gg6dUrg2LGjDBw4GIdDZdGiFwgP\nd4/RXnDBaLZsyWHatN/hcDi4+OJLGhwLr09sbCy33TaN++6bhsFgpEePnkyffg/Hjh3lqaeewGQy\nYTQauffe/6NLly48+eRM3n77LYxGY5OuN+qLblY/dJQU0/3NXozdA2vWJ1P05Xey+mEQrOjmT1KP\nGlILb8FQj6BY/dCycxeWKjhkg4rD+2T6oRBCnKabID/RN5kqBX5OhHPvUjjRNznQTRJCiA7BZ5C7\nXC6efPJJrr/+eqZMmcLevXu99i9ZsoSrr76aa665hjVr1rRZQ/Or9uE83dqf41RZOEsIIU7zebBz\n7dq1VFVVsWLFCnJzc5k3bx6LFy8GoKSkhGXLlvH5559TUVHBVVddxbhx49qkoanxaURgphIHKcYk\nmbUihBCn+eyR5+TkMHr0aADS09PJy8vz7LNYLHTr1o2KigoqKiqafPHTlrCZbZwXmQLAuoNXyMJZ\nQghxms8eud1u97qIg8lkQlVVFMX91K5du3LFFVfgdDqZNm2azzeMi7OiKKYWNTba5J5sr771Gj2+\n/AZ++EFmrjRyJDsUST1qSC28BXM9fAa5zWajrKzMc9/lcnlCPDs7myNHjrBu3ToApk6dSkZGBkOG\nDKn3tQCKi8tb1FC7w85XpT8BcMmtkPvSzzg2fN+uV/LuaIJhSpU/ST1qSC28BUM9WjX9MCMjg+zs\nbAByc3NJSUnx7IuJiSEiIoKwsDDCw8OJioqipKTED02uK79oOyc191lTv8TDjxk9ZeEsIYSgCT3y\ncePGsXHjRiZPnoymacydO5elS5eSnJxMZmYm33zzDZMmTcJoNJKRkcEFF1zQJg1NjU8jISKeY5VF\n9KwMp9sbX4T8sIoQQoCOzuwE+Md/XuShL2fy2vY0/mfBJj+2Sp+C4eeiP0k9akgtvAVDPYLizE6A\nLnE9AaiwF8sVgoQQ4jRdBXm8wQpAnnYY8xVjJMyFEAKdBXnEfw8BsHg4jLx4F5X/2RzgFgkhRODp\nKsiPJ0V7bv+cCNsaXp5YCCFChq6CfFi/0Z7bA6L7kdojI4CtEUKIjkFXQd4jugcAGQfh88wP/XJl\nEiGE0DtdBbliVIh2KpSEg/HIoUA3RwghOgRdBbm96DAVqOzqBOP/dTn24sJAN0kIIQJOV0G+7Yd/\n4Ti93tbPsSq7tq4ObIOEEKID0FWQDzz3CqwO9+3UYhP9h4wPbIOEEKID0FWQ2+K7cGH42QAs7fwA\ntrikALdICCECT1dBbq+y8w0FANxY8YqMkQshBDoL8m1HtnHS5V7PvEAp5eCtF8tp+kKIkKerIB/Y\neSCJBvcKYN1LYOjm/6Lkbw9wq4QQIrB0FeS2MBuPpT0AwHV5oPbrLxeXEEKEPF0FOUB81wEAPHc+\nDL8T7OEBbpAQQgSY7oK8lErP7Z0nd5FfJEMrQojQprsgHxY10HP7rJNhpIYlB7A1QggReLoL8t4H\n3LNUUo/C+leqiN29L8AtEkKIwNJdkJf174vRBfmJMPZOMyf6So9cCBHadBfk+VX7cJ1u9c8xDvKr\npEcuhAhtugvy1Pg0LC73ylkDIpJJjZfph0KI0Ka7ILedgjEF7tvvL6vEdiqgzRFCiIDTXZBX/mcz\nm7o6Afh15hG5ALMQIuTpLsi3JcIJi/v27ni5ALMQQuguyFN7ZNDZGANAV9VCamxqgFskhBCBpbsg\nt5ltPN31DgB+vbmCuKsukxUQhRAhTXdBDtD1lALAS8Nh5MW7ZJxcCBHSdBnkxb27e27/nCjj5EKI\n0KbLIB8x8ArQ3Lf72XqT2iMjsA0SQogA0mWQK1VOTKeD3HTwANjLAtsgIYQIIF0G+a6tq3GebvmO\naAe7tq4ObIOEECKAdBnk/YeMx1rlvt3vpEL/IeMD2yAhhAggXQY5tkgUo3u9FUdSItgiA9wgIYQI\nHF0Gef7+zZQo7tP091UeIn+/TD8UQoQuxdcDXC4Xs2fPJj8/n7CwMLKysujVqxcA27dvZ+7cuZ7H\n5ubmsnDhQsaMGdN2LQYGHoWupXAoCjqVQe/DFdCnTd9SCCE6LJ898rVr11JVVcWKFSuYMWMG8+bN\n8+xLS0tj2bJlLFu2jBtvvJFLL720zUMcIOLsDP62wX2a/vFIuHL3o9gdcnanECI0+eyR5+TkMHr0\naADS09PJy8ur85jy8nIWLFjAm2++6fMN4+KsKIqpBU11S0yMgsQozLdPhQN/BdwXYT7i2kefxBEt\nfl29SkyMCnQTOhSpRw2phbdgrofPILfb7dhsNs99k8mEqqooSs1T3333XSZMmEB8fLzPNywuLm9h\nU93/Rxw9WgpAeuxw2A8YIOWkmc7lnTz7QkXtegipR21SC2/BUI/Gvoh8Dq3YbDbKympOuHG5XF4h\nDrBy5Uquu+66VjSx+cLtFSiu03ccDpSd+e36/kII0VH4DPKMjAyys7MB98HMlJQUr/2lpaVUVVXR\ntWvXtmlhA35KiUE9PUKzI0HWWxFChC6fQyvjxo1j48aNTJ48GU3TmDt3LkuXLiU5OZnMzEz27NlD\n9+7dfb2M36X2Po+oU1AaDsnWHrLeihAiZPkMcqPRyFNPPeW1rV+/fp7bQ4YMYdGiRf5vmS/2Mszu\nqeS4jh52r7cSZ2v8OUIIEYR0eUIQuNdbKbK6b++PVPlpy8eBbZAQQgSIboO8/5DxdC+puf9/BxfK\nXHIhREjSbZDbzJHM/9riuf9LyW7yi7YHsEVCCBEYug1yJX87Y/9T4bnAhNmg0CMqObCNEkKIANBt\nkKupaRT06wQG932HprK/dF9gGyWEEAGg2yDHZqPnjL9iO+W+26dEITVMeuRCiNCj3yDH3fiw01MQ\nHZoqZ3cKIUKSroP8p9S4mimIMfDvuIrANkgIIQJA10GeGpdG8oma+7/f9LBMQRRChBxdB3ns7n0s\n/qTmvkxBFEKEIl0HuZqaRnqJtWYKotEsUxCFECFH10EOsDfeVDMF0eWQKYhCiJCj6yBX8rfT57+l\nGE+vS65gkh65ECLk6DrI1dQ0dvdPxHX6r1BxsrNYpiAKIUKLroMcm40ejy+mV1HNpt+vv09mrggh\nQoq+gxyIMll4dWXNfZm5IoQINboPcnVACgOP4Jm5oiCLZwkhQovug1zZv4+fE/DMXFFRZZxcCBFS\ndB/kamoamtXita1ClVP1hRChQ/dBDjCsyELPWqfqP75BTtUXQoQO3Qe5kr+d6MIiFtU6VX/Pyd3k\nHtkcuEYJIUQ70n2Qq6lpOLv3qPOHyPCKECJU6D7IsdkonfdnLGqgGyKEEIGh/yAHHOnnMOwg9JBx\nciFECAqKIFf27yOqCq8lbWWcXAgRKoIiyNUeyWhGo4yTCyFCUlAEubJ/HwaXS8bJhRAhKSiCXE1N\nw9mlK+cexGsBLRknF0KEgqAIcmw27FnPYKuCRZ/WbJZxciFEKAiOIAeqRpxfvW6Wl+LKonq2CiFE\n8AiaIFf2/xcD1Bknf3zDIzK8IoQIakET5NUzV849CN1P1mw/VHZQhleEEEEtaIK8euaKrQqeX+W9\nT4ZXhBDBLGiCXE1Nw9nTfUGJ+ErvfTK8IoQIZj6D3OVy8eSTT3L99dczZcoU9u7d67X/q6++YtKk\nSUyaNInZs2ejafUdcmwHNhslz70I4B5eqXW6vgyvCCGCmc8gX7t2LVVVVaxYsYIZM2Ywb948zz67\n3c6zzz7LSy+9xNtvv0337t0pLi5u0wY3Rk1JQwNsVfDc5977DtkPBqRNQgjR1nwGeU5ODqNHjwYg\nPT2dvLw8z74tW7aQkpLC/PnzufHGG0lISCA+Pr7tWuuDsjO/+opvdCr33nffurvYc3J3u7dJCCHa\nmuLrAXa7HZvN5rlvMplQVRVFUSguLmbTpk18+OGHWK1WbrrpJtLT0+nTp0+DrxcXZ0VRTC1ucGJi\nVMM7Y62em+cehM6mWI443WMsTpxM/PBSfrnvF2xhtoZeQXcarUcIknrUkFp4C+Z6+Axym81GWVmZ\n577L5UJR3E+LjY1l8ODBJCYmAjBs2DC2b9/eaJAXF5c3uM+XxMQojh4tbfgBvc8irkdPlP3/xVYF\n2W/bSLvmJNrpU4WOlB3h462fMa7X+Ba3oSPxWY8QI/WoIbXwFgz1aOyLyOfQSkZGBtnZ2QDk5uaS\nkpLi2Tdo0CB27NhBUVERqqry448/0r9/fz80uYVsNkrn/8VzN/Wn/Szs/qDXQ2asv09msAghgorP\nHvm4cePYuHEjkydPRtM05s6dy9KlS0lOTiYzM5MZM2Zw++23AzBhwgSvoA8Ii9XrbvewBK/7h8sP\n8e3BjUHTKxdCCIPWzvMFW/Pzpkk/jwoLSRh6FgaXE81opODrDYzccDWFFYc9D+lsSeK7m7dgM+t7\nrDwYfi76k9SjhtTCWzDUo1VDK3rjPsPTCYDB5SJ50iT+et6zXo85UlHIqt2f1Pd0IYTQnaALcjU1\nDbVbd89904H9jD4SQacI7yGWe9ZNk+mIQoigEHRBjs1G6bPPeW8yWfj0mrVe2zQ0Ln83Uw58CiF0\nL/iCHFCHpKMZ3XPVNaMRtXsP+sT0ZWHm370ed/zUcRliEULoXlAG+Znj5PFX/w/Y7VzW9wriwzt5\nPVaGWIQQeheUQV7fOLmSuxmb2caqa9d5PVZDY9zbYygsL2zvZgohhF8EZZBjs1H6x2e8t1VUANQ7\nxFLiKOH85edIz1wIoUvBGeQAcQ0v3lXfEEupo4Tzlv+KbcfyGniWEEJ0TEEb5Gp6BmpyL8/9qMcf\nBrt7hkr1EIvBs1aim4bG2LfP59+Hvm/XtgohRGsEbZBjs1H6zJ89d5U9u1G+3ei53yemL19M2ljf\nM7n8g0tYsvUVmZoohNCF4A1yAIvF6270Q/d7euUAAxMGsemmXKLN0XWe+uiGhxjyeqoMtQghOryg\nDnI1PQNnYmfPfdOhgyi53pd86xPTl4035ZAQkVjn+XZHKWPfPp/pn0+VA6FCiA4rqIMcm42SeX/2\n3lZcVOdhSdYkvp/yI3NHPVtnH8D7u95hxPJ0bv/sVlb+8pEMuQghOpTgDnKoM3sl+vFHvIZXqtnM\nNm4fMo1Pf7O2zr5qH+/+gKmrpzDotQH86ftnZO65EKJDCPogV9MzUDsnee6bDh30Ouh5pmFdh/PT\nb3cyfci9DT6m3FnGn//9DINfH8BvP72JB7+4R3rqQoiACb71yOuhrPyQuKm3eO47u3Sl6JscsDW+\nHvmek7uZ910WH/zybpPex2K0cEnv8VgUCwPiUpicdjNJ1iTfT2yhYFhj2Z+kHjWkFt6CoR6NrUce\nGkG+IZu4q//Ha1vx+5+gjhrTpOfvObmbv3w/n7d3vtXs976890TClXAAzEazXwM+GD6c/iT1qCG1\n8BYM9Qj5IMduJ27kr1AKa8a0i5f8A3XiVc16mcLyQt7a/iY/Hd3Kyt0fNL8dtVzcYxwxEdFQ66Sk\n5gZ9MHw4/UnqUUNq4S0Y6iFBDihrVhN303We+86kLhR9u9nn8EpD9pzczeLNCyisKGRVgf+Xwh3V\ndQzRETGEm8LgjDNQAWLCY3j84keJdnau++QQFQz/WP1FauEtGOohQQ7uXvnwoSjHjno2taRXXp/q\nnvqu4p1UqOWs27uGcmdZq1+3KUZ0HkknayfMJjNGg6nOfrPRTKeIBI5XHsdqtnBX+r30ienbLm1r\nb8Hwj9VfpBbegqEeEuSnhS9+kehZMz33nQkJFH2/tcW98obYHXbW71vLFwVrKXeWA6C61HYN+Mac\nmzCcGEssYaZwTEYTitFEfb3+2qyKlYt7jWNscmaHvWh1MPxj9RephbdgqIcEebXCQhKGpmJwuTyb\nipe/gzpufMtfsxnqC/jaKtXKNhmm8ScFhYzO52AxW4m3dKK8qgwNUIxKnS8FDa3OwmS+mI1mukZ2\nI97SiatTrmvWQeFg+MfqL1ILb8FQDwnyWpR3VhB39x2e+02ditheqsfeTzpONvgYe5WdNfs+a8dW\nBc7QTulYTBaMRhMmo4LZaEYxKigmBbNRwWAwYDh9OoQlLIyKqqo6r1F7eMlsVDr8Lwt/CIbg8qdg\nqIcEeS31TkVsx165v+w5uZulP79E4cljjT6uOsQKSgpYVbCynVrX8ZkJ4/xuFxChRGA0GDEYjDhd\nKmGmMBSTgq+hJvD+gnC46n6BxITHBOyYRDAElz8FQz0kyGuz24kbmYFSeNizydk5iaLvtnSYXnlT\nNbceTent10cPQz4d2fDO5xEXEUeYEnF66Klhvr4cmurMXye1j3EcLT/CG3mv0S92AIfKDnLy1Alu\nHzKtWV84heWF/OuXj+kZnczIbhc06ddN7c9fdXuGdz2P/aX76BGVzNajuWwp3Mwh+0Giw6JbXYPa\nLGFhqKrml9rW1pz/v1p7nEmC/AxnTkUEKF74Cup1k1v92u2pPXsZtWfmOFxVfguc+qwrWEOJ2rwv\nG9E0Rky4cNa7b0indGLCY4kKi8JggEr1FE6XilNzoWkuXJoLl8uJ6nLy72M1F1+xGK2M7jEGAwaq\nXA4cLgcWxYIRA05cOF1O7JWl/HBsU3v9mR1a7+g+fHH9xmaHuQT5mex24s4dgnK8ZlhCMxo59mM+\nJLXdKfX+Fgw/F+vj66BwQ3yNke+372/1iVxC+MOqa9ZxTtK5zXqOBHl99uwmYcSvMFDz55fMnMWp\nB2b45/XbQbAGeUs1pR5n/rJojcZ+lYTSAWnRPNIj93NwnTmDRTMaOfbtZuijjxNmJMi9dbR6tOSY\nRFuMkasulS/2rqXM2TFW5xzTbSzZB9c3uD/SZGPyWTdR6iiVMfJaJMgbYrcTN2wwStFxzyZnp04U\n/fCTLg58drTgCjSpR40za1F7uMqsmJmUcgNbj/1Iz+hkukV2542fljTrC8eqWMlIOpfjlcewV9k5\nXHbIZ5DVnsVT/cto78kCosOiKakqoZutG+lJGU0+eNocwfDZkCBvhLLyI+KmTvHappcDn8Hw4fQn\nqUcNqYW3YKhHY0Ee9BeW8EUdm4ka38lrW+zdd8I2ueiyEEIfQj7IsdkoXrUOzVBzAogBSLj4Atgj\nF1wWQnR8EuQAffpy4sVXvDYZNI34yzPrvb6nEEJ0JIqvB7hcLmbPnk1+fj5hYWFkZWXRq1cvz/6s\nrCw2b95MZGQkAIsWLSIqquGxnI5KvewK1M5JKEdqLj5hOn4c5YN3Uaf8NnANE0IIH3wG+dq1a6mq\nqmLFihXk5uYyb948Fi9e7Nm/bds2Xn31VeLj4xt5FR2w2Shet4H4C87BVFLi2Rw74z6O9e4Doy8M\nYOOEEKJhPodWcnJyGD16NADp6enk5dUcBHS5XOzdu5cnn3ySyZMn8+67TbtIcYeVlETRmuy64+XX\nTIR/f9/w84QQIoB89sjtdju2WnOqTSYTqqqiKArl5eXcfPPN/O53v8PpdHLLLbcwaNAgzjrrrAZf\nLy7OiqI0vnBQYxqbguMXiUPhm29g5EjPJgOQePkl8OOPMGRI275/M7V5PXRG6lFDauEtmOvhM8ht\nNhtlZTVXtXG5XCiK+2kWi4VbbrkFi8UCwHnnncfPP//caJAXFzd97Ywztdtc0H4D4b2VJFwz0Wsx\nU23oUI6t/wYGDmr7NjRBMMyN9SepRw2phbdgqEer5pFnZGSQnZ0NQG5uLikpKZ59BQUF3HjjjTid\nThwOB5s3b2bgwIF+aHIHMPrGZj7xAAANDElEQVRCTvx1gdcmA5Aw9nwZZhFCdCg+e+Tjxo1j48aN\nTJ48GU3TmDt3LkuXLiU5OZnMzEwmTpzIpEmTMJvN/PrXv2bAgAHt0e52oV51Deq8LK+ZLAYg4fJL\nOPbeSjkAKoToEEL+FH2fCguJHzMCU3GR12YNKL1/Bqdunx6wpW+D4eeiP0k9akgtvAVDPeQU/dZI\nSqIoexPOhESvzQYg+vm/kDA0VU7nF0IElAR5UyQlUfT9jxTPfZYzf74YXC4Sxp6P8uYbchaoECIg\nJMibymZDvX0axz5dWzfMgbj/u5e4jIGyPosQot1JkDfXsOEc25SLMzq6zi7lRDEJI9JlVosQol1J\nkLdEn74UbcypM24ONbNawmc9BoWFdZ8rhBB+JkHeUtXj5n95od6hlujFC0gYPEDGzoUQbU6CvDVs\nNtQpv3UPtcTVXTTMM3Y+RGa2CCHajgS5P/TpS1FOXr2zWgAUeykJY8/HOn2qHAwVQvidBLm/VM9q\nWf8NrnrWYzcAke+/Q8KIdBk/F0L4lQS5vw0cxPEf8+sdOwfv8fPwp+dIoAshWk2CvC1Uj53/tJOS\n6fc2HOjP/4WEwQOw3jtdhlyEEC0mQd6WkpI49dTTHNuUS9lvrm0w0CNX/JOEEelYb78VZeVHMstF\nCNEsEuTtoU9fyl9+rcHxczgd6B9/QNzUKcQNGoD1nmkS6kKIJpEgb0/V4+cLX8FV66pLZ1LKy4h8\n+y13qA/sj/XBe2ToRQjRIAny9mazoV43meNbd1C85B+UTbyq3iGXakpFOZHL/+Eeern5eqx/eFBC\nXQjhRdYj7wj27Mb6wl+xfPg+xjLfQykaUH7pZUQmd6d45IWoYzOhkR5+qAjaz0cLSC28BUM9GluP\nXIK8I7HbUdavJeyTj7F+8K7X9UIbo1osnJpwBc6zB3Jq8s0Bu9BFoAX956MZpBbegqEeEuR6VFhI\n+FtvYtqyGeuqlU0OdQ0ov3wixMVRdfG4kOqth9TnwwephbdgqIcEud7t2Y118QI4cADrms+aHOoA\nqsVK+Y1TMDmdVI0O7mGYkP181ENq4S0Y6iFBHkyqQ72wkMhVnzT76WqEhVPjxoPFgnNASlANxcjn\no4bUwlsw1EOCPEglOssoWfASpu3/wbL6U4zlZc1+Dc9QTHg4WK26Ho6Rz0cNqYW3YKhHY0GutGM7\nhL916cKpB2YAUF59oPSLtVBUhHXVJ00agjEAkZ+u9NyPXP4P1PAITl06ARRF9+EuRCiQHrmONVqP\n6oOlewtwKiai3nitWWPrZ1LDwzl16WXucAeIiaH8rnuhT99WvKp/yeejhtTCWzDUQ4ZWglSz6lEd\n7Lt2QkU5lnVrWjQUU5sGlI8bD7ZaH7AABrx8PmpILbwFQz1kaEW4F/A6PQwDZwzFlJdDZWWTh2Oq\nGYDINavrbLe+voSK0RehJSTUbDSbg+7gqhAdhfTIdczv9ajda3dUtSjcfdGA8sxLITrae4cfevLy\n+aghtfAWDPWQHrlomjN67QDlZ4Y7tCrgDUDkus/r3Wd9fQkVo0bjTDkLo72s5v1AevRCNEJ65DoW\n0HrUF/B2e7NPWGouDagYMxYtLhaMJq99kZ1iZe2Z0+TfirdgqIcc7AxSHbIe1ScsnTxZs01V/XJw\ntamcYeFUXnQxRFoBg7s33ykB0/HjYLV0uNk2baFDfjYCKBjqIUEepHRVjzMPrp6xr6178rVpQOWI\nkbg6JUB4GJz5zkEwjKOrz0Y7CIZ6SJAHqaCqR3VPvry8pvdcPWTTzj36ahpQMWo0WnQshIWBoZ7A\n75SAqaQEZ+/eHSr4g+qz4QfBUA8J8iAVUvVorEcPUFnZorVn/Mkr+Ovr6dfWxvPtQ+qz0QTBUA8J\n8iAl9fDmWXum9gFYqOk5FxQ0a0ngtqYBlcOGo8XEooWHQ5gZwsLr/iKp1owhH/lseAuGekiQBymp\nh7cm1aO+g7G1BWgYpzk0oHLkKLToKLSwsNPLJnh/PUVawiirOOPLrFdvnOkZqCMvCLlZPcHwb0Xm\nkQtRrU9fyv/0t0YfUues14aYzTijo7G9tbxJl+jzFwNg+XaDz8dFNrDdaTZTde4ItPAIMJvRFAXM\nSp3pnE0ii6p1CD575C6Xi9mzZ5Ofn09YWBhZWVn06tWrzmPuvPNOMjMzueGGGxp9Q+mR+4/Uw1vA\n6tHU4K/1+PacpdMenGYzVRnDICwcFBOaSXH/12gCkxFMJjA08VrvtaeLnjm8VL2/mbOKguHfSqt6\n5GvXrqWqqooVK1aQm5vLvHnzWLx4sddjnnvuOU429FNViGBns6FOvAp14lVNfkp5Q0M8DYVYBx/y\nMTkcWDZ9267vqT09h1PnnIsWEeH+NWEyoZnc/8VkRDOc/gIxGiDSglXVGv+CaI4OtvqnzyDPyclh\n9OjRAKSnp5OXl+e1/7PPPsNgMDBmzJgmvWFcnBVFacFPuNMa+1YKRVIPb7qpR+JQGP5q855jt8Pq\n1bBqFVRUNO+5Dge8807zntPBGYCInB+a/PiGhppaKvL1JTBiBHTvDmVloGmnvzhOf4FU31YU922r\nFSZMgPHj/T4M5TPI7XY7tlpvajKZUFUVRVHYsWMHn3zyCS+88AILFy5s0hsWFzfhp2cDguHnkT9J\nPbyFRD3GXOr+nw/11uLJuXWXVWgNVcXyxdp2PT7Q4Wza1LzHv/oqau8+FH+xsdlh3qqhFZvNRllZ\nzc85l8uFcvriAh9++CGFhYXceuutHDhwALPZTPfu3ZvcOxdCtKN6FkVrrSYfGG6OxsbIO/gQU1Mo\nBXtQ8rejnnOu/17T1wMyMjJYv349l19+Obm5uaSkpHj2/eEPf/DcXrBgAQkJCRLiQoSSFhwfaK2W\nfHlEWsIo89cYeSsPVqu9+6CmprX8/evhM8jHjRvHxo0bmTx5MpqmMXfuXJYuXUpycjKZmZl+bYwQ\nQvjUgi+PyMQoyv047Fbe2JISDWnDqZpyQpCOST28ST1qSC28BUM9Ghsjb+LETiGEEB2VBLkQQuic\nBLkQQuicBLkQQuicBLkQQuicBLkQQuhcu08/FEII4V/SIxdCCJ2TIBdCCJ2TIBdCCJ2TIBdCCJ2T\nIBdCCJ2TIBdCCJ2TIBdCCJ3zuR55R+ByuZg9ezb5+fmEhYWRlZVFr169At2sNudwOJg5cyYHDhyg\nqqqKu+66i/79+/PII49gMBgYMGAAs2bNwmg08uKLL/Lll1+iKAozZ85kyJAhgW5+mzl+/DhXX301\nr732GoqihGw9Xn75Zb744gscDgc33HADw4cPD9laOBwOHnnkEQ4cOIDRaOSPf/xjaH02NB1YvXq1\n9vDDD2uapmlbtmzRpk+fHuAWtY93331Xy8rK0jRN04qKirQLL7xQmzZtmvbdd99pmqZpTzzxhPb5\n559reXl52pQpUzSXy6UdOHBAu/rqqwPZ7DZVVVWl/e///q926aWXart27QrZenz33XfatGnTNKfT\nqdntdu2FF14I2VpomqatWbNGu++++zRN07QNGzZo99xzT0jVQxdDKzk5OYwePRqA9PR08vLyAtyi\n9jFhwgTuv/9+z32TycS2bdsYPnw4AGPGjOGbb74hJyeHUaNGYTAY6NatG06nk6KiokA1u03Nnz+f\nyZMn07lzZ4CQrceGDRtISUnh7rvvZvr06Vx00UUhWwuAPn364HQ6cblc2O12FEUJqXroIsjtdju2\nWpdGMplMqKoawBa1j8jISGw2G3a7nfvuu48HHngATdMwGAye/aWlpXXqU7092Lz//vvEx8d7vtSB\nkK1HcXExeXl5PP/888yZM4eHHnooZGsBYLVaOXDgAJdddhlPPPEEU6ZMCal66GKM3GazUVZWc9Vs\nl8uFouii6a126NAh7r77bm688UYmTpzIs88+69lXVlZGdHR0nfqUlZURFdXwZaH06r333sNgMPDt\nt9+yfft2Hn74Ya/eVCjVIzY2lr59+xIWFkbfvn0JDw/n8OHDnv2hVAuA119/nVGjRjFjxgwOHTrE\nrbfeisPh8OwP9nrookeekZFBdnY2ALm5uaSkpAS4Re3j2LFj3Hbbbfz+97/n2muvBeDss89m06ZN\nAGRnZzNs2DAyMjLYsGEDLpeLgwcP4nK5iI+PD2TT28Ty5ct58803WbZsGWlpacyfP58xY8aEZD3O\nOeccvv76azRNo7CwkIqKCkaOHBmStQCIjo72BHJMTAyqqobUvxVdrH5YPWtlx44daJrG3Llz6dev\nX6Cb1eaysrJYtWoVffv29Wx77LHHyMrKwuFw0LdvX7KysjCZTCxYsIDs7GxcLhePPvoow4YNC2DL\n296UKVOYPXs2RqORJ554IiTr8ac//YlNmzahaRoPPvggPXr0CNlalJWVMXPmTI4ePYrD4eCWW25h\n0KBBIVMPXQS5EEKIhuliaEUIIUTDJMiFEELnJMiFEELnJMiFEELnJMiFEELnJMiFEELnJMiFEELn\n/h/pI3O1Mcu5wQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4786ecf4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the training and validation losses over the different epochs\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(history.history['loss'], 'r', marker = '.', label = 'Train loss')\n",
    "\n",
    "ax.plot(history.history['val_loss'], 'g', marker = '.', label = 'Validation loss')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation:\n",
    "Validation loss is stable around 800-1220 epochs\n",
    "Validation loss starts getting worse at 1220 - 1500 epochs\n",
    "training loss still going down\n",
    "\n",
    "Conclusion: The best epoch to used for this model is around 1000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models_Accuracies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log_reg</th>\n",
       "      <td>77.638015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_svc</th>\n",
       "      <td>77.456324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_rbf</th>\n",
       "      <td>75.974843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_forest</th>\n",
       "      <td>75.433263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural_nets</th>\n",
       "      <td>74.025974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Models_Accuracies\n",
       "log_reg                77.638015\n",
       "linear_svc             77.456324\n",
       "svc_rbf                75.974843\n",
       "Random_forest          75.433263\n",
       "Neural_nets            74.025974"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracies = pd.DataFrame(cross_val_df )\n",
    "Accuracies.rename(columns = {\"cross validation means b4 feat_sels(%)\" : \"Models_Accuracies\"}, inplace = True)\n",
    "Accuracies.loc['Neural_nets'] = accuracy_nn*100\n",
    "Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAHtCAYAAAAwQfbGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOBkp3kIIIYST+f/gGjfP+ZgMaAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x478884c400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_probs.append(nn_proba_predict)\n",
    "model_names_all = ['log_reg', 'linear_svc', 'svc_rbf', 'Random_forest', 'Neural nets']\n",
    "plot_multiple_roc(validation_probs, y_test, model_names_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Models with their corresponding Roc_AUC_score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Roc_auc_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random_forest</th>\n",
       "      <td>84.493827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_reg</th>\n",
       "      <td>83.827160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_svc</th>\n",
       "      <td>83.802469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_rbf</th>\n",
       "      <td>82.543210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural_nets</th>\n",
       "      <td>82.090535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Roc_auc_scores\n",
       "Random_forest       84.493827\n",
       "log_reg             83.827160\n",
       "linear_svc          83.802469\n",
       "svc_rbf             82.543210\n",
       "Neural_nets         82.090535"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=200).fit(X_train, y_train)\n",
    "rf_proba_predict = rf_model.predict_proba(X_test)[:,1]\n",
    "rf_auc = roc_auc_score(y_test, rf_proba_predict)\n",
    "\n",
    "rbf_svc = SVC(kernel ='rbf').fit(X_train, y_train)\n",
    "rbf_proba_predict = rbf_svc.decision_function(X_test)\n",
    "rbf_auc = roc_auc_score(y_test, rbf_proba_predict)\n",
    "\n",
    "lin_svc = LinearSVC().fit(X_train, y_train)\n",
    "lsvc_proba_predict = lin_svc.decision_function(X_test)\n",
    "lsvc_auc = roc_auc_score(y_test, lsvc_proba_predict)\n",
    "\n",
    "log_reg = LogisticRegression().fit (X_train, y_train)\n",
    "log_reg_proba_predict = log_reg.predict_proba(X_test)[:,1]\n",
    "log_reg_auc = roc_auc_score(y_test, log_reg_proba_predict)\n",
    "\n",
    "nn_auc = roc_auc_score(y_test, nn_proba_predict)\n",
    "\n",
    "AUCROC_scores = [log_reg_auc*100, lsvc_auc*100, rbf_auc*100, rf_auc*100, nn_auc*100]\n",
    "labels = ['log_reg', 'linear_svc', 'svc_rbf', 'Random_forest', 'Neural_nets']\n",
    "\n",
    "\n",
    "RocAuc_score = pd.Series(AUCROC_scores, index = labels).sort_values(ascending=False).to_frame()\n",
    "RocAuc_score.rename(columns = {0: 'Roc_auc_scores'}, inplace = True)\n",
    "print('\\nModels with their corresponding Roc_AUC_score')\n",
    "RocAuc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation and Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the correlation between each columns and the the outcome column(those with diabetes- We used it up, it is calles diabetic_patients). This will help us pick the best 4 features in the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BMI                         1.0\n",
       "BloodPressure               1.0\n",
       "Glucose                     1.0\n",
       "Insulin                     1.0\n",
       "SkinThickness               1.0\n",
       "Age                         1.0\n",
       "DiabetesPedigreeFunction    1.0\n",
       "Pregnancies                 1.0\n",
       "Outcome                     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetic_patients = diabetes[diabetes['Outcome']==1]\n",
    "non_diabetics = list(diabetes.columns[:-1])\n",
    "correlations = diabetes[non_diabetics].corrwith(diabetic_patients)\n",
    "correlations.sort_values(inplace= True)\n",
    "\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAFoCAYAAACmMNenAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3XlcVPXiPvBn2HEABQXTBFECdzQ0\nt5ISNb3mVsamYq65XExcMVFSQVwI85ahmcZV3IDSSs38hpqUuSRdQS2VCEETZQxUZkAGmPP7gx8T\nk8tBgjmHeN6v131d5hyYz6MkD+d8zvkchSAIAoiIiB7DROoAREQkfywLIiISxbIgIiJRLAsiIhLF\nsiAiIlEsCyIiEiVJWaSlpSEoKOiB7UePHsXo0aPh7++PxMREAMD9+/cxa9YsjBkzBlOnTkV+fr6x\n4xIRNXhGL4uPP/4YS5YsQUlJicH20tJSrFq1Cp988gni4+ORkJAAlUqF3bt3w8PDA7t27cKoUaMQ\nGxtr7MhERA2e0cvCxcUFH3zwwQPbMzMz4eLigsaNG8PCwgLdu3fH2bNnkZqain79+gEAvL29cfLk\nSWNHJiJq8MyMPeDgwYNx/fr1B7ar1WrY2trqXyuVSqjVaoPtSqUShYWFomOUlZXDzMxU9POGz/vi\nCZI/2v6YkbXyPgDglzCj1t4r0X9jrbzPiZGja+V9AOD5Lz6rlfdZMW9/rbwPAITHDK+190r9vwW1\n8j7dX46ulfcBgKlf/VQr7/PxUK9aeR+g9v7tAbX370+OmeTE6GXxKDY2NtBoNPrXGo0Gtra2Bts1\nGg3s7OxE36ugoKjOcj6MSiVeYFKQYy5mqh5mqj455jJ2JkdH21oZ09HR9pH7ZHM1lJubG7Kzs3Hn\nzh1otVqcPXsWzz77LLy8vHD8+HEAQEpKCrp37y5xUiKihkfyI4v9+/ejqKgI/v7+WLRoESZPngxB\nEDB69Gg0b94cgYGBCA0NRWBgIMzNzRETEyN1ZCKiBkeSsmjVqpX+0tjhw/88X+zj4wMfHx+Dz7W2\ntsb7779v1HxERGRINqehiIhIvlgWREQkimVBRESiWBZERCSKZUFERKJYFkREJIplQUREolgWREQk\nimVBRESiWBZERCSKZUFERKJYFkREJIplQUREolgWREQkimVBRESiWBZERCSKZUFERKJYFkREJIpl\nQUREooz+DG6dTodly5bh8uXLsLCwQGRkJFq3bg0A+OWXXxAVFaX/3HPnzuHDDz+Ep6cnBg8eDA8P\nDwDAwIED8cYbbxg7OhFRg2X0skhOToZWq0VCQgLOnTuH1atXY+PGjQCADh06ID4+HgBw6NAhODk5\nwdvbGz/88AOGDRuGpUuXGjsuERFBgtNQqamp6NevHwCgW7duuHDhwgOfU1RUhA8++ABhYWEAgAsX\nLuDixYsYN24c3nrrLeTl5Rk1MxFRQ2f0Iwu1Wg0bGxv9a1NTU5SVlcHM7M8on376KYYMGQIHBwcA\nQNu2bdG5c2f07dsXX375JSIjI/H+++8/cgx7+0YwMzOtuz/EXzg62hptrCdRW7mu1Mq7VJDj31Vt\nZsqppff5p/891SY55pIiU12PafSysLGxgUaj0b/W6XQGRQEA+/fvNyiD3r17w9raGgAwaNCgxxYF\nABQUFNViYnEqVaFRx6suOeZipuphpuqTYy5jZ3J0tK2VMR9XOEY/DeXl5YWUlBQAFRPYlZPWlQoL\nC6HVatGiRQv9tiVLluDw4cMAgJMnT6JTp07GC0xERMY/shg0aBBOnDiBgIAACIKAqKgoxMXFwcXF\nBQMGDEBWVhaefvppg6+ZN28eFi9ejN27d8Pa2hqRkZHGjk1E1KAZvSxMTEywYsUKg21ubm76jz09\nPREbG2uw39nZWX+VFBERGR9vyiMiIlEsCyIiEsWyICIiUSwLIiISxbIgIiJRLAsiIhLFsiAiIlEs\nCyIiEsWyICIiUSwLIiISxbIgIiJRLAsiIhLFsiAiIlEsCyIiEsWyICIiUSwLIiISxbIgIiJRLAsi\nIhLFsiAiIlEsCyIiEmVm7AF1Oh2WLVuGy5cvw8LCApGRkWjdurV+f2RkJH766ScolUoAQGxsLEpL\nSzF//nzcv38fTk5OWLVqFaytrY0dnYiowTL6kUVycjK0Wi0SEhIwb948rF692mD/xYsXsWXLFsTH\nxyM+Ph62traIjY3FsGHDsGvXLnTs2BEJCQnGjk1E1KAZ/cgiNTUV/fr1AwB069YNFy5c0O/T6XTI\nzs5GeHg4bt++jddffx2vv/46UlNTMW3aNACAt7c31q1bhwkTJjxyDHv7RjAzM63TP0dVjo62Rhvr\nSdRWriu18i4V5Ph3VZuZcmrpff7pf0+1SY65pMhU12MavSzUajVsbGz0r01NTVFWVgYzMzMUFRVh\n3LhxmDhxIsrLyzF+/Hh07twZarUatrYVfxFKpRKFhYWPHaOgoKhO/wx/pVI9Po9U5JiLmaqHmapP\njrmMncnR0bZWxnxc4Ri9LGxsbKDRaPSvdTodzMwqYlhbW2P8+PH6+YjevXvj0qVL+q+xsrKCRqOB\nnZ2dsWMTETVoRp+z8PLyQkpKCgDg3Llz8PDw0O+7evUqxowZg/LycpSWluKnn35Cp06d4OXlhePH\njwMAUlJS0L17d2PHJiJq0Ix+ZDFo0CCcOHECAQEBEAQBUVFRiIuLg4uLCwYMGIDhw4fDz88P5ubm\nGDlyJNzd3TFjxgyEhoYiMTER9vb2iImJMXZsIqIGzehlYWJighUrVhhsc3Nz0388depUTJ061WB/\ns2bNsHXrVqPkIyKiB/GmPCIiEsWyICIiUSwLIiISxbIgIiJRohPcP//8MzZt2oS7d+9CEAT99u3b\nt9dpMCIikg/RsggNDYW/vz/c3d2hUCiMkYmIiGRGtCysrKwwbtw4Y2QhIiKZEi2LF154AfHx8Xjh\nhRdgaWmp396yZcs6DUZERPIhWhZffPEFACAuLk6/TaFQ4MiRI3WXioiIZEW0LI4ePWqMHEREJGOi\nl87m5+cjJCQEvXr1Qo8ePRAcHIzbt28bIxsREcmEaFmEh4ejS5cuOHLkCI4ePYquXbsiLCzMGNmI\niEgmRMvi2rVrmDx5MmxsbGBnZ4epU6fixo0bxshGREQyIVoWCoUCubm5+tc3btzQP6yIiIgaBtGf\n+rNnz4a/vz+6du0KQRCQlpaGiIgIY2QjIiKZEC2L/v37o2vXrkhPT4dOp8Py5cvRtGlTY2QjIiKZ\neGRZJCQkwN/fHxs2bDDY/vPPPwMAgoOD6zYZERHJxiPnLKouGkhERA3bI48sAgICAABPP/00Xn31\nVYN9O3furNtUREQkK48si//+979Qq9XYs2cPfv/9d/328vJy7N+/H2PHjn3iwXQ6HZYtW4bLly/D\nwsICkZGRaN26tcGYBw8eBAC8+OKLCA4OhiAI8Pb2hqurKwCgW7dumDdv3hOPTURENffIsnB1dcWF\nCxce2G5hYYHVq1fXaLDk5GRotVokJCTg3LlzWL16NTZu3Aig4n6OL7/8EklJSVAoFBgzZgwGDhwI\na2trdOrUCZs2barRmERE9Pc9sixeeuklvPTSS/jXv/4FNzc3g33379+v0WCpqano168fgIojhKpl\n9NRTT2HLli0wNTUFAJSVlcHS0hIXL17ErVu3EBQUBCsrK7z99tto27ZtjcYnIqKaEb10Njs7GyEh\nISguLoYgCNDpdCguLsapU6eeeDC1Wg0bGxv9a1NTU5SVlcHMzAzm5uZwcHCAIAhYu3YtOnbsiDZt\n2uD27dt488038a9//Qtnz57FggUL8Nlnnz12HHv7RjAzM33ifDXl6GhrtLGeRG3lulIr71JBjn9X\ntZkpp5be55/+91Sb5JhLikx1PaZoWaxatQoRERGIi4vD9OnTkZycjOLi4hoNZmNjA41Go3+t0+kM\n7gYvKSnB4sWLoVQq8c477wAAOnfurD/a6NGjB27dugVBEB771L6CgqIa5asplarQqONVlxxzMVP1\nMFP1yTGXsTM5OtrWypiPKxzR5T5sbW3Ru3dvdO3aFYWFhViwYEGNjioAwMvLCykpKQCAc+fOwcPD\nQ79PEATMnDkT7dq1w4oVK/QFsWHDBmzbtg0AcOnSJbRs2ZKPdyUiMrJqPVY1KysLbm5uOHPmDHr3\n7o3S0tIaDTZo0CCcOHECAQEBEAQBUVFRiIuLg4uLC3Q6Hc6cOQOtVovvvvsOADB37ly8+eabWLBg\nAY4fPw5TU1OsWrWqRmMTEVHNiZZFSEgI1q9fj+joaGzevBkJCQkYPXp0jQYzMTHBihUrDLZVnTw/\nf/78Q79u8+bNNRqPiIhqh2hZ9OzZEz179gQAfPbZZ7h79y4aN25c58GIiEg+HlkWQUFBj50b2L59\ne50EIiIi+XlkWcyaNcuYOYiISMYeeTVU5emnnj17wtTUFJmZmejWrRsUCoX+tBQRETUMopfObtu2\nDevXr8d///tfaDQahIeHY+vWrcbIRkREMiFaFvv27cPWrVthbW0Ne3t7fPrpp6J3UBMR0T+LaFmY\nmJjAwsJC/9rS0lJ/wxwRETUM1bp0ds2aNSguLkZycjISEhLQu3dvY2QjIiKZED2yWLhwIVq3bo12\n7drh888/x4svvojQ0FBjZCMiIpkQPbKYOnUqtm7dqn9yHhERNTyiRxbFxcXIzc01RhYiIpIp0SOL\n/Px8+Pj4oGnTprC0tNQvD37kyBFj5CMiIhkQLYu1a9eiadOmxshCREQyJVoWoaGhOHTokDGyEBGR\nTImWRfv27fH555/D09MTVlZW+u0tW7as02BERCQfomWRlpaGtLQ0g22csyAialhEy+Lo0aPGyEFE\nRDImeulsfn4+QkJC0KtXL/To0QPBwcG4ffu2MbIREZFMiJZFeHg4unTpgiNHjuDo0aPo2rUrwsLC\njJGNiIhkQrQsrl27hsmTJ8PGxgZ2dnaYOnUqbty4UeMBdTodwsPD4e/vj6CgIGRnZxvsT0xMxGuv\nvQY/Pz8cO3YMQMXRzaRJkzBmzBiEhISguLi4xuMTEdGTEy0LhUJhcAf3jRs3YGYmOtXxSMnJydBq\ntUhISMC8efOwevVq/T6VSoX4+Hjs2bMHW7duxbp166DVahEbG4thw4Zh165d6NixIxISEmo8PhER\nPTnRn/qzZ8+Gv78/unbtCkEQkJaWhoiIiBoPmJqain79+gEAunXrhgsXLuj3paen49lnn4WFhQUs\nLCzg4uKCS5cuITU1FdOmTQMAeHt7Y926dZgwYUKNMxAR0ZMRLYv+/fuja9euSE9Ph06nw4oVK+Dg\n4FDjAdVqNWxsbPSvTU1NUVZWBjMzM6jVatja2ur3KZVKqNVqg+1KpRKFhYWPHcPevhHMzMSfubE/\nZmQN/xR1J9F/o9QRHuD4hfwedhUeM1zqCA/l+HK01BEe8PFQL6kjPECO//bkmOlJODrain/S3yBa\nFqdOncL69euxZ88e/Pbbb/D19UV0dDS8vGr2H6CNjQ00Go3+tU6n05/W+us+jUYDW1tb/XYrKyto\nNBrY2dk9doyCgqIaZXsYR0dbqFSPLydjY6bqk2MuZqoeZqq+2sr1uMIRnbNYs2YNVqxYAQBo27Yt\nNm/ejJUrV9Y4jJeXF1JSUgAA586dg4eHh36fp6cnUlNTUVJSgsLCQmRmZsLDwwNeXl44fvw4ACAl\nJQXdu3ev8fhERPTkRI8sSkpKDH6gu7m5oaysrMYDDho0CCdOnEBAQAAEQUBUVBTi4uLg4uKCAQMG\nICgoCGPGjIEgCJgzZw4sLS0xY8YMhIaGIjExEfb29oiJianx+ERE9OREy6Jt27aIjo7GyJEjoVAo\ncODAAbi6utZ4QBMTE/2RSiU3Nzf9x35+fvDz8zPY36xZM2zdurXGYxIR0d8jehpq5cqVKC4uxrx5\n87Bw4UIUFxcjMjLSGNmIiEgmRI8sGjdujPDwcGNkISIimRI9siAiImJZEBGRKJYFERGJEp2z2Lt3\nL9asWYN79+4BAARBgEKhwC+//FLn4YiISB5EyyI2Nhbx8fEG91oQEVHDInoaysnJiUVBRNTAiR5Z\ndOrUCW+99Raef/55WFpa6rePGjWqToMREZF8iJaFWq2GUqnEuXPnDLazLIiIGg7Rsli1ahVKS0uR\nlZWF8vJyuLu7/62HHxERUf0j+lP/woULeOutt9CkSRPodDrcvn0bH374Ibp27WqMfEREJAOiZREZ\nGYn33ntPXw7nzp1DREQEPv300zoPR0RE8iB6NVRRUZHBUUS3bt1QUlJSp6GIiEheRMuicePGSE5O\n1r9OTk5GkyZN6jQUERHJi+hpqIiICCxYsABhYWEAAGdnZ6xdu7bOgxERkXyIloWrqyuSkpJQVFQE\nnU4HoOJZ2URE1HCInoY6duwYoqOjIQgCfH19MWDAAOzdu9cY2YiISCZEy2LDhg0YPnw4vvrqK3h6\neuLo0aPYsWOHMbIREZFMVOvuuvbt2+ODDz7AiBEjoFQqUVpaWqPB7t+/jwULFuCPP/6AUqnEmjVr\n4ODgYPA5a9aswU8//YSysjL4+/vDz88Pd+7cweDBg/VrVA0cOBBvvPFGjTIQEdGTEy2LZs2aISIi\nAhcuXEB0dDRWr16Nli1b1miw3bt3w8PDA7NmzcLBgwcRGxuLJUuW6PefOnUKOTk5SEhIgFarxSuv\nvILBgwfj559/xrBhw7B06dIajUtERH+P6GmoZcuWoUuXLti+fTsaNWoEZ2dnxMTE1Giw1NRU9OvX\nDwDg7e2NkydPGux/9tlnERUVpX9dXl4OMzMzXLhwARcvXsS4cePw1ltvIS8vr0bjExFRzSgEQRAe\n9wn/+te/cOjQoSd+46SkJGzbts1gW9OmTREeHg43NzfodDq89NJLSElJeeBrS0tLERoainbt2mHa\ntGlITk5Go0aN0LdvX3z55ZdITk7G+++//8ixy8rKYWZm+sSZiYjo4URPQ7Vv3x6ff/45PD09YWVl\npd8udirK19cXvr6+BtuCg4Oh0WgAABqNBnZ2dg983d27d/HWW2+hZ8+emDZtGgCgd+/esLa2BgAM\nGjTosUUBAAUFRWJ/rGpzdLSFSlVYa+9XG5ip+uSYi5mqh5mqr7ZyOTraPnKfaFmkpaUhLS3NYJtC\nocCRI0eeOIiXlxeOHz8OT09PpKSkoHv37gb779+/jwkTJmDixIkYMWKEfvuSJUvw8ssvY+jQoTh5\n8iQ6der0xGMTEVHNiZ6Gqk3FxcUIDQ2FSqWCubk5YmJi4OjoiLVr12LIkCH46aefsGHDBnTo0EH/\nNZVzGIsXLwYAWFtbIzIyEk5OTo8cpzabX46/STBT9ckxFzNVDzNVnzGOLETL4urVq9ixYweKioog\nCAJ0Oh2uX7+OnTt3/u1gdYVlYXxyzATIMxczVQ8zVZ8xykL0aqi5c+fCzs4Ov/zyCzp06IAbN27A\n3d39b4ciIqL6Q3TOorS0FG+99RbKysrQsWNH+Pn5YfTo0cbIRkREMiF6ZGFtbQ2tVgtXV1dcvHjR\n4IooIiJqGETLYsSIEZg+fTpeeukl7NixA1OmTEHz5s2NkY2IiGRC9DTUuHHjMGrUKNjY2CA+Ph7n\nz5/H888/b4xsREQkE6JHFlqtFjt27MDChQthY2ODy5cvw8ysWusPEhHRP4RoWaxYsQJFRUX4+eef\nYWpqipycHP09D0RE1DCIlsXFixcxd+5cmJmZwdraGmvWrMGlS5eMkY2IiGRCtCwUCgW0Wi0UCgUA\noKCgQP8xERE1DKKTD+PHj8fEiROhUqmwcuVKJCcn49///rcxshERkUyIlsWoUaPQuXNnnD59Gjqd\nDhs3bkT79u2NkY2IiGSiWndwf//99zh16hTMzMxgaWmJdu3a8VQUEVEDIloWS5Yswf379+Hn5wed\nTocvvvgCGRkZCAsLM0Y+IiKSgWo9z+Lrr7/Wv/bx8cGwYcPqNBQREcmL6NVQrVq1QnZ2tv717du3\nudwHEVEDI3pkUVZWhpEjR6JHjx4wMzNDamoqHB0dMX78eADA9u3b6zwkERFJS7QsZs6cafB60qRJ\ndRaGiIjkSbQsevbsaYwcREQkY6JzFkREREZdPvb+/ftYsGAB/vjjDyiVSqxZswYODg4GnzN9+nTc\nuXMH5ubmsLS0xJYtW5CdnY1FixZBoVDA3d0d77zzDkxM2HNERMZi1J+4u3fvhoeHB3bt2oVRo0Yh\nNjb2gc/JycnB7t27ER8fjy1btgAAVq1ahZCQEOzatQuCIODIkSPGjE1E1OAZtSxSU1PRr18/AIC3\ntzdOnjxpsP/27du4d+8epk+fjsDAQBw7dgxAxcq3lXMn3t7e+OGHH4wZm4iowauz01BJSUnYtm2b\nwbamTZvC1tYWAKBUKlFYWGiwv7S0FJMmTcL48eNx9+5dBAYGwtPTE4Ig6JcXedjX/ZW9fSOYmZnW\n2p/F0dG21t6rtjBT9ckxFzNVDzNVX13nqrOy8PX1ha+vr8G24OBgaDQaAIBGo4GdnZ3B/mbNmiEg\nIABmZmZo2rQpOnTogKysLIP5iYd93V8VFBTV0p+i4hugUj2+nIyNmapPjrmYqXqYqfpqK9fjCseo\np6G8vLxw/PhxAEBKSgq6d+9usP+HH35ASEgIgIpSyMjIQNu2bdGxY0ecPn1a/3U9evQwZmwiogbP\nqGURGBiIjIwMBAYGIiEhAcHBwQCAtWvXIj09HS+++CJat24NPz8/TJ48GXPnzoWDgwNCQ0PxwQcf\nwN/fH6WlpRg8eLAxYxMRNXgKQRAEqUPUtto8TJTjYSczVZ8cczFT9TBT9f3jTkMREVH9xLIgIiJR\nLAsiIhLFsiAiIlEsCyIiEsWyICIiUSwLIiISxbIgIiJRLAsiIhLFsiAiIlEsCyIiEsWyICIiUSwL\nIiISxbIgIiJRLAsiIhLFsiAiIlEsCyIiEsWyICIiUSwLIiISZWbMwe7fv48FCxbgjz/+gFKpxJo1\na+Dg4KDfn5KSgo8//hgAIAgCUlNTceDAAdy/fx/Tp0+Hq6srACAwMBBDhw41ZnQiogbNqGWxe/du\neHh4YNasWTh48CBiY2OxZMkS/X5vb294e3sDALZs2QIvLy+4ubkhKSkJEydOxKRJk4wZl4iI/j+j\nnoZKTU1Fv379AFQUw8mTJx/6eTdv3sQXX3yB4OBgAMCFCxfw7bffYuzYsVi8eDHUarXRMhMRUR0e\nWSQlJWHbtm0G25o2bQpbW1sAgFKpRGFh4UO/Ni4uDhMmTICFhQUAwNPTE76+vujcuTM2btyIDz/8\nEKGhoY8c296+EczMTGvpTwI4OtrW2nvVFmaqPjnmYqbqYabqq+tcdVYWvr6+8PX1NdgWHBwMjUYD\nANBoNLCzs3vg63Q6Hb799lvMmTNHv23QoEH6zx00aBAiIiIeO3ZBQdHfja/n6GgLlerhpSYVZqo+\nOeZipuphpuqrrVyPKxyjnoby8vLC8ePHAVRMZnfv3v2Bz7ly5QratGkDKysr/bbJkycjPT0dAHDy\n5El06tTJOIGJiAiAkSe4AwMDERoaisDAQJibmyMmJgYAsHbtWgwZMgSenp7IysqCs7OzwdctW7YM\nERERMDc3R7NmzUSPLIiIqHYpBEEQpA5R22rzMFGOh53MVH1yzMVM1cNM1fePOw1FRET1E8uCiIhE\nsSyIiEgUy4KIiESxLIiISBTLgoiIRLEsiIhIFMuCiIhEsSyIiEgUy4KIiESxLIiISBTLgoiIRLEs\niIhIFMuCiIhEsSyIiEgUy4KIiESxLIiISBTLgoiIRLEsiIhIFMuCiIhESVIW33zzDebNm/fQfYmJ\niXjttdfg5+eHY8eOAQDy8/MxadIkjBkzBiEhISguLjZmXCKiBs/oZREZGYmYmBjodLoH9qlUKsTH\nx2PPnj3YunUr1q1bB61Wi9jYWAwbNgy7du1Cx44dkZCQYOzYREQNmtHLwsvLC8uWLXvovvT0dDz7\n7LOwsLCAra0tXFxccOnSJaSmpqJfv34AAG9vb/zwww9GTExERGZ19cZJSUnYtm2bwbaoqCgMHToU\np0+ffujXqNVq2Nra6l8rlUqo1WqD7UqlEoWFhY8d29HR9rH7n1Rtv19tYKbqk2MuZqoeZqq+us5V\nZ2Xh6+sLX1/fJ/oaGxsbaDQa/WuNRgNbW1v9disrK2g0GtjZ2dV2XCIiegxZXQ3l6emJ1NRUlJSU\noLCwEJmZmfDw8ICXlxeOHz8OAEhJSUH37t0lTkpE1LDU2ZHFk4iLi4OLiwsGDBiAoKAgjBkzBoIg\nYM6cObC0tMSMGTMQGhqKxMRE2NvbIyYmRurIREQNikIQBEHqEEREJG+yOg1FRETyxLIgIiJRLAsi\nIhLFsiBqwK5evYrjx4/j5s2b4PQlPY4sroai6ikvL8fevXuRm5uLXr16wd3dHQ4ODpJmOnnyJK5d\nuwZPT0+0adMGlpaWkuYBKm7uTElJgVar1W8bNWqUhIkq6HQ6CIKA//3vf/D09ISFhYWkeXbs2IFv\nvvkGd+/exahRo5CTk4Pw8HBJMwFAbm4uDhw4gJKSEv224OBgCRNVUKvVUCgU+Oabb9C/f380btxY\n6ki4evUqsrOz0a5dOzRv3hwKhaLOxmJZVOHv7//AX7YgCFAoFNizZ49Eqf4UHh4OJycn/PDDD+jc\nuTNCQ0Px8ccfS5Zn3bp1uHnzJjIzM2Fubo7Nmzdj3bp1kuWpNHPmTDg5OaFFixYAUKf/gKorOjoa\nzs7OuHHjBi5evIhmzZphzZo1kmY6ePAgdu3ahfHjx2PChAkYPXq0pHkqzZ49G3369NF//+Rg4cKF\neP755/G///0POp0O33zzDT788ENJMxm77FkWVcjhB93j5OTkYOXKlUhNTYWPjw82b94saZ7U1FTs\n3LkTQUFBePXVV7F7925J81QSBAHvvvuu1DEMpKamYsGCBQgKCkJ8fDzeeOMNqSPpTztVlqnURzqV\nlEol5syZI3UMA7///jtGjhyJTz/9VDbfP2OXPcuiihs3bjxy39NPP23EJA9XXl6O/Px8ABWHxCYm\n0k45lZeXo6SkBAqFAuXl5ZLnqdSuXTukpaWhQ4cO+m1S/yDU6XRIT09Hq1atoNVq9d9HKb3yyisY\nO3Ysbty4galTp2LgwIFSRwJmRbpQAAAdFUlEQVQAuLu74+DBg+jQoYO+yNq0aSNpptLSUnz11Vd4\n5plnkJ+fjzt37kiaBzB+2fOmvCrat28PFxcXdOnSBYDhN0MOd43/+OOPWLJkCVQqFVq0aIGwsDD0\n7dtXsjyHDh3Chg0bkJ+fjxYtWmDChAkYMWKEZHkqjRgxAmq1Wv9aoVDgyJEjEiYCdu7cic8//xxR\nUVFITEyEh4fHE6+dVhcyMzNx5coVtG3bFu3atZM6DgAgKCjI4LVCocD27dslSlPh//7v//DVV19h\n0aJFSEhIgKenJ/r37y9pph07duCrr77CjRs34O7ujt69e2Py5Ml1Nh7LooqLFy/iwIEDuHjxInr3\n7o3hw4fD2dlZ6lh6X375JUaMGIH8/HzY29vL4lz83bt3kZ2dDWdnZ9jb20sdp17Izc2Vxfn4t99+\n2+C1ubk5nnrqKYwdO1byyduCggJcu3YNrVq1kvwijkpZWVnIyckxymRydRmz7FkWDyEIAk6dOoX9\n+/fj9u3b8PHxQUBAgNSxMG7cOOzYsUPqGHo//vgjiouLIQgCIiIiMHv2bAwfPlyyPCtWrEB4ePhD\nL1SQ+gKF7du3w8rKCvfu3cPevXvRr1+/B35YG9vcuXPh7OyMHj16IC0tDefPn0eHDh1w6dIlbNq0\nSbJchw4dwvr16+Hm5oaMjAwEBwdj5MiRkuUBDCeTX331VWRnZ0t+5Vh6ejoOHjxocNXYo54VVCsE\neqji4mJh//79wuTJk4XXXntN6jiCIAiCr6+vMHLkSCEkJESYO3euMHfuXMnzZGdnC5MmTRLy8vKE\nMWPGSJpHpVIJgiAI169ff+B/UvPz8xNKSkqEoKAgQafTCUFBQVJHEt544w2D1xMnThQEQZD8++jn\n5yeo1WpBEAShsLBQFv/+AgICBJ1OJ4wbN04QBEEWmYYMGSJ89tlnwjfffKP/X13iBHcVpaWlSElJ\nwYEDB3D16lX4+PggLCxM8sm1SvPnz5c6ggFLS0s0bdoUZmZmcHR0NLivQQqPO689d+5cIyZ5kEKh\ngEqlQrNmzaBQKHD37l1J8wAVF0lkZmbCzc0NmZmZKCoqQkFBAYqKiiTNpVAooFQqAVQ840YO9+4I\nMrxyrHXr1njttdeMNh7Looq+ffvCyckJr7zyiv6b8Pvvv+P333/HCy+8IHG6x1+tJQUbGxtMnDgR\nY8aMwc6dOyU/Dy+XUn+YXr16Ydy4cYiJiUFUVBRefvllqSMhPDwcCxYsQF5eHqysrPDqq6/iq6++\nwvTp0yXN5eLigtWrV6NHjx44e/YsXFxcJM0DAMOGDZPdlWODBw/GnDlz4Obmpt9Wlzcvcs6iikWL\nFhmc6648F2hpaYlVq1ZJFUuv8oosQRDwyy+/oEmTJpJepaXVapGTk4NnnnkGGRkZaN26tSx+4/rx\nxx8f2Pbcc89JkORBd+/ehbW1tSz+noCK8947duzAiRMnMHjwYMnPwwNAWVkZEhIS9Ec9fn5+MDc3\nlzqWfjK5TZs2aN++vdRx4Ovri0GDBhk8ObQu51ZZFlX89ttvWLt2LVq1aoWXX34Zs2bNAlBx1Ygc\nlouoShAETJs2TdIb827evImoqChkZmbC1dUVb7/9Nlq1aiVZnkqVp5wEQcCvv/6Kp59+WtIJW6Ci\nwJYvX47y8nIMGTIELVu2lOzSWa1Wi4MHD2Lnzp2wsLCAWq1GYmIirKysJMlT6fz58+jSpQu+//77\nB/ZJdWSflJQEX19fxMTEPHDRhNSnNqdMmYItW7YYbTyehqoiLCwMs2bNwp07dzBt2jTs27cPDg4O\nmDJliizKouqcgEqlwvXr1yVMAyxZsgSBgYF47rnncObMGYSFhWHbtm2SZgIM78TXarUICQmRME2F\n9evXY8eOHZg1axamT5+OwMBAycrCx8cHw4YNw7vvvgtXV1dMmTJF8qIAKtYZ69KlCw4ePPjAPqnK\n4qmnngIAtG3bVpLxH8fe3h7h4eHo2LGjvsj8/f3rbDyWRRVmZmb6m9y2b98OV1dXAECjRo0kTPWn\nIUOGQKFQQBAEWFlZ1ekNONVRUlKCAQMGAAAGDhyIuLg4SfM8THl5Oa5duyZ1DJiYmKBJkyZQKBSw\ntLTUT+BKYfz48Thw4AB+//13vP7667JZbfbNN98EAHh5eRkUqZQ35PXr1w9AxXxYeno6xo8fj3nz\n5mHSpEmSZarUunVrAMDt27eNMh7Looqqh5lVzynrdDop4jzg6NGj+o91Op3ky2uUl5fj8uXLaNeu\nHS5fviyLm5QAw99Cy8rKMH78eAnTVHBxcUFMTAzu3LmDzZs3o2XLlpJlefPNN/Hmm2/izJkzSEpK\nwoULFxAdHY2RI0fCw8NDslwHDhzA0aNHcfr0aZw6dQpAxX9jGRkZkn8PIyMjsXr1agBASEgIFi1a\nhJ07d0qaKTg4GN9++y0yMjLQpk2bOp9055xFFX379kWfPn30N+VVfnz69GmcOHFC6ng4dOgQdDod\ntFotoqOjMXnyZEmPLn7++WcsXboUKpUKTk5OiIiIMFiPif5UVlaGpKQkXLlyRT9pK5dJ7nv37uGL\nL77AZ599hs8//1yyHHfv3sWlS5fw0UcfYcaMGRAEASYmJnB2dkbz5s0lywVUTBxXvbGzckFIKcXE\nxCA7OxteXl44e/YsnJ2dERoaWmfjsSyqOHPmzCP39ezZ04hJHs7X1xebN2/G3Llz8dFHH2HSpEmS\n3tGt1Wrx66+/omPHjkhOTsaLL74oi6tW5HZnOVAx2X7+/HmDu23lcoWW3GRnZ+P8+fP6eZWAgADJ\nL5yYO3cuWrVqhW7duiE9PR3Xrl2TfL24qgUmCAL8/PyQlJRUZ+PxNFQVciiEx6m8OUmpVMLCwgIa\njUbSPPPnz0efPn3QsWNHZGVl4dChQ5L/AwIqnh3x7rvvYvny5di9ezdCQkIkL4vg4GAUFBSgRYsW\n+meksCweLjQ0VL9E+YsvviiLCydWrVqF3bt34/jx43jmmWcwc+ZMSfMAFUerlaejK/+bqkssi3qk\nVatWGD16NJYuXYoNGzbA09NT0jy3bt1CYGAgAGDq1KkPrBYqFbndWQ4Af/zxh+TrU9UnvXr1AlBx\n9CWHOUMLCwt4eXmhU6dOAIC0tDTJy37o0KEIDAxE165dkZ6ejqFDh9bpeCyLemT16tXQaDRQKpXo\n0qULmjVrJnUkZGVloU2bNsjJyZHFP2pAfneWAxVX09y6dUvyc+/1gZ2dHRISEvSnfKS8cqzSrFmz\n9Evxy+XIcNKkSXjhhRfw22+/YfTo0Vx1lv4kt3PxaWlpCA8Pxx9//AEnJycsX75c/ywQKVW9s/zK\nlStwdXWVfDL55ZdfxvXr1w2W237YzWcE5OfnY+PGjcjKysIzzzyDN998U/Jlyv86wS0HiYmJ+PXX\nX7F48WJMmjQJI0aMqNP7wVgW9Yifn5/+XPzq1asREhIi+eV7cpSbm4sDBw4YTCbX5Zo5NXHnzh00\nadJE6hiy9ccffxh8/6S81BioWMUhJCREVkeGr776Kvbs2QNLS0uUlpZi3LhxSEhIqLPxeBqqHpHb\nuXgfHx+DSTUbGxt88cUXEiaqMHv2bPTp00cWp58qRUREYOnSpQAqjigiIiJw+PBhiVPJ07Jly5CS\nkgInJyf9KR+pf6v/6aef0L9/f1kdGZqYmOgvejE3N+cEN/1Jbufiv/76awAVl+1duHBB/1pqSqVS\nfzWNXNjY2ODdd99FUVERMjIyjLqmT32Tnp6O5ORkyW86rUqOxT5gwACMGTMGnp6euHjxInx8fOp0\nPJ6GqkfkeC6+qrFjx8ritFhUVBS6du2KDh066H/bksPy5WvWrMGVK1ewdetWqaPI2pw5cxAVFQVr\na2upo+idO3cOe/fuRWlpKQAgLy9P8u9jWVkZMjIykJWVhbZt26Jly5YGK9DWNh5Z1CMFBQXYtGkT\nCgoKMHjwYBQXF6Nr166S5am6EmdeXp5sfhP85ZdfcOnSJYNtUq0v9NcF8G7fvq3fJvVpDLnKzc1F\n//799WsfyeE0VGRkJCZMmIDDhw/Dw8ND0lPAKpUKarUaoaGhWLt2LTp06ACdTodJkybh008/rbNx\nWRb1yNKlSzFx4kTExsaiR48eWLRoERITEyXLU3Ulzvbt2+sXXZNK5bO3/3qwLOWaVVULoaioCI0a\nNeIltCLkcGPnX9nZ2WHYsGE4ceIEZs2ahXHjxkmWJS0tDdu2bUNWVpZ+HszExKTOV+ZlWdQjJSUl\n6NOnDzZu3Ii2bdtK9rjJyh+Ajo6OBtvT0tIkfaJg1aXJ5WbDhg1Qq9VYtGgRVq5cic6dO+tXWSVD\n+/bte2Cb1FezKRQKZGRkoLi4GL/99htUKpVkWQYOHIiBAwfi+PHjePHFF402LsuiHrGwsMB3330H\nnU6Hc+fOSTZfUfV5A5W/Jd+4cQMtW7aUtCyefvppycYWc/ToUezduxcA8P777yMgIIBl8QiVN5sK\ngoCff/5ZFjd7Llq0CBkZGQgKCsL8+fP1KxdI6euvv37gopK6fKIny6IeiYiIwJo1a1BQUIBPPvkE\ny5YtkyTH5MmTsWLFCmzfvh1DhgyBRqPBzZs3JX++hpwpFApotVpYWFigtLRUNs+QkKO/Php0ypQp\nEiX5k7u7O9zd3QFAX/pSq1zeo7JU8/Ly6nQ8lkU9EhcXh/fee0/qGHj33XexYMECABWnouLj45Gd\nnY0lS5bA29tb4nTyFBAQgOHDh8PDwwO//fabLH4AylVWVpb+Y5VKhdzcXAnTVNi0aRO2bNli8ERB\nqS9QqDpH6O3tXecPZGJZ1COZmZm4d+9enV4eVx3FxcX6ZT1sbW0BVDy1q6ysTMpYsubr64sBAwbg\n2rVrcHZ2lnz5CjkLDw/Xf2xlZYWFCxdKmKbCoUOH8N1338nqct6qZZWXl1fnT8xjWdQjmZmZ6N27\nN+zt7fVX+Ejx203VZRhiY2P1H5uZ8T+nv4qNjcXMmTMxd+7cB67KkuNVP1K6efMmnnrqKckfKvQw\nTz/9tCyeU17V/v37cfbsWTz33HOwsrJCVFRUnY7Hf931yLFjx6SOAABwcnJCenq6wRLp6enpD1wd\nRdDfVfvX8/D0oIULF+rvh/noo48wbdo0iRP9qbS0VH8aEaiYg5Kq7DUaDebNm4eCggJ069YNGRkZ\naNq0KVxdXet0XJZFPXDmzBmsXr0aSqUSkZGR+puVpLJgwQLMnDkTvXv3RuvWrXHt2jWcPHkSmzZt\nkjSXHLVv3x5AxUJ4hw8fRnFxsX6f3B+2ZWxVJ/1PnDghq7KYOnWq1BH0YmJiMGTIEIMVZpOSkrB2\n7VqsWLGizsZlWdQD7733HqKjo3Hnzh3ExMTg/ffflzSPs7MzkpKScPToUVy/fh2dO3fG7Nmz0ahR\nI0lzydm8efPQr18/WTyDRK6kvHlSzF8fuWxubo7c3FwMHTrU6I8SvnTpksG8DlAxJ1aXd28DLIt6\nwdzcHG5ubgCADz74QOI0FaysrOr8yVz/JFZWVpLfWCZ3d+7cwYkTJ6DT6XD37l2D+Tgp798BgMuX\nL8PS0hI9evRAWloacnNz4ejoiO+//x7R0dFGzfKouUFTU9O6HbdO351qnRxuUKLqq7wMtFmzZjhw\n4AA6duwoq8UN5aRTp044cOAAAKBjx44GN39KXRb37t3TPwc8ICAAkyZNQnR0tCQ35zVp0gTnz583\neNDY+fPn0bhx4zodl2VRD9y6dQsJCQkQBEH/cSV/f38Jk5GYqqcLqn7fFAqFZIsbytVf7z6+e/cu\n7OzsZHF6qrCwEPn5+XBwcEBBQQEKCwtRWlqK+/fvGz3LwoULMWPGDPTq1QvOzs64fv06Tp48iY0b\nN9bpuFyivB7YsGHDI/fx1Ia8GXv9nn+CH3/8EcuXL0d5eTmGDBmCli1bwtfXV9JMx44dw8qVK2Fj\nY4OioiIsWbIEly5dglKpxNixY42ep6SkBN9++y2uXbuG5s2bY8CAAXU+Z8iyIKpD48eP5xHEExo7\ndiw+/PBDzJo1C1u2bEFgYKAsltjQ6XRQqVRwcnKSxdGOsfE0VD1Qeb62tLQUxcXFaNGiBW7dugUH\nBwccPXpU4nT0OIIgPHItKDk9uEpOTExM0KRJEygUClhaWkKpVEodCWfOnMGKFStkdbRjbCyLeqDy\nqpD58+dj3rx5+rKoyxUmqXakpaVhyJAh+mdJA9B/fOTIEYnTyZOLiwtiYmJQUFCAzZs3o2XLllJH\nwn/+8x/s2LEDs2bNwvTp0xEYGMiyIPm6fv26/rnbzZs3l8UCa/R4Xbt2leXyFXK2fPlyJCUloUeP\nHmjUqBEiIiKkjiTLox1jY1nUI25ubliwYAE8PT3xv//9D927d5c6ElGtUygUMDMzg729Pdzd3aFW\nqyVfeLHyaOfOnTuyOdoxNk5w1yM6nQ4pKSn49ddf0bZtW/26QyRfV65c0a8nRNUTFhYGJycn/PDD\nD5g2bRp2796Njz/+WNJMWq0Wn332Ga5cuYK2bdvC39+/wc058ciiHikqKsLp06fx66+/Ii8vD15e\nXmjSpInUsegxKovixIkTiIuLg1ar1e/jVVIPl5OTg5UrV+Ls2bPw8fHB5s2bpY6E6dOn45NPPpE6\nhqRYFvXI4sWL8dxzz2HEiBE4c+YMFi1axMX76olVq1Zh8eLFeOqpp6SOInvl5eXIz8+HQqGAWq2G\niYmJ1JFga2uL5ORktGnTRp+nod2Bz7KoRwoKChAUFAQA6NChAw4fPixxIqquFi1aoG/fvlLHqBfm\nzJmDwMBAqFQq+Pv7IywsTNI8arUa169f1y/3ATTMO/BZFvVISUkJVCoVHB0dcfv2ba4TVY80bdoU\n4eHhBmtDcamWh8vNzcXhw4eRn59v8KAvKezYsQOffPIJTE1NMXv27Ab92GCWRT0ye/ZsBAQEwMbG\nBhqNRhaXFFL1tGrVCgDq/NGX/wSJiYkYMWKE5FdAAcCBAwfw9ddfQ61WY+HChSwLqh+ef/55fPPN\nNygoKECTJk3qfEli+vsqHxX6yiuvSB2l3tBqtRg1ahTatGkDhUIh6VPpLCwsYGFhAQcHB5SWlkqS\nQS5YFvXIqVOnEBYWBltbW9y7dw8RERF4/vnnpY5FjxEXF4e3334b4eHhD9zB3dDOeVfX/PnzpY7w\nUA39LgPeZ1GPBAYGYv369WjevDlu3bqF4OBgJCUlSR2LqqGwsBC2trb616mpqbyp8hH+usqyubk5\nnnrqKUmeSte3b1/06dMHgiDg1KlT6NOnj36fVEc7UuGRRT1iamqK5s2bA6hY7sPS0lLiRFRdwcHB\n2Lx5M0xNTfGf//wH33//Pfbt2yd1LFmS01Pp1q9fr/84ICDAqGPLDcuiHrGxsUF8fDyee+45/Pjj\nj3X+ZCyqPW+88QZmzpyJe/fu4YUXXkBiYqLUkWRLTk+l69mzp9HHlCvp73ahaouOjsaNGzfw3nvv\nITc3F1FRUVJHIhFZWVnIyspCmzZt0LNnT9jY2GDEiBG4fv261NFkq/KpdAAkfyod/YlzFvVA5XOc\nK1Vd7rqh3UVa3wQFBUGhUOgnR+/duwdTU1PY2NhwgvsR5PZUOqrAsqgHKn/gVCopKQEAWFpa8geO\nzF28eBGLFy9GUlISvv32Wyxbtgy2trZYuHAhBgwYIHU82dLpdMjPz0fTpk0b5FPp5IhzFvXA8uXL\nsXbtWrRq1Qovv/wygoODoVAo8Pbbb0sdjUS89957WLNmDSwsLLB+/Xp8/PHHaN26NaZMmcKy+IsV\nK1YgPDwc/v7+DxTEnj17JEpFlVgW9UBYWBhmzZqFO3fuYNq0adi3bx8cHBwwZcoUjBo1Sup49BiC\nIKB9+/a4desWiouL0alTJwDgb8sPMXPmTADAunXrJE5CD8OyqAfMzMz0i9Bt374drq6uAIBGjRpJ\nmIqqo3L9ru+++05/jb5Wq0VRUZGUsWTpcUcPwcHBRkxCD8OyqAeq/hZa9YErXEhQ/vr06YOAgADc\nvHkTGzduRE5ODpYtW4ahQ4dKHU12mjVrBgBITk5Gq1at4OXlhfPnz/PxwTLBCe564GF3kQqCgNOn\nT+PEiRNSxyMRmZmZcHBwgL29PXJycnD58mUMGjRI6liyNXnyZGzdulX/euLEiYiLi5MwEQE8sqgX\nHnUXaUO/o7S+cHNz03/s4uICFxcXCdPIX0FBAXJycuDi4oLffvsNarVa6kgEHlkQkcycPXsWq1ev\nRl5eHpo1a4bo6GiDwiVpsCyISHYKCwvx+++/w9nZGUqlUuo4BJ6GIiKZOXz4MDZu3Ijy8nIMGTIE\nCoVCf1ktSYdrQxGRrMTFxSExMRFNmjTBzJkzkZycLHUkAsuCiGTGxMQEFhYW+qfkWVtbSx2JwLIg\nIpnp0aMH5s2bh1u3biE8PBxdunSROhKBE9xEJEMpKSm4cuUK2rZtCx8fH6njEFgWRCQTKpUKn3zy\nCRo1aoTJkydzORuZ4WkoIpKF0NBQuLi4wNzc3OiPTyVxvHSWiGShrKxM/+jUCRMmSBuGHsAjCyKS\nhaoLZnKRTPnhkQURyUJxcTGuXr0KnU6H+/fv4+rVq/rH0fLxwdLjBDcRyUJQUNBDtysUCj4+WAZY\nFkQkWzqdDiYmPFsuB/wuEJGsHDp0CAcPHsS+ffvwwgsvGDzbgqTDsiAiWfnkk0/Qt29ffPnll/j2\n229x7NgxqSMRWBZEJDOWlpYAAKVSCQsLC2g0GokTEcCyICKZadWqFUaPHo3Ro0djw4YN8PT0lDoS\ngRPcRCRDGo0GSqUSKpUKjo6OUsch8D4LIpKZjIwMvPPOOygsLMTw4cPh7u6O/v37Sx2rweNpKCKS\nlcjISKxatQpNmjTB66+/jg8++EDqSASWBRHJUOvWraFQKODg4MBncMsEy4KIZKVx48bYs2cPiouL\ncfDgQdjZ2UkdicAJbiKSGbVajU2bNuHKlStwc3PD9OnT0bhxY6ljNXic4CYiWdm+fTvmz5+vfx0T\nE4N58+ZJmIgAHlkQkUwkJSXh008/RWZmJp555hkAFWtDlZaWYt++fRKnI5YFEcmCVqtFXl4ePvro\nI0yfPh0AYGJigqZNm8LCwkLidMSyICJZKSsrw759+5Cbm4tevXrB3d0dDg4OUsdq8Hg1FBHJyjvv\nvIMbN27gxIkT0Gg0CA0NlToSgWVBRDKTk5OD2bNnw9LSEj4+PigsLJQ6EoFlQUQyU15ejvz8fAAV\nl9Hy4UfywDkLIpKVM2fOYOnSpVCpVGjRogUWL16M559/XupYDR7LgohkR6fToaCgAA4ODlAoFFLH\nIfA0FBHJzPHjxzFo0CBMmTIFQ4YMwenTp6WOROCRBRHJjK+vLz766CM4ODhApVLh3//+NxITE6WO\n1eDxyIKIZEWpVOrvq3B0dIS1tbXEiQjg2lBEJBPr1q0DUHE11LRp09C9e3ekp6fz7m2ZYFkQkSy0\nadPG4P8BYMCAAVLFob/gnAURyUpZWRnOnz+PsrIyCIKAvLw8DBs2TOpYDR6PLIhIVoKDg1FaWoq8\nvDyUl5fDycmJZSEDnOAmIllRq9XYunUrPD09sXfvXpSUlEgdicCyICKZMTOrOOFRXFwMKysrlJaW\nSpyIAM5ZEJHM7Ny5EwUFBbCwsEBycjKsra2xbds2qWM1eCwLIpKty5cvw9XVFZaWllJHafA4wU1E\nshAbG4uZM2c+9HnbMTExEiSiqlgWRCQLPj4+uHTpEnJzc1FQUICRI0fCwcEBrq6uUkcjcIKbiGQi\nKysLixcvxqhRozB//nwolUrEx8fj3r17UkcjcM6CiGQiMDAQW7duRaNGjfTb1Go1ZsyYgfj4eAmT\nEcAjCyKSCTMzM4OiAAAbGxuYmppKlIiqYlkQkSw86iFHOp3OyEnoYTjBTUSy8Ouvvz5wJZQgCMjM\nzJQoEVXFOQsikoUzZ848cl/Pnj2NmIQehmVBRESiOGdBRESiWBZERCSKZUFERKJYFkREJIplQURE\nov4fMBNafFRlLHMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x47885d7400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = correlations.plot(kind='bar')\n",
    "ax.set(ylim=[-1, 1], ylabel='pearson correlation');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####No idea why i am having this kind of correllation#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentage importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>25.531204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>16.611817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>13.963501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>12.415163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>8.422233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>8.203880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>7.778867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>7.073334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          percentage importance\n",
       "Glucose                               25.531204\n",
       "BMI                                   16.611817\n",
       "Age                                   13.963501\n",
       "DiabetesPedigreeFunction              12.415163\n",
       "BloodPressure                          8.422233\n",
       "Pregnancies                            8.203880\n",
       "Insulin                                7.778867\n",
       "SkinThickness                          7.073334"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the random forest classifier to get the most important features\n",
    "\n",
    "X = diabetes[diabetes.columns[:-1]]\n",
    "Y = diabetes['Outcome']\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 200).fit(X, Y)\n",
    "most_important = pd.Series(rf.feature_importances_ *100, index=X.columns).sort_values(ascending =False).to_frame()\n",
    "most_important.rename(columns = {0: 'percentage importance'}, inplace = True)\n",
    "most_important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the 4 most important feature in this dataset are Glucose, BMI, Age, DiabetesPedigreeFunction. We will use these features plus the Outcome as our new dataset, and drop the other features, calcualte the accuracies and see if they are very different from what we got before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Glucose  BloodPressure   BMI  DiabetesPedigreeFunction  Age  Outcome\n",
       "0    148.0           72.0  33.6                     0.627   50        1\n",
       "1     85.0           66.0  26.6                     0.351   31        0\n",
       "2    183.0           64.0  23.3                     0.672   32        1\n",
       "3     89.0           66.0  28.1                     0.167   21        0\n",
       "4    137.0           40.0  43.1                     2.288   33        1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_2 = diabetes.drop(['Pregnancies', 'Insulin', 'SkinThickness'], axis = 1)\n",
    "\n",
    "diabetes_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols_2 = diabetes_2.columns[:-1]\n",
    "# Get the split indexes\n",
    "strat_shuf_split = StratifiedShuffleSplit(n_splits=1, \n",
    "                                          test_size=0.3, \n",
    "                                          random_state=42)\n",
    "\n",
    "train_idx_2, test_idx_2 = next(strat_shuf_split.split(diabetes_2[feature_cols_2], diabetes_2.Outcome))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframes\n",
    "X_train_2 = diabetes_2.loc[train_idx_2, feature_cols_2]\n",
    "y_train_3 = diabetes_2.loc[train_idx_2, 'Outcome']\n",
    "\n",
    "X_test_2  = diabetes_2.loc[test_idx_2, feature_cols_2]\n",
    "y_test_3  = diabetes_2.loc[test_idx_2, 'Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3 = StandardScaler().fit_transform(X_train_2)\n",
    "X_test_3 = StandardScaler().fit_transform(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not have a enough data to creat a validation set so we will use k fold cross validation to pick the best model\n",
    "cv_results_2 = []\n",
    "\n",
    "labels = ['log_reg', 'linear_svc', 'svc_rbf', 'Random_forest']\n",
    "\n",
    "models = [LogisticRegression(), LinearSVC(), SVC(kernel = 'rbf'), \n",
    "            RandomForestClassifier(n_estimators = 200)]\n",
    "\n",
    "kf_2 = KFold(n_splits=10, random_state = 42)\n",
    "\n",
    "for i in models:\n",
    "    result_cv_2 = cross_val_score(i, X_train_3, y_train_3, cv= kf_2, scoring = 'accuracy')\n",
    "   \n",
    "    cv_results_2.append(result_cv_2.mean()* 100)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Models with their corresponding cross validation means after feature selection:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cross_val with feature selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear_svc</th>\n",
       "      <td>77.830189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_reg</th>\n",
       "      <td>77.830189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_rbf</th>\n",
       "      <td>76.897275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_forest</th>\n",
       "      <td>76.530398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cross_val with feature selection\n",
       "linear_svc                            77.830189\n",
       "log_reg                               77.830189\n",
       "svc_rbf                               76.897275\n",
       "Random_forest                         76.530398"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_sel_cross_val = pd.Series(cv_results_2, index = labels).sort_values(ascending=False).to_frame()\n",
    "feature_sel_cross_val.rename(columns = {0: 'cross_val with feature selection'}, inplace = True)\n",
    "print('\\nModels with their corresponding cross validation means after feature selection:')\n",
    "feature_sel_cross_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_probs_fs = []\n",
    "models_names = ['log_reg_fs', 'linear_svc_fs', 'svc_rbf_fs', 'Random_forest_fs']\n",
    "\n",
    "for i in [LogisticRegression(),RandomForestClassifier(n_estimators = 200)]:\n",
    "    i.fit(X_train_3, y_train_3)\n",
    "    validation_probabilities = i.predict_proba(X_test_3)\n",
    "    validation_probs_fs.append(validation_probabilities[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in [LinearSVC(), SVC(kernel = 'rbf')]:\n",
    "    j.fit(X_train_3, y_train_3)\n",
    "    svc_probabilities = j.decision_function(X_test_3)\n",
    "    validation_probs_fs.append(svc_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5_Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our input_shape has changed, was 8, now it is 5\n",
    "#Building a single layered neural network\n",
    "nn_model_2 = Sequential()\n",
    "nn_model_2.add(Dense(15, input_shape = (5,),activation = 'relu'))\n",
    "#nn_model.add(Dropout(0.1))\n",
    "nn_model_2.add(Dense(1, activation ='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat a training and validation set from the training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_nn3, x_val_3, y_train_nn3, y_val_3 = train_test_split(X_train_3, y_train_3, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 429 samples, validate on 108 samples\n",
      "Epoch 1/900\n",
      "429/429 [==============================] - 0s 887us/step - loss: 0.8166 - acc: 0.4033 - val_loss: 0.7654 - val_acc: 0.4167\n",
      "Epoch 2/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.8012 - acc: 0.4103 - val_loss: 0.7536 - val_acc: 0.4074\n",
      "Epoch 3/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.7869 - acc: 0.4242 - val_loss: 0.7425 - val_acc: 0.4259\n",
      "Epoch 4/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.7729 - acc: 0.4359 - val_loss: 0.7321 - val_acc: 0.4444\n",
      "Epoch 5/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.7597 - acc: 0.4452 - val_loss: 0.7223 - val_acc: 0.4630\n",
      "Epoch 6/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.7473 - acc: 0.4685 - val_loss: 0.7128 - val_acc: 0.4722\n",
      "Epoch 7/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.7350 - acc: 0.4825 - val_loss: 0.7040 - val_acc: 0.4907\n",
      "Epoch 8/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.7231 - acc: 0.5035 - val_loss: 0.6955 - val_acc: 0.5185\n",
      "Epoch 9/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.7119 - acc: 0.5245 - val_loss: 0.6874 - val_acc: 0.5463\n",
      "Epoch 10/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.7016 - acc: 0.5594 - val_loss: 0.6798 - val_acc: 0.5833\n",
      "Epoch 11/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.6917 - acc: 0.5758 - val_loss: 0.6725 - val_acc: 0.6111\n",
      "Epoch 12/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.6822 - acc: 0.6084 - val_loss: 0.6655 - val_acc: 0.6019\n",
      "Epoch 13/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.6733 - acc: 0.6294 - val_loss: 0.6591 - val_acc: 0.6019\n",
      "Epoch 14/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.6652 - acc: 0.6573 - val_loss: 0.6529 - val_acc: 0.6111\n",
      "Epoch 15/900\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.6574 - acc: 0.6573 - val_loss: 0.6470 - val_acc: 0.6111\n",
      "Epoch 16/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.6500 - acc: 0.6690 - val_loss: 0.6411 - val_acc: 0.6296\n",
      "Epoch 17/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.6426 - acc: 0.6690 - val_loss: 0.6357 - val_acc: 0.6389\n",
      "Epoch 18/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.6359 - acc: 0.6807 - val_loss: 0.6304 - val_acc: 0.6389\n",
      "Epoch 19/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.6293 - acc: 0.6830 - val_loss: 0.6254 - val_acc: 0.6389\n",
      "Epoch 20/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.6229 - acc: 0.6853 - val_loss: 0.6207 - val_acc: 0.6759\n",
      "Epoch 21/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.6168 - acc: 0.6923 - val_loss: 0.6160 - val_acc: 0.6852\n",
      "Epoch 22/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.6110 - acc: 0.6970 - val_loss: 0.6118 - val_acc: 0.7130\n",
      "Epoch 23/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.6055 - acc: 0.6993 - val_loss: 0.6076 - val_acc: 0.7130\n",
      "Epoch 24/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.6001 - acc: 0.6923 - val_loss: 0.6035 - val_acc: 0.7222\n",
      "Epoch 25/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.5947 - acc: 0.6946 - val_loss: 0.5999 - val_acc: 0.7222\n",
      "Epoch 26/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.5899 - acc: 0.6946 - val_loss: 0.5964 - val_acc: 0.7222\n",
      "Epoch 27/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5854 - acc: 0.6993 - val_loss: 0.5929 - val_acc: 0.7315\n",
      "Epoch 28/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.5808 - acc: 0.6993 - val_loss: 0.5895 - val_acc: 0.7315\n",
      "Epoch 29/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.5763 - acc: 0.6993 - val_loss: 0.5863 - val_acc: 0.7315\n",
      "Epoch 30/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5721 - acc: 0.7063 - val_loss: 0.5832 - val_acc: 0.7315\n",
      "Epoch 31/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.5680 - acc: 0.7086 - val_loss: 0.5802 - val_acc: 0.7315\n",
      "Epoch 32/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5641 - acc: 0.7133 - val_loss: 0.5774 - val_acc: 0.7315\n",
      "Epoch 33/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.5602 - acc: 0.7110 - val_loss: 0.5747 - val_acc: 0.7315\n",
      "Epoch 34/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5566 - acc: 0.7110 - val_loss: 0.5722 - val_acc: 0.7407\n",
      "Epoch 35/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.5531 - acc: 0.7110 - val_loss: 0.5697 - val_acc: 0.7407\n",
      "Epoch 36/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.5497 - acc: 0.7086 - val_loss: 0.5673 - val_acc: 0.7407\n",
      "Epoch 37/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.5464 - acc: 0.7203 - val_loss: 0.5650 - val_acc: 0.7407\n",
      "Epoch 38/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5432 - acc: 0.7249 - val_loss: 0.5628 - val_acc: 0.7407\n",
      "Epoch 39/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.5401 - acc: 0.7319 - val_loss: 0.5607 - val_acc: 0.7500\n",
      "Epoch 40/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5371 - acc: 0.7343 - val_loss: 0.5588 - val_acc: 0.7593\n",
      "Epoch 41/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.5344 - acc: 0.7436 - val_loss: 0.5569 - val_acc: 0.7593\n",
      "Epoch 42/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.5317 - acc: 0.7436 - val_loss: 0.5550 - val_acc: 0.7685\n",
      "Epoch 43/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5290 - acc: 0.7436 - val_loss: 0.5532 - val_acc: 0.7685\n",
      "Epoch 44/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.5264 - acc: 0.7483 - val_loss: 0.5515 - val_acc: 0.7685\n",
      "Epoch 45/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5239 - acc: 0.7483 - val_loss: 0.5498 - val_acc: 0.7685\n",
      "Epoch 46/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5215 - acc: 0.7529 - val_loss: 0.5482 - val_acc: 0.7685\n",
      "Epoch 47/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5191 - acc: 0.7576 - val_loss: 0.5467 - val_acc: 0.7593\n",
      "Epoch 48/900\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.5168 - acc: 0.7576 - val_loss: 0.5453 - val_acc: 0.7593\n",
      "Epoch 49/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.5147 - acc: 0.7622 - val_loss: 0.5439 - val_acc: 0.7685\n",
      "Epoch 50/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5126 - acc: 0.7599 - val_loss: 0.5426 - val_acc: 0.7685\n",
      "Epoch 51/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.5106 - acc: 0.7622 - val_loss: 0.5413 - val_acc: 0.7685\n",
      "Epoch 52/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5086 - acc: 0.7622 - val_loss: 0.5400 - val_acc: 0.7778\n",
      "Epoch 53/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.5067 - acc: 0.7622 - val_loss: 0.5389 - val_acc: 0.7778\n",
      "Epoch 54/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5049 - acc: 0.7646 - val_loss: 0.5378 - val_acc: 0.7778\n",
      "Epoch 55/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5032 - acc: 0.7622 - val_loss: 0.5368 - val_acc: 0.7778\n",
      "Epoch 56/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5015 - acc: 0.7669 - val_loss: 0.5360 - val_acc: 0.7778\n",
      "Epoch 57/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.5000 - acc: 0.7646 - val_loss: 0.5350 - val_acc: 0.7778\n",
      "Epoch 58/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4984 - acc: 0.7646 - val_loss: 0.5341 - val_acc: 0.7778\n",
      "Epoch 59/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4968 - acc: 0.7622 - val_loss: 0.5332 - val_acc: 0.7778\n",
      "Epoch 60/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4953 - acc: 0.7646 - val_loss: 0.5323 - val_acc: 0.7778\n",
      "Epoch 61/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4938 - acc: 0.7646 - val_loss: 0.5315 - val_acc: 0.7778\n",
      "Epoch 62/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4924 - acc: 0.7646 - val_loss: 0.5307 - val_acc: 0.7870\n",
      "Epoch 63/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4911 - acc: 0.7646 - val_loss: 0.5300 - val_acc: 0.7870\n",
      "Epoch 64/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4897 - acc: 0.7646 - val_loss: 0.5294 - val_acc: 0.7870\n",
      "Epoch 65/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4885 - acc: 0.7669 - val_loss: 0.5287 - val_acc: 0.7870\n",
      "Epoch 66/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4872 - acc: 0.7669 - val_loss: 0.5280 - val_acc: 0.7870\n",
      "Epoch 67/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4859 - acc: 0.7692 - val_loss: 0.5275 - val_acc: 0.7870\n",
      "Epoch 68/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4848 - acc: 0.7692 - val_loss: 0.5270 - val_acc: 0.7870\n",
      "Epoch 69/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4837 - acc: 0.7716 - val_loss: 0.5264 - val_acc: 0.7870\n",
      "Epoch 70/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4826 - acc: 0.7739 - val_loss: 0.5260 - val_acc: 0.7870\n",
      "Epoch 71/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4815 - acc: 0.7786 - val_loss: 0.5255 - val_acc: 0.7870\n",
      "Epoch 72/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4804 - acc: 0.7786 - val_loss: 0.5251 - val_acc: 0.7870\n",
      "Epoch 73/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4794 - acc: 0.7786 - val_loss: 0.5247 - val_acc: 0.7778\n",
      "Epoch 74/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4785 - acc: 0.7786 - val_loss: 0.5243 - val_acc: 0.7778\n",
      "Epoch 75/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4776 - acc: 0.7786 - val_loss: 0.5239 - val_acc: 0.7778\n",
      "Epoch 76/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4767 - acc: 0.7786 - val_loss: 0.5236 - val_acc: 0.7778\n",
      "Epoch 77/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4758 - acc: 0.7739 - val_loss: 0.5233 - val_acc: 0.7778\n",
      "Epoch 78/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4750 - acc: 0.7786 - val_loss: 0.5230 - val_acc: 0.7778\n",
      "Epoch 79/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4741 - acc: 0.7762 - val_loss: 0.5227 - val_acc: 0.7778\n",
      "Epoch 80/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4734 - acc: 0.7739 - val_loss: 0.5224 - val_acc: 0.7778\n",
      "Epoch 81/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4726 - acc: 0.7739 - val_loss: 0.5221 - val_acc: 0.7778\n",
      "Epoch 82/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4718 - acc: 0.7762 - val_loss: 0.5219 - val_acc: 0.7685\n",
      "Epoch 83/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4711 - acc: 0.7762 - val_loss: 0.5217 - val_acc: 0.7685\n",
      "Epoch 84/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4702 - acc: 0.7762 - val_loss: 0.5214 - val_acc: 0.7593\n",
      "Epoch 85/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4695 - acc: 0.7786 - val_loss: 0.5213 - val_acc: 0.7593\n",
      "Epoch 86/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4689 - acc: 0.7786 - val_loss: 0.5211 - val_acc: 0.7593\n",
      "Epoch 87/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4681 - acc: 0.7762 - val_loss: 0.5209 - val_acc: 0.7593\n",
      "Epoch 88/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4675 - acc: 0.7786 - val_loss: 0.5208 - val_acc: 0.7593\n",
      "Epoch 89/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4669 - acc: 0.7786 - val_loss: 0.5207 - val_acc: 0.7593\n",
      "Epoch 90/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4662 - acc: 0.7809 - val_loss: 0.5206 - val_acc: 0.7593\n",
      "Epoch 91/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4656 - acc: 0.7809 - val_loss: 0.5205 - val_acc: 0.7593\n",
      "Epoch 92/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4651 - acc: 0.7786 - val_loss: 0.5204 - val_acc: 0.7593\n",
      "Epoch 93/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4645 - acc: 0.7786 - val_loss: 0.5204 - val_acc: 0.7593\n",
      "Epoch 94/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4639 - acc: 0.7786 - val_loss: 0.5204 - val_acc: 0.7593\n",
      "Epoch 95/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4633 - acc: 0.7786 - val_loss: 0.5204 - val_acc: 0.7593\n",
      "Epoch 96/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4629 - acc: 0.7809 - val_loss: 0.5204 - val_acc: 0.7593\n",
      "Epoch 97/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4623 - acc: 0.7809 - val_loss: 0.5203 - val_acc: 0.7500\n",
      "Epoch 98/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4618 - acc: 0.7809 - val_loss: 0.5203 - val_acc: 0.7500\n",
      "Epoch 99/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4613 - acc: 0.7809 - val_loss: 0.5202 - val_acc: 0.7500\n",
      "Epoch 100/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4608 - acc: 0.7809 - val_loss: 0.5202 - val_acc: 0.7500\n",
      "Epoch 101/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4603 - acc: 0.7809 - val_loss: 0.5202 - val_acc: 0.7500\n",
      "Epoch 102/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4598 - acc: 0.7809 - val_loss: 0.5202 - val_acc: 0.7500\n",
      "Epoch 103/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4593 - acc: 0.7809 - val_loss: 0.5203 - val_acc: 0.7500\n",
      "Epoch 104/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4589 - acc: 0.7809 - val_loss: 0.5203 - val_acc: 0.7500\n",
      "Epoch 105/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4585 - acc: 0.7809 - val_loss: 0.5203 - val_acc: 0.7500\n",
      "Epoch 106/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4580 - acc: 0.7832 - val_loss: 0.5204 - val_acc: 0.7500\n",
      "Epoch 107/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4576 - acc: 0.7832 - val_loss: 0.5204 - val_acc: 0.7500\n",
      "Epoch 108/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4571 - acc: 0.7855 - val_loss: 0.5205 - val_acc: 0.7500\n",
      "Epoch 109/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4567 - acc: 0.7832 - val_loss: 0.5205 - val_acc: 0.7500\n",
      "Epoch 110/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4564 - acc: 0.7832 - val_loss: 0.5206 - val_acc: 0.7407\n",
      "Epoch 111/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4560 - acc: 0.7832 - val_loss: 0.5207 - val_acc: 0.7500\n",
      "Epoch 112/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4557 - acc: 0.7855 - val_loss: 0.5207 - val_acc: 0.7500\n",
      "Epoch 113/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4553 - acc: 0.7855 - val_loss: 0.5206 - val_acc: 0.7500\n",
      "Epoch 114/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4550 - acc: 0.7855 - val_loss: 0.5207 - val_acc: 0.7500\n",
      "Epoch 115/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4546 - acc: 0.7855 - val_loss: 0.5206 - val_acc: 0.7500\n",
      "Epoch 116/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4543 - acc: 0.7855 - val_loss: 0.5207 - val_acc: 0.7500\n",
      "Epoch 117/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4539 - acc: 0.7855 - val_loss: 0.5207 - val_acc: 0.7500\n",
      "Epoch 118/900\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.4536 - acc: 0.7855 - val_loss: 0.5208 - val_acc: 0.7500\n",
      "Epoch 119/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4533 - acc: 0.7832 - val_loss: 0.5210 - val_acc: 0.7500\n",
      "Epoch 120/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4530 - acc: 0.7832 - val_loss: 0.5211 - val_acc: 0.7500\n",
      "Epoch 121/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 75us/step - loss: 0.4526 - acc: 0.7832 - val_loss: 0.5211 - val_acc: 0.7500\n",
      "Epoch 122/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4524 - acc: 0.7832 - val_loss: 0.5212 - val_acc: 0.7500\n",
      "Epoch 123/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4520 - acc: 0.7832 - val_loss: 0.5214 - val_acc: 0.7500\n",
      "Epoch 124/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4518 - acc: 0.7832 - val_loss: 0.5214 - val_acc: 0.7500\n",
      "Epoch 125/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4515 - acc: 0.7855 - val_loss: 0.5215 - val_acc: 0.7500\n",
      "Epoch 126/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4512 - acc: 0.7832 - val_loss: 0.5215 - val_acc: 0.7500\n",
      "Epoch 127/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4509 - acc: 0.7855 - val_loss: 0.5216 - val_acc: 0.7500\n",
      "Epoch 128/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4506 - acc: 0.7855 - val_loss: 0.5217 - val_acc: 0.7500\n",
      "Epoch 129/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4503 - acc: 0.7855 - val_loss: 0.5219 - val_acc: 0.7500\n",
      "Epoch 130/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4501 - acc: 0.7855 - val_loss: 0.5220 - val_acc: 0.7500\n",
      "Epoch 131/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4498 - acc: 0.7855 - val_loss: 0.5220 - val_acc: 0.7500\n",
      "Epoch 132/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4495 - acc: 0.7855 - val_loss: 0.5221 - val_acc: 0.7500\n",
      "Epoch 133/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4492 - acc: 0.7855 - val_loss: 0.5221 - val_acc: 0.7500\n",
      "Epoch 134/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4490 - acc: 0.7879 - val_loss: 0.5221 - val_acc: 0.7500\n",
      "Epoch 135/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4488 - acc: 0.7879 - val_loss: 0.5221 - val_acc: 0.7500\n",
      "Epoch 136/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4486 - acc: 0.7879 - val_loss: 0.5223 - val_acc: 0.7500\n",
      "Epoch 137/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4483 - acc: 0.7879 - val_loss: 0.5224 - val_acc: 0.7500\n",
      "Epoch 138/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4481 - acc: 0.7879 - val_loss: 0.5224 - val_acc: 0.7500\n",
      "Epoch 139/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4479 - acc: 0.7855 - val_loss: 0.5225 - val_acc: 0.7500\n",
      "Epoch 140/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4477 - acc: 0.7855 - val_loss: 0.5227 - val_acc: 0.7500\n",
      "Epoch 141/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4474 - acc: 0.7855 - val_loss: 0.5227 - val_acc: 0.7500\n",
      "Epoch 142/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4472 - acc: 0.7855 - val_loss: 0.5228 - val_acc: 0.7500\n",
      "Epoch 143/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4470 - acc: 0.7855 - val_loss: 0.5230 - val_acc: 0.7500\n",
      "Epoch 144/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4468 - acc: 0.7855 - val_loss: 0.5231 - val_acc: 0.7500\n",
      "Epoch 145/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4466 - acc: 0.7855 - val_loss: 0.5233 - val_acc: 0.7500\n",
      "Epoch 146/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4464 - acc: 0.7855 - val_loss: 0.5234 - val_acc: 0.7500\n",
      "Epoch 147/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4462 - acc: 0.7855 - val_loss: 0.5234 - val_acc: 0.7500\n",
      "Epoch 148/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4460 - acc: 0.7855 - val_loss: 0.5234 - val_acc: 0.7500\n",
      "Epoch 149/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4458 - acc: 0.7855 - val_loss: 0.5235 - val_acc: 0.7500\n",
      "Epoch 150/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4456 - acc: 0.7855 - val_loss: 0.5236 - val_acc: 0.7500\n",
      "Epoch 151/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4454 - acc: 0.7855 - val_loss: 0.5237 - val_acc: 0.7500\n",
      "Epoch 152/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4452 - acc: 0.7855 - val_loss: 0.5238 - val_acc: 0.7500\n",
      "Epoch 153/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4451 - acc: 0.7855 - val_loss: 0.5239 - val_acc: 0.7500\n",
      "Epoch 154/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4448 - acc: 0.7855 - val_loss: 0.5240 - val_acc: 0.7500\n",
      "Epoch 155/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4447 - acc: 0.7855 - val_loss: 0.5241 - val_acc: 0.7500\n",
      "Epoch 156/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4445 - acc: 0.7855 - val_loss: 0.5242 - val_acc: 0.7500\n",
      "Epoch 157/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4444 - acc: 0.7855 - val_loss: 0.5243 - val_acc: 0.7500\n",
      "Epoch 158/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4442 - acc: 0.7855 - val_loss: 0.5243 - val_acc: 0.7593\n",
      "Epoch 159/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4441 - acc: 0.7855 - val_loss: 0.5244 - val_acc: 0.7593\n",
      "Epoch 160/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4439 - acc: 0.7855 - val_loss: 0.5245 - val_acc: 0.7593\n",
      "Epoch 161/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4438 - acc: 0.7855 - val_loss: 0.5246 - val_acc: 0.7500\n",
      "Epoch 162/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4436 - acc: 0.7855 - val_loss: 0.5248 - val_acc: 0.7500\n",
      "Epoch 163/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4435 - acc: 0.7855 - val_loss: 0.5250 - val_acc: 0.7500\n",
      "Epoch 164/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4432 - acc: 0.7879 - val_loss: 0.5250 - val_acc: 0.7593\n",
      "Epoch 165/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4431 - acc: 0.7855 - val_loss: 0.5251 - val_acc: 0.7593\n",
      "Epoch 166/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4429 - acc: 0.7855 - val_loss: 0.5252 - val_acc: 0.7593\n",
      "Epoch 167/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4428 - acc: 0.7855 - val_loss: 0.5253 - val_acc: 0.7593\n",
      "Epoch 168/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4427 - acc: 0.7855 - val_loss: 0.5254 - val_acc: 0.7593\n",
      "Epoch 169/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4425 - acc: 0.7879 - val_loss: 0.5254 - val_acc: 0.7593\n",
      "Epoch 170/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4424 - acc: 0.7879 - val_loss: 0.5255 - val_acc: 0.7593\n",
      "Epoch 171/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4423 - acc: 0.7879 - val_loss: 0.5257 - val_acc: 0.7593\n",
      "Epoch 172/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4421 - acc: 0.7855 - val_loss: 0.5258 - val_acc: 0.7593\n",
      "Epoch 173/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4420 - acc: 0.7855 - val_loss: 0.5259 - val_acc: 0.7593\n",
      "Epoch 174/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4418 - acc: 0.7879 - val_loss: 0.5259 - val_acc: 0.7593\n",
      "Epoch 175/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4417 - acc: 0.7855 - val_loss: 0.5259 - val_acc: 0.7593\n",
      "Epoch 176/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4415 - acc: 0.7855 - val_loss: 0.5260 - val_acc: 0.7593\n",
      "Epoch 177/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4414 - acc: 0.7855 - val_loss: 0.5261 - val_acc: 0.7593\n",
      "Epoch 178/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4413 - acc: 0.7855 - val_loss: 0.5262 - val_acc: 0.7593\n",
      "Epoch 179/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4412 - acc: 0.7855 - val_loss: 0.5263 - val_acc: 0.7593\n",
      "Epoch 180/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4411 - acc: 0.7855 - val_loss: 0.5264 - val_acc: 0.7593\n",
      "Epoch 181/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4410 - acc: 0.7855 - val_loss: 0.5264 - val_acc: 0.7593\n",
      "Epoch 182/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4408 - acc: 0.7855 - val_loss: 0.5266 - val_acc: 0.7593\n",
      "Epoch 183/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4406 - acc: 0.7855 - val_loss: 0.5267 - val_acc: 0.7593\n",
      "Epoch 184/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4405 - acc: 0.7855 - val_loss: 0.5268 - val_acc: 0.7593\n",
      "Epoch 185/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4404 - acc: 0.7855 - val_loss: 0.5270 - val_acc: 0.7593\n",
      "Epoch 186/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4403 - acc: 0.7855 - val_loss: 0.5270 - val_acc: 0.7593\n",
      "Epoch 187/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4402 - acc: 0.7855 - val_loss: 0.5271 - val_acc: 0.7593\n",
      "Epoch 188/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4401 - acc: 0.7855 - val_loss: 0.5271 - val_acc: 0.7593\n",
      "Epoch 189/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4400 - acc: 0.7855 - val_loss: 0.5272 - val_acc: 0.7593\n",
      "Epoch 190/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4398 - acc: 0.7855 - val_loss: 0.5273 - val_acc: 0.7593\n",
      "Epoch 191/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4397 - acc: 0.7855 - val_loss: 0.5274 - val_acc: 0.7593\n",
      "Epoch 192/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4396 - acc: 0.7855 - val_loss: 0.5274 - val_acc: 0.7593\n",
      "Epoch 193/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4395 - acc: 0.7855 - val_loss: 0.5275 - val_acc: 0.7593\n",
      "Epoch 194/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4393 - acc: 0.7879 - val_loss: 0.5277 - val_acc: 0.7593\n",
      "Epoch 195/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4393 - acc: 0.7879 - val_loss: 0.5278 - val_acc: 0.7593\n",
      "Epoch 196/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4391 - acc: 0.7879 - val_loss: 0.5280 - val_acc: 0.7593\n",
      "Epoch 197/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4391 - acc: 0.7879 - val_loss: 0.5281 - val_acc: 0.7593\n",
      "Epoch 198/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4390 - acc: 0.7879 - val_loss: 0.5281 - val_acc: 0.7593\n",
      "Epoch 199/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4388 - acc: 0.7879 - val_loss: 0.5282 - val_acc: 0.7593\n",
      "Epoch 200/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4387 - acc: 0.7879 - val_loss: 0.5282 - val_acc: 0.7593\n",
      "Epoch 201/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4386 - acc: 0.7879 - val_loss: 0.5283 - val_acc: 0.7593\n",
      "Epoch 202/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4385 - acc: 0.7879 - val_loss: 0.5284 - val_acc: 0.7593\n",
      "Epoch 203/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4384 - acc: 0.7879 - val_loss: 0.5284 - val_acc: 0.7593\n",
      "Epoch 204/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4384 - acc: 0.7879 - val_loss: 0.5285 - val_acc: 0.7593\n",
      "Epoch 205/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4382 - acc: 0.7855 - val_loss: 0.5286 - val_acc: 0.7593\n",
      "Epoch 206/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4381 - acc: 0.7855 - val_loss: 0.5288 - val_acc: 0.7593\n",
      "Epoch 207/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4380 - acc: 0.7855 - val_loss: 0.5289 - val_acc: 0.7593\n",
      "Epoch 208/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4379 - acc: 0.7855 - val_loss: 0.5290 - val_acc: 0.7593\n",
      "Epoch 209/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4378 - acc: 0.7855 - val_loss: 0.5291 - val_acc: 0.7593\n",
      "Epoch 210/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4377 - acc: 0.7855 - val_loss: 0.5291 - val_acc: 0.7593\n",
      "Epoch 211/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4376 - acc: 0.7855 - val_loss: 0.5291 - val_acc: 0.7593\n",
      "Epoch 212/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4375 - acc: 0.7855 - val_loss: 0.5292 - val_acc: 0.7593\n",
      "Epoch 213/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4374 - acc: 0.7855 - val_loss: 0.5294 - val_acc: 0.7593\n",
      "Epoch 214/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4373 - acc: 0.7855 - val_loss: 0.5294 - val_acc: 0.7593\n",
      "Epoch 215/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4372 - acc: 0.7855 - val_loss: 0.5295 - val_acc: 0.7593\n",
      "Epoch 216/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4371 - acc: 0.7855 - val_loss: 0.5297 - val_acc: 0.7593\n",
      "Epoch 217/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4370 - acc: 0.7855 - val_loss: 0.5297 - val_acc: 0.7593\n",
      "Epoch 218/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4369 - acc: 0.7855 - val_loss: 0.5297 - val_acc: 0.7593\n",
      "Epoch 219/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4368 - acc: 0.7855 - val_loss: 0.5297 - val_acc: 0.7593\n",
      "Epoch 220/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4367 - acc: 0.7855 - val_loss: 0.5298 - val_acc: 0.7500\n",
      "Epoch 221/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4366 - acc: 0.7855 - val_loss: 0.5299 - val_acc: 0.7500\n",
      "Epoch 222/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4365 - acc: 0.7855 - val_loss: 0.5299 - val_acc: 0.7500\n",
      "Epoch 223/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4364 - acc: 0.7855 - val_loss: 0.5300 - val_acc: 0.7500\n",
      "Epoch 224/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4364 - acc: 0.7855 - val_loss: 0.5302 - val_acc: 0.7500\n",
      "Epoch 225/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4363 - acc: 0.7855 - val_loss: 0.5303 - val_acc: 0.7500\n",
      "Epoch 226/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4361 - acc: 0.7855 - val_loss: 0.5304 - val_acc: 0.7500\n",
      "Epoch 227/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4360 - acc: 0.7855 - val_loss: 0.5305 - val_acc: 0.7500\n",
      "Epoch 228/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4360 - acc: 0.7855 - val_loss: 0.5306 - val_acc: 0.7500\n",
      "Epoch 229/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4359 - acc: 0.7855 - val_loss: 0.5307 - val_acc: 0.7500\n",
      "Epoch 230/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4358 - acc: 0.7855 - val_loss: 0.5307 - val_acc: 0.7500\n",
      "Epoch 231/900\n",
      "429/429 [==============================] - 0s 94us/step - loss: 0.4357 - acc: 0.7855 - val_loss: 0.5309 - val_acc: 0.7500\n",
      "Epoch 232/900\n",
      "429/429 [==============================] - 0s 92us/step - loss: 0.4356 - acc: 0.7855 - val_loss: 0.5308 - val_acc: 0.7500\n",
      "Epoch 233/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4355 - acc: 0.7855 - val_loss: 0.5309 - val_acc: 0.7500\n",
      "Epoch 234/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4354 - acc: 0.7855 - val_loss: 0.5309 - val_acc: 0.7500\n",
      "Epoch 235/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4353 - acc: 0.7855 - val_loss: 0.5310 - val_acc: 0.7500\n",
      "Epoch 236/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4353 - acc: 0.7855 - val_loss: 0.5310 - val_acc: 0.7500\n",
      "Epoch 237/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4352 - acc: 0.7855 - val_loss: 0.5311 - val_acc: 0.7500\n",
      "Epoch 238/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4352 - acc: 0.7855 - val_loss: 0.5312 - val_acc: 0.7500\n",
      "Epoch 239/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4350 - acc: 0.7855 - val_loss: 0.5313 - val_acc: 0.7500\n",
      "Epoch 240/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4349 - acc: 0.7855 - val_loss: 0.5313 - val_acc: 0.7500\n",
      "Epoch 241/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 93us/step - loss: 0.4349 - acc: 0.7855 - val_loss: 0.5313 - val_acc: 0.7500\n",
      "Epoch 242/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4348 - acc: 0.7855 - val_loss: 0.5314 - val_acc: 0.7500\n",
      "Epoch 243/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4347 - acc: 0.7855 - val_loss: 0.5315 - val_acc: 0.7500\n",
      "Epoch 244/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4346 - acc: 0.7855 - val_loss: 0.5316 - val_acc: 0.7500\n",
      "Epoch 245/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4345 - acc: 0.7855 - val_loss: 0.5315 - val_acc: 0.7500\n",
      "Epoch 246/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4345 - acc: 0.7855 - val_loss: 0.5315 - val_acc: 0.7500\n",
      "Epoch 247/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4344 - acc: 0.7855 - val_loss: 0.5316 - val_acc: 0.7500\n",
      "Epoch 248/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4343 - acc: 0.7855 - val_loss: 0.5317 - val_acc: 0.7500\n",
      "Epoch 249/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4342 - acc: 0.7855 - val_loss: 0.5317 - val_acc: 0.7500\n",
      "Epoch 250/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4341 - acc: 0.7855 - val_loss: 0.5317 - val_acc: 0.7500\n",
      "Epoch 251/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4341 - acc: 0.7855 - val_loss: 0.5318 - val_acc: 0.7500\n",
      "Epoch 252/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4340 - acc: 0.7855 - val_loss: 0.5319 - val_acc: 0.7500\n",
      "Epoch 253/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4339 - acc: 0.7855 - val_loss: 0.5319 - val_acc: 0.7500\n",
      "Epoch 254/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4339 - acc: 0.7855 - val_loss: 0.5321 - val_acc: 0.7500\n",
      "Epoch 255/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4338 - acc: 0.7855 - val_loss: 0.5322 - val_acc: 0.7500\n",
      "Epoch 256/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4337 - acc: 0.7855 - val_loss: 0.5323 - val_acc: 0.7500\n",
      "Epoch 257/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4336 - acc: 0.7855 - val_loss: 0.5323 - val_acc: 0.7500\n",
      "Epoch 258/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4336 - acc: 0.7832 - val_loss: 0.5323 - val_acc: 0.7500\n",
      "Epoch 259/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4335 - acc: 0.7832 - val_loss: 0.5325 - val_acc: 0.7500\n",
      "Epoch 260/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4334 - acc: 0.7832 - val_loss: 0.5326 - val_acc: 0.7500\n",
      "Epoch 261/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4333 - acc: 0.7855 - val_loss: 0.5328 - val_acc: 0.7500\n",
      "Epoch 262/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4332 - acc: 0.7879 - val_loss: 0.5328 - val_acc: 0.7500\n",
      "Epoch 263/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4332 - acc: 0.7855 - val_loss: 0.5329 - val_acc: 0.7500\n",
      "Epoch 264/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4331 - acc: 0.7832 - val_loss: 0.5330 - val_acc: 0.7500\n",
      "Epoch 265/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4330 - acc: 0.7832 - val_loss: 0.5331 - val_acc: 0.7500\n",
      "Epoch 266/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4329 - acc: 0.7855 - val_loss: 0.5332 - val_acc: 0.7500\n",
      "Epoch 267/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4329 - acc: 0.7855 - val_loss: 0.5333 - val_acc: 0.7500\n",
      "Epoch 268/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4328 - acc: 0.7855 - val_loss: 0.5333 - val_acc: 0.7500\n",
      "Epoch 269/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4328 - acc: 0.7855 - val_loss: 0.5333 - val_acc: 0.7500\n",
      "Epoch 270/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4327 - acc: 0.7855 - val_loss: 0.5334 - val_acc: 0.7500\n",
      "Epoch 271/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4326 - acc: 0.7855 - val_loss: 0.5334 - val_acc: 0.7407\n",
      "Epoch 272/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4325 - acc: 0.7855 - val_loss: 0.5335 - val_acc: 0.7407\n",
      "Epoch 273/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4325 - acc: 0.7855 - val_loss: 0.5336 - val_acc: 0.7407\n",
      "Epoch 274/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4324 - acc: 0.7855 - val_loss: 0.5337 - val_acc: 0.7407\n",
      "Epoch 275/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4323 - acc: 0.7855 - val_loss: 0.5337 - val_acc: 0.7407\n",
      "Epoch 276/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4323 - acc: 0.7855 - val_loss: 0.5336 - val_acc: 0.7407\n",
      "Epoch 277/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4322 - acc: 0.7879 - val_loss: 0.5336 - val_acc: 0.7407\n",
      "Epoch 278/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4321 - acc: 0.7879 - val_loss: 0.5335 - val_acc: 0.7407\n",
      "Epoch 279/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4321 - acc: 0.7855 - val_loss: 0.5334 - val_acc: 0.7407\n",
      "Epoch 280/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4320 - acc: 0.7879 - val_loss: 0.5336 - val_acc: 0.7407\n",
      "Epoch 281/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4319 - acc: 0.7855 - val_loss: 0.5336 - val_acc: 0.7407\n",
      "Epoch 282/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4319 - acc: 0.7879 - val_loss: 0.5337 - val_acc: 0.7407\n",
      "Epoch 283/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4318 - acc: 0.7879 - val_loss: 0.5337 - val_acc: 0.7407\n",
      "Epoch 284/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4317 - acc: 0.7879 - val_loss: 0.5338 - val_acc: 0.7407\n",
      "Epoch 285/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4317 - acc: 0.7879 - val_loss: 0.5339 - val_acc: 0.7407\n",
      "Epoch 286/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4316 - acc: 0.7879 - val_loss: 0.5339 - val_acc: 0.7407\n",
      "Epoch 287/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4316 - acc: 0.7855 - val_loss: 0.5338 - val_acc: 0.7407\n",
      "Epoch 288/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4314 - acc: 0.7855 - val_loss: 0.5338 - val_acc: 0.7407\n",
      "Epoch 289/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4314 - acc: 0.7855 - val_loss: 0.5339 - val_acc: 0.7407\n",
      "Epoch 290/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4313 - acc: 0.7855 - val_loss: 0.5339 - val_acc: 0.7407\n",
      "Epoch 291/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4312 - acc: 0.7855 - val_loss: 0.5339 - val_acc: 0.7407\n",
      "Epoch 292/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4312 - acc: 0.7855 - val_loss: 0.5340 - val_acc: 0.7407\n",
      "Epoch 293/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4311 - acc: 0.7855 - val_loss: 0.5340 - val_acc: 0.7407\n",
      "Epoch 294/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4310 - acc: 0.7879 - val_loss: 0.5340 - val_acc: 0.7407\n",
      "Epoch 295/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4310 - acc: 0.7879 - val_loss: 0.5340 - val_acc: 0.7407\n",
      "Epoch 296/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4309 - acc: 0.7855 - val_loss: 0.5339 - val_acc: 0.7407\n",
      "Epoch 297/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4309 - acc: 0.7879 - val_loss: 0.5338 - val_acc: 0.7407\n",
      "Epoch 298/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4308 - acc: 0.7902 - val_loss: 0.5338 - val_acc: 0.7407\n",
      "Epoch 299/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4307 - acc: 0.7902 - val_loss: 0.5340 - val_acc: 0.7407\n",
      "Epoch 300/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4307 - acc: 0.7925 - val_loss: 0.5340 - val_acc: 0.7500\n",
      "Epoch 301/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4306 - acc: 0.7902 - val_loss: 0.5340 - val_acc: 0.7500\n",
      "Epoch 302/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4306 - acc: 0.7925 - val_loss: 0.5340 - val_acc: 0.7500\n",
      "Epoch 303/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4305 - acc: 0.7925 - val_loss: 0.5341 - val_acc: 0.7500\n",
      "Epoch 304/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4305 - acc: 0.7925 - val_loss: 0.5341 - val_acc: 0.7500\n",
      "Epoch 305/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4304 - acc: 0.7925 - val_loss: 0.5341 - val_acc: 0.7500\n",
      "Epoch 306/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4303 - acc: 0.7925 - val_loss: 0.5341 - val_acc: 0.7500\n",
      "Epoch 307/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4303 - acc: 0.7925 - val_loss: 0.5342 - val_acc: 0.7500\n",
      "Epoch 308/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4302 - acc: 0.7925 - val_loss: 0.5341 - val_acc: 0.7500\n",
      "Epoch 309/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4301 - acc: 0.7925 - val_loss: 0.5340 - val_acc: 0.7500\n",
      "Epoch 310/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4301 - acc: 0.7925 - val_loss: 0.5339 - val_acc: 0.7500\n",
      "Epoch 311/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4300 - acc: 0.7925 - val_loss: 0.5340 - val_acc: 0.7500\n",
      "Epoch 312/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4300 - acc: 0.7925 - val_loss: 0.5340 - val_acc: 0.7500\n",
      "Epoch 313/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4300 - acc: 0.7925 - val_loss: 0.5341 - val_acc: 0.7500\n",
      "Epoch 314/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4299 - acc: 0.7925 - val_loss: 0.5341 - val_acc: 0.7500\n",
      "Epoch 315/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4298 - acc: 0.7925 - val_loss: 0.5341 - val_acc: 0.7500\n",
      "Epoch 316/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4297 - acc: 0.7925 - val_loss: 0.5342 - val_acc: 0.7500\n",
      "Epoch 317/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4297 - acc: 0.7925 - val_loss: 0.5342 - val_acc: 0.7500\n",
      "Epoch 318/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4297 - acc: 0.7925 - val_loss: 0.5341 - val_acc: 0.7500\n",
      "Epoch 319/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4296 - acc: 0.7925 - val_loss: 0.5342 - val_acc: 0.7500\n",
      "Epoch 320/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4296 - acc: 0.7925 - val_loss: 0.5341 - val_acc: 0.7500\n",
      "Epoch 321/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4295 - acc: 0.7925 - val_loss: 0.5340 - val_acc: 0.7500\n",
      "Epoch 322/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4295 - acc: 0.7925 - val_loss: 0.5340 - val_acc: 0.7500\n",
      "Epoch 323/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4295 - acc: 0.7925 - val_loss: 0.5341 - val_acc: 0.7500\n",
      "Epoch 324/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4294 - acc: 0.7925 - val_loss: 0.5340 - val_acc: 0.7500\n",
      "Epoch 325/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4294 - acc: 0.7925 - val_loss: 0.5339 - val_acc: 0.7500\n",
      "Epoch 326/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4293 - acc: 0.7925 - val_loss: 0.5339 - val_acc: 0.7500\n",
      "Epoch 327/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4292 - acc: 0.7925 - val_loss: 0.5339 - val_acc: 0.7500\n",
      "Epoch 328/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4292 - acc: 0.7925 - val_loss: 0.5341 - val_acc: 0.7500\n",
      "Epoch 329/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4292 - acc: 0.7925 - val_loss: 0.5342 - val_acc: 0.7500\n",
      "Epoch 330/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4291 - acc: 0.7925 - val_loss: 0.5342 - val_acc: 0.7500\n",
      "Epoch 331/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4291 - acc: 0.7925 - val_loss: 0.5342 - val_acc: 0.7500\n",
      "Epoch 332/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4290 - acc: 0.7925 - val_loss: 0.5342 - val_acc: 0.7500\n",
      "Epoch 333/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4290 - acc: 0.7925 - val_loss: 0.5343 - val_acc: 0.7500\n",
      "Epoch 334/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4290 - acc: 0.7925 - val_loss: 0.5343 - val_acc: 0.7500\n",
      "Epoch 335/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4289 - acc: 0.7925 - val_loss: 0.5344 - val_acc: 0.7500\n",
      "Epoch 336/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4288 - acc: 0.7925 - val_loss: 0.5345 - val_acc: 0.7500\n",
      "Epoch 337/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4288 - acc: 0.7925 - val_loss: 0.5347 - val_acc: 0.7500\n",
      "Epoch 338/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4288 - acc: 0.7925 - val_loss: 0.5347 - val_acc: 0.7500\n",
      "Epoch 339/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4287 - acc: 0.7925 - val_loss: 0.5348 - val_acc: 0.7500\n",
      "Epoch 340/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4287 - acc: 0.7925 - val_loss: 0.5348 - val_acc: 0.7500\n",
      "Epoch 341/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4286 - acc: 0.7925 - val_loss: 0.5348 - val_acc: 0.7500\n",
      "Epoch 342/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4286 - acc: 0.7925 - val_loss: 0.5346 - val_acc: 0.7500\n",
      "Epoch 343/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4286 - acc: 0.7925 - val_loss: 0.5346 - val_acc: 0.7500\n",
      "Epoch 344/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4285 - acc: 0.7925 - val_loss: 0.5346 - val_acc: 0.7500\n",
      "Epoch 345/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4285 - acc: 0.7925 - val_loss: 0.5346 - val_acc: 0.7500\n",
      "Epoch 346/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4284 - acc: 0.7925 - val_loss: 0.5347 - val_acc: 0.7500\n",
      "Epoch 347/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4284 - acc: 0.7925 - val_loss: 0.5347 - val_acc: 0.7500\n",
      "Epoch 348/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4283 - acc: 0.7925 - val_loss: 0.5348 - val_acc: 0.7500\n",
      "Epoch 349/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4283 - acc: 0.7925 - val_loss: 0.5348 - val_acc: 0.7500\n",
      "Epoch 350/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4282 - acc: 0.7925 - val_loss: 0.5349 - val_acc: 0.7500\n",
      "Epoch 351/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4282 - acc: 0.7925 - val_loss: 0.5349 - val_acc: 0.7500\n",
      "Epoch 352/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4282 - acc: 0.7925 - val_loss: 0.5349 - val_acc: 0.7500\n",
      "Epoch 353/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4281 - acc: 0.7925 - val_loss: 0.5350 - val_acc: 0.7500\n",
      "Epoch 354/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4281 - acc: 0.7925 - val_loss: 0.5351 - val_acc: 0.7500\n",
      "Epoch 355/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4280 - acc: 0.7925 - val_loss: 0.5352 - val_acc: 0.7500\n",
      "Epoch 356/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4280 - acc: 0.7925 - val_loss: 0.5352 - val_acc: 0.7593\n",
      "Epoch 357/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4280 - acc: 0.7925 - val_loss: 0.5352 - val_acc: 0.7593\n",
      "Epoch 358/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4279 - acc: 0.7925 - val_loss: 0.5351 - val_acc: 0.7593\n",
      "Epoch 359/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4279 - acc: 0.7925 - val_loss: 0.5352 - val_acc: 0.7593\n",
      "Epoch 360/900\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.4279 - acc: 0.7925 - val_loss: 0.5352 - val_acc: 0.7593\n",
      "Epoch 361/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 75us/step - loss: 0.4278 - acc: 0.7925 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 362/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4278 - acc: 0.7925 - val_loss: 0.5354 - val_acc: 0.7593\n",
      "Epoch 363/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4277 - acc: 0.7925 - val_loss: 0.5354 - val_acc: 0.7593\n",
      "Epoch 364/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4277 - acc: 0.7925 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 365/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4276 - acc: 0.7925 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 366/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4276 - acc: 0.7925 - val_loss: 0.5352 - val_acc: 0.7593\n",
      "Epoch 367/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4276 - acc: 0.7925 - val_loss: 0.5352 - val_acc: 0.7593\n",
      "Epoch 368/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4275 - acc: 0.7925 - val_loss: 0.5352 - val_acc: 0.7593\n",
      "Epoch 369/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4275 - acc: 0.7925 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 370/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4274 - acc: 0.7925 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 371/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4274 - acc: 0.7925 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 372/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4274 - acc: 0.7925 - val_loss: 0.5354 - val_acc: 0.7593\n",
      "Epoch 373/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4273 - acc: 0.7925 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 374/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4273 - acc: 0.7925 - val_loss: 0.5354 - val_acc: 0.7593\n",
      "Epoch 375/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4272 - acc: 0.7949 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 376/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4272 - acc: 0.7925 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 377/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4272 - acc: 0.7925 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 378/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4272 - acc: 0.7925 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 379/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4271 - acc: 0.7925 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 380/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4271 - acc: 0.7925 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 381/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4270 - acc: 0.7949 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 382/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4269 - acc: 0.7949 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 383/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4269 - acc: 0.7925 - val_loss: 0.5354 - val_acc: 0.7593\n",
      "Epoch 384/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4269 - acc: 0.7949 - val_loss: 0.5355 - val_acc: 0.7593\n",
      "Epoch 385/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4268 - acc: 0.7949 - val_loss: 0.5355 - val_acc: 0.7593\n",
      "Epoch 386/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4268 - acc: 0.7949 - val_loss: 0.5355 - val_acc: 0.7593\n",
      "Epoch 387/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4268 - acc: 0.7949 - val_loss: 0.5356 - val_acc: 0.7593\n",
      "Epoch 388/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4268 - acc: 0.7949 - val_loss: 0.5355 - val_acc: 0.7593\n",
      "Epoch 389/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4267 - acc: 0.7972 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 390/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4267 - acc: 0.7925 - val_loss: 0.5354 - val_acc: 0.7593\n",
      "Epoch 391/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4266 - acc: 0.7925 - val_loss: 0.5354 - val_acc: 0.7593\n",
      "Epoch 392/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4266 - acc: 0.7972 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 393/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4265 - acc: 0.7972 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 394/900\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.4265 - acc: 0.7972 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 395/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4264 - acc: 0.7949 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 396/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4265 - acc: 0.7949 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 397/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4264 - acc: 0.7972 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 398/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4263 - acc: 0.7949 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 399/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4263 - acc: 0.7972 - val_loss: 0.5351 - val_acc: 0.7593\n",
      "Epoch 400/900\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.4263 - acc: 0.7972 - val_loss: 0.5351 - val_acc: 0.7593\n",
      "Epoch 401/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4262 - acc: 0.7949 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 402/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4262 - acc: 0.7972 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 403/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4261 - acc: 0.7949 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 404/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4261 - acc: 0.7972 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 405/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4260 - acc: 0.7972 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 406/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4260 - acc: 0.7972 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 407/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4260 - acc: 0.7972 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 408/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4259 - acc: 0.7972 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 409/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4259 - acc: 0.7972 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 410/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4259 - acc: 0.7972 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 411/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4258 - acc: 0.7972 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 412/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4258 - acc: 0.7972 - val_loss: 0.5351 - val_acc: 0.7593\n",
      "Epoch 413/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4258 - acc: 0.7972 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 414/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4257 - acc: 0.7972 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 415/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4257 - acc: 0.7972 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 416/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4256 - acc: 0.7972 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 417/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4256 - acc: 0.7972 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 418/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4255 - acc: 0.7972 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 419/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4255 - acc: 0.7972 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 420/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4255 - acc: 0.7972 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 421/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4254 - acc: 0.7972 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 422/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4254 - acc: 0.7972 - val_loss: 0.5351 - val_acc: 0.7593\n",
      "Epoch 423/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4254 - acc: 0.7972 - val_loss: 0.5351 - val_acc: 0.7593\n",
      "Epoch 424/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4253 - acc: 0.7972 - val_loss: 0.5351 - val_acc: 0.7593\n",
      "Epoch 425/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4253 - acc: 0.7972 - val_loss: 0.5352 - val_acc: 0.7593\n",
      "Epoch 426/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4252 - acc: 0.7972 - val_loss: 0.5351 - val_acc: 0.7593\n",
      "Epoch 427/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4252 - acc: 0.7972 - val_loss: 0.5352 - val_acc: 0.7593\n",
      "Epoch 428/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4251 - acc: 0.7972 - val_loss: 0.5351 - val_acc: 0.7593\n",
      "Epoch 429/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4252 - acc: 0.7972 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 430/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4251 - acc: 0.7972 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 431/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4250 - acc: 0.7972 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 432/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4250 - acc: 0.7995 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 433/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4250 - acc: 0.7995 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 434/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4249 - acc: 0.8019 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 435/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4249 - acc: 0.8019 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 436/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4248 - acc: 0.7995 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 437/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4248 - acc: 0.7995 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 438/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4247 - acc: 0.7995 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 439/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4247 - acc: 0.7995 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 440/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4247 - acc: 0.8019 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 441/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4246 - acc: 0.8019 - val_loss: 0.5351 - val_acc: 0.7593\n",
      "Epoch 442/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4246 - acc: 0.7995 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 443/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4245 - acc: 0.8019 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 444/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4245 - acc: 0.8019 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 445/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4245 - acc: 0.7995 - val_loss: 0.5351 - val_acc: 0.7593\n",
      "Epoch 446/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4244 - acc: 0.8019 - val_loss: 0.5351 - val_acc: 0.7593\n",
      "Epoch 447/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4245 - acc: 0.8019 - val_loss: 0.5351 - val_acc: 0.7593\n",
      "Epoch 448/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4243 - acc: 0.8019 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 449/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4244 - acc: 0.7995 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 450/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4243 - acc: 0.8019 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 451/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4242 - acc: 0.8019 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 452/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4242 - acc: 0.8019 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 453/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4242 - acc: 0.8019 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 454/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4241 - acc: 0.8019 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 455/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4241 - acc: 0.8019 - val_loss: 0.5347 - val_acc: 0.7593\n",
      "Epoch 456/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4240 - acc: 0.8019 - val_loss: 0.5346 - val_acc: 0.7593\n",
      "Epoch 457/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4240 - acc: 0.8019 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 458/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4240 - acc: 0.8019 - val_loss: 0.5346 - val_acc: 0.7593\n",
      "Epoch 459/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4239 - acc: 0.8019 - val_loss: 0.5346 - val_acc: 0.7593\n",
      "Epoch 460/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4239 - acc: 0.8019 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 461/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4238 - acc: 0.8019 - val_loss: 0.5346 - val_acc: 0.7593\n",
      "Epoch 462/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4238 - acc: 0.8019 - val_loss: 0.5346 - val_acc: 0.7593\n",
      "Epoch 463/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4238 - acc: 0.8019 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 464/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4237 - acc: 0.8019 - val_loss: 0.5344 - val_acc: 0.7593\n",
      "Epoch 465/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4237 - acc: 0.8019 - val_loss: 0.5343 - val_acc: 0.7593\n",
      "Epoch 466/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4236 - acc: 0.8019 - val_loss: 0.5343 - val_acc: 0.7593\n",
      "Epoch 467/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4236 - acc: 0.8019 - val_loss: 0.5343 - val_acc: 0.7593\n",
      "Epoch 468/900\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.4236 - acc: 0.8019 - val_loss: 0.5342 - val_acc: 0.7593\n",
      "Epoch 469/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4235 - acc: 0.8019 - val_loss: 0.5342 - val_acc: 0.7593\n",
      "Epoch 470/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4235 - acc: 0.8019 - val_loss: 0.5342 - val_acc: 0.7593\n",
      "Epoch 471/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4235 - acc: 0.8019 - val_loss: 0.5343 - val_acc: 0.7593\n",
      "Epoch 472/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4235 - acc: 0.8019 - val_loss: 0.5342 - val_acc: 0.7593\n",
      "Epoch 473/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4234 - acc: 0.8019 - val_loss: 0.5342 - val_acc: 0.7593\n",
      "Epoch 474/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4234 - acc: 0.8019 - val_loss: 0.5342 - val_acc: 0.7593\n",
      "Epoch 475/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4233 - acc: 0.8019 - val_loss: 0.5343 - val_acc: 0.7593\n",
      "Epoch 476/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4233 - acc: 0.8019 - val_loss: 0.5342 - val_acc: 0.7593\n",
      "Epoch 477/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4233 - acc: 0.8019 - val_loss: 0.5343 - val_acc: 0.7593\n",
      "Epoch 478/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4233 - acc: 0.8019 - val_loss: 0.5342 - val_acc: 0.7593\n",
      "Epoch 479/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4232 - acc: 0.8019 - val_loss: 0.5342 - val_acc: 0.7593\n",
      "Epoch 480/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4232 - acc: 0.8019 - val_loss: 0.5343 - val_acc: 0.7593\n",
      "Epoch 481/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 75us/step - loss: 0.4231 - acc: 0.8019 - val_loss: 0.5344 - val_acc: 0.7593\n",
      "Epoch 482/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4231 - acc: 0.8019 - val_loss: 0.5343 - val_acc: 0.7593\n",
      "Epoch 483/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4230 - acc: 0.8019 - val_loss: 0.5343 - val_acc: 0.7593\n",
      "Epoch 484/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4230 - acc: 0.8019 - val_loss: 0.5342 - val_acc: 0.7593\n",
      "Epoch 485/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4230 - acc: 0.8019 - val_loss: 0.5343 - val_acc: 0.7593\n",
      "Epoch 486/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4230 - acc: 0.8019 - val_loss: 0.5343 - val_acc: 0.7593\n",
      "Epoch 487/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4230 - acc: 0.8019 - val_loss: 0.5344 - val_acc: 0.7593\n",
      "Epoch 488/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4230 - acc: 0.8019 - val_loss: 0.5342 - val_acc: 0.7593\n",
      "Epoch 489/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4228 - acc: 0.8019 - val_loss: 0.5343 - val_acc: 0.7593\n",
      "Epoch 490/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4228 - acc: 0.8019 - val_loss: 0.5344 - val_acc: 0.7593\n",
      "Epoch 491/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4227 - acc: 0.8019 - val_loss: 0.5343 - val_acc: 0.7593\n",
      "Epoch 492/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4227 - acc: 0.8019 - val_loss: 0.5344 - val_acc: 0.7593\n",
      "Epoch 493/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4227 - acc: 0.8019 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 494/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4227 - acc: 0.8019 - val_loss: 0.5346 - val_acc: 0.7593\n",
      "Epoch 495/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4226 - acc: 0.8019 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 496/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4226 - acc: 0.8019 - val_loss: 0.5346 - val_acc: 0.7593\n",
      "Epoch 497/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4226 - acc: 0.8019 - val_loss: 0.5347 - val_acc: 0.7593\n",
      "Epoch 498/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4225 - acc: 0.8019 - val_loss: 0.5346 - val_acc: 0.7593\n",
      "Epoch 499/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4225 - acc: 0.8019 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 500/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4224 - acc: 0.8019 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 501/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4224 - acc: 0.8019 - val_loss: 0.5344 - val_acc: 0.7593\n",
      "Epoch 502/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4224 - acc: 0.8019 - val_loss: 0.5343 - val_acc: 0.7593\n",
      "Epoch 503/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4223 - acc: 0.8019 - val_loss: 0.5344 - val_acc: 0.7593\n",
      "Epoch 504/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4223 - acc: 0.8019 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 505/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4222 - acc: 0.8019 - val_loss: 0.5344 - val_acc: 0.7593\n",
      "Epoch 506/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4222 - acc: 0.8019 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 507/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4222 - acc: 0.8019 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 508/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4221 - acc: 0.8019 - val_loss: 0.5344 - val_acc: 0.7593\n",
      "Epoch 509/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4221 - acc: 0.7995 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 510/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4220 - acc: 0.7995 - val_loss: 0.5346 - val_acc: 0.7593\n",
      "Epoch 511/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4220 - acc: 0.8019 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 512/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4219 - acc: 0.7995 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 513/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4219 - acc: 0.7995 - val_loss: 0.5346 - val_acc: 0.7593\n",
      "Epoch 514/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4219 - acc: 0.7995 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 515/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4219 - acc: 0.7995 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 516/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4218 - acc: 0.7995 - val_loss: 0.5346 - val_acc: 0.7593\n",
      "Epoch 517/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4218 - acc: 0.7995 - val_loss: 0.5347 - val_acc: 0.7593\n",
      "Epoch 518/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4218 - acc: 0.7995 - val_loss: 0.5348 - val_acc: 0.7593\n",
      "Epoch 519/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4217 - acc: 0.7995 - val_loss: 0.5348 - val_acc: 0.7593\n",
      "Epoch 520/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4217 - acc: 0.7995 - val_loss: 0.5347 - val_acc: 0.7593\n",
      "Epoch 521/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4217 - acc: 0.7995 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 522/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4216 - acc: 0.7995 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 523/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4216 - acc: 0.7995 - val_loss: 0.5346 - val_acc: 0.7593\n",
      "Epoch 524/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4215 - acc: 0.7995 - val_loss: 0.5346 - val_acc: 0.7593\n",
      "Epoch 525/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4215 - acc: 0.7995 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 526/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4214 - acc: 0.7995 - val_loss: 0.5345 - val_acc: 0.7593\n",
      "Epoch 527/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4214 - acc: 0.7995 - val_loss: 0.5346 - val_acc: 0.7593\n",
      "Epoch 528/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4214 - acc: 0.7995 - val_loss: 0.5346 - val_acc: 0.7593\n",
      "Epoch 529/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4214 - acc: 0.7995 - val_loss: 0.5347 - val_acc: 0.7593\n",
      "Epoch 530/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4213 - acc: 0.7995 - val_loss: 0.5348 - val_acc: 0.7593\n",
      "Epoch 531/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4213 - acc: 0.7995 - val_loss: 0.5348 - val_acc: 0.7593\n",
      "Epoch 532/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4212 - acc: 0.7995 - val_loss: 0.5348 - val_acc: 0.7593\n",
      "Epoch 533/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4212 - acc: 0.7995 - val_loss: 0.5348 - val_acc: 0.7593\n",
      "Epoch 534/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4212 - acc: 0.7995 - val_loss: 0.5348 - val_acc: 0.7593\n",
      "Epoch 535/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4211 - acc: 0.7995 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 536/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4210 - acc: 0.7995 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 537/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4210 - acc: 0.7995 - val_loss: 0.5349 - val_acc: 0.7593\n",
      "Epoch 538/900\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.4210 - acc: 0.7995 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 539/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4209 - acc: 0.7995 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 540/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4209 - acc: 0.7995 - val_loss: 0.5350 - val_acc: 0.7593\n",
      "Epoch 541/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4208 - acc: 0.7995 - val_loss: 0.5352 - val_acc: 0.7593\n",
      "Epoch 542/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4208 - acc: 0.7995 - val_loss: 0.5352 - val_acc: 0.7593\n",
      "Epoch 543/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4208 - acc: 0.7995 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 544/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4207 - acc: 0.7995 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 545/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4207 - acc: 0.7995 - val_loss: 0.5352 - val_acc: 0.7593\n",
      "Epoch 546/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4207 - acc: 0.7995 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 547/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4206 - acc: 0.7995 - val_loss: 0.5354 - val_acc: 0.7593\n",
      "Epoch 548/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4206 - acc: 0.7995 - val_loss: 0.5355 - val_acc: 0.7593\n",
      "Epoch 549/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4206 - acc: 0.7995 - val_loss: 0.5354 - val_acc: 0.7593\n",
      "Epoch 550/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4205 - acc: 0.7995 - val_loss: 0.5354 - val_acc: 0.7593\n",
      "Epoch 551/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4205 - acc: 0.7995 - val_loss: 0.5354 - val_acc: 0.7593\n",
      "Epoch 552/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4204 - acc: 0.7995 - val_loss: 0.5353 - val_acc: 0.7593\n",
      "Epoch 553/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4204 - acc: 0.7995 - val_loss: 0.5354 - val_acc: 0.7593\n",
      "Epoch 554/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4204 - acc: 0.7995 - val_loss: 0.5354 - val_acc: 0.7593\n",
      "Epoch 555/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4204 - acc: 0.7995 - val_loss: 0.5354 - val_acc: 0.7593\n",
      "Epoch 556/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4203 - acc: 0.7995 - val_loss: 0.5355 - val_acc: 0.7593\n",
      "Epoch 557/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4203 - acc: 0.7995 - val_loss: 0.5355 - val_acc: 0.7593\n",
      "Epoch 558/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4203 - acc: 0.7995 - val_loss: 0.5355 - val_acc: 0.7593\n",
      "Epoch 559/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4202 - acc: 0.7995 - val_loss: 0.5356 - val_acc: 0.7593\n",
      "Epoch 560/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4202 - acc: 0.7995 - val_loss: 0.5356 - val_acc: 0.7593\n",
      "Epoch 561/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4202 - acc: 0.8019 - val_loss: 0.5356 - val_acc: 0.7593\n",
      "Epoch 562/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4201 - acc: 0.7995 - val_loss: 0.5357 - val_acc: 0.7593\n",
      "Epoch 563/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4201 - acc: 0.7995 - val_loss: 0.5357 - val_acc: 0.7593\n",
      "Epoch 564/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4201 - acc: 0.7995 - val_loss: 0.5357 - val_acc: 0.7593\n",
      "Epoch 565/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4200 - acc: 0.8019 - val_loss: 0.5357 - val_acc: 0.7593\n",
      "Epoch 566/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4199 - acc: 0.8019 - val_loss: 0.5357 - val_acc: 0.7593\n",
      "Epoch 567/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4199 - acc: 0.8019 - val_loss: 0.5358 - val_acc: 0.7593\n",
      "Epoch 568/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4199 - acc: 0.8019 - val_loss: 0.5358 - val_acc: 0.7593\n",
      "Epoch 569/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4199 - acc: 0.8019 - val_loss: 0.5359 - val_acc: 0.7593\n",
      "Epoch 570/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4198 - acc: 0.8019 - val_loss: 0.5360 - val_acc: 0.7593\n",
      "Epoch 571/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4199 - acc: 0.8019 - val_loss: 0.5360 - val_acc: 0.7593\n",
      "Epoch 572/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4198 - acc: 0.8019 - val_loss: 0.5360 - val_acc: 0.7593\n",
      "Epoch 573/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4198 - acc: 0.7995 - val_loss: 0.5360 - val_acc: 0.7593\n",
      "Epoch 574/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4197 - acc: 0.8019 - val_loss: 0.5360 - val_acc: 0.7593\n",
      "Epoch 575/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4196 - acc: 0.8019 - val_loss: 0.5361 - val_acc: 0.7593\n",
      "Epoch 576/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4196 - acc: 0.8019 - val_loss: 0.5361 - val_acc: 0.7593\n",
      "Epoch 577/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4196 - acc: 0.8019 - val_loss: 0.5362 - val_acc: 0.7593\n",
      "Epoch 578/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4196 - acc: 0.8019 - val_loss: 0.5362 - val_acc: 0.7593\n",
      "Epoch 579/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4196 - acc: 0.8019 - val_loss: 0.5363 - val_acc: 0.7593\n",
      "Epoch 580/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4195 - acc: 0.8019 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 581/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4195 - acc: 0.8019 - val_loss: 0.5363 - val_acc: 0.7593\n",
      "Epoch 582/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4194 - acc: 0.8019 - val_loss: 0.5365 - val_acc: 0.7593\n",
      "Epoch 583/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4194 - acc: 0.8019 - val_loss: 0.5365 - val_acc: 0.7593\n",
      "Epoch 584/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4194 - acc: 0.8019 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 585/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4193 - acc: 0.8019 - val_loss: 0.5365 - val_acc: 0.7593\n",
      "Epoch 586/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4193 - acc: 0.8019 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 587/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4192 - acc: 0.8019 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 588/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4192 - acc: 0.8042 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 589/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4192 - acc: 0.8019 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 590/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4192 - acc: 0.8042 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 591/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4191 - acc: 0.8019 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 592/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4191 - acc: 0.8042 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 593/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4191 - acc: 0.8019 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 594/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4191 - acc: 0.8019 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 595/900\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.4190 - acc: 0.8019 - val_loss: 0.5363 - val_acc: 0.7593\n",
      "Epoch 596/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4190 - acc: 0.8019 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 597/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4190 - acc: 0.8019 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 598/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4189 - acc: 0.8019 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 599/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4189 - acc: 0.8019 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 600/900\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.4189 - acc: 0.8019 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 601/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 84us/step - loss: 0.4189 - acc: 0.8019 - val_loss: 0.5364 - val_acc: 0.7593\n",
      "Epoch 602/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4188 - acc: 0.8019 - val_loss: 0.5365 - val_acc: 0.7593\n",
      "Epoch 603/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4187 - acc: 0.8019 - val_loss: 0.5366 - val_acc: 0.7593\n",
      "Epoch 604/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4187 - acc: 0.8019 - val_loss: 0.5365 - val_acc: 0.7593\n",
      "Epoch 605/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4187 - acc: 0.8019 - val_loss: 0.5366 - val_acc: 0.7593\n",
      "Epoch 606/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4186 - acc: 0.8019 - val_loss: 0.5366 - val_acc: 0.7593\n",
      "Epoch 607/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4186 - acc: 0.7995 - val_loss: 0.5366 - val_acc: 0.7593\n",
      "Epoch 608/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4186 - acc: 0.7995 - val_loss: 0.5366 - val_acc: 0.7593\n",
      "Epoch 609/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4186 - acc: 0.7995 - val_loss: 0.5367 - val_acc: 0.7593\n",
      "Epoch 610/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4186 - acc: 0.7995 - val_loss: 0.5367 - val_acc: 0.7593\n",
      "Epoch 611/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4185 - acc: 0.8019 - val_loss: 0.5368 - val_acc: 0.7593\n",
      "Epoch 612/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4185 - acc: 0.7995 - val_loss: 0.5369 - val_acc: 0.7593\n",
      "Epoch 613/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4185 - acc: 0.7972 - val_loss: 0.5369 - val_acc: 0.7593\n",
      "Epoch 614/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4184 - acc: 0.7972 - val_loss: 0.5370 - val_acc: 0.7593\n",
      "Epoch 615/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4184 - acc: 0.7972 - val_loss: 0.5370 - val_acc: 0.7593\n",
      "Epoch 616/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4183 - acc: 0.7995 - val_loss: 0.5371 - val_acc: 0.7593\n",
      "Epoch 617/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4184 - acc: 0.7995 - val_loss: 0.5371 - val_acc: 0.7593\n",
      "Epoch 618/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4183 - acc: 0.7995 - val_loss: 0.5370 - val_acc: 0.7593\n",
      "Epoch 619/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4182 - acc: 0.7972 - val_loss: 0.5370 - val_acc: 0.7593\n",
      "Epoch 620/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4182 - acc: 0.7972 - val_loss: 0.5371 - val_acc: 0.7593\n",
      "Epoch 621/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4182 - acc: 0.7972 - val_loss: 0.5372 - val_acc: 0.7593\n",
      "Epoch 622/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4181 - acc: 0.7995 - val_loss: 0.5372 - val_acc: 0.7593\n",
      "Epoch 623/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4181 - acc: 0.7972 - val_loss: 0.5372 - val_acc: 0.7593\n",
      "Epoch 624/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4181 - acc: 0.7972 - val_loss: 0.5370 - val_acc: 0.7593\n",
      "Epoch 625/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4181 - acc: 0.7972 - val_loss: 0.5370 - val_acc: 0.7593\n",
      "Epoch 626/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4180 - acc: 0.7972 - val_loss: 0.5369 - val_acc: 0.7593\n",
      "Epoch 627/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4180 - acc: 0.7972 - val_loss: 0.5369 - val_acc: 0.7593\n",
      "Epoch 628/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4180 - acc: 0.7972 - val_loss: 0.5369 - val_acc: 0.7593\n",
      "Epoch 629/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4180 - acc: 0.7972 - val_loss: 0.5370 - val_acc: 0.7593\n",
      "Epoch 630/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4179 - acc: 0.7972 - val_loss: 0.5369 - val_acc: 0.7593\n",
      "Epoch 631/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4179 - acc: 0.7972 - val_loss: 0.5370 - val_acc: 0.7593\n",
      "Epoch 632/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4178 - acc: 0.7972 - val_loss: 0.5370 - val_acc: 0.7593\n",
      "Epoch 633/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4178 - acc: 0.7972 - val_loss: 0.5370 - val_acc: 0.7593\n",
      "Epoch 634/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4178 - acc: 0.7972 - val_loss: 0.5370 - val_acc: 0.7593\n",
      "Epoch 635/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4177 - acc: 0.7972 - val_loss: 0.5370 - val_acc: 0.7593\n",
      "Epoch 636/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4177 - acc: 0.7972 - val_loss: 0.5371 - val_acc: 0.7593\n",
      "Epoch 637/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4177 - acc: 0.7972 - val_loss: 0.5370 - val_acc: 0.7593\n",
      "Epoch 638/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4176 - acc: 0.7972 - val_loss: 0.5370 - val_acc: 0.7593\n",
      "Epoch 639/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4176 - acc: 0.7972 - val_loss: 0.5369 - val_acc: 0.7593\n",
      "Epoch 640/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4176 - acc: 0.7972 - val_loss: 0.5369 - val_acc: 0.7593\n",
      "Epoch 641/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4176 - acc: 0.7972 - val_loss: 0.5368 - val_acc: 0.7593\n",
      "Epoch 642/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4176 - acc: 0.7972 - val_loss: 0.5367 - val_acc: 0.7593\n",
      "Epoch 643/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4175 - acc: 0.7972 - val_loss: 0.5367 - val_acc: 0.7593\n",
      "Epoch 644/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4175 - acc: 0.7972 - val_loss: 0.5367 - val_acc: 0.7593\n",
      "Epoch 645/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4175 - acc: 0.7972 - val_loss: 0.5367 - val_acc: 0.7593\n",
      "Epoch 646/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4175 - acc: 0.7972 - val_loss: 0.5367 - val_acc: 0.7593\n",
      "Epoch 647/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4174 - acc: 0.7972 - val_loss: 0.5367 - val_acc: 0.7593\n",
      "Epoch 648/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4174 - acc: 0.7972 - val_loss: 0.5367 - val_acc: 0.7593\n",
      "Epoch 649/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4174 - acc: 0.7972 - val_loss: 0.5368 - val_acc: 0.7593\n",
      "Epoch 650/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4174 - acc: 0.7972 - val_loss: 0.5368 - val_acc: 0.7593\n",
      "Epoch 651/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4173 - acc: 0.7972 - val_loss: 0.5368 - val_acc: 0.7593\n",
      "Epoch 652/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4173 - acc: 0.7972 - val_loss: 0.5367 - val_acc: 0.7593\n",
      "Epoch 653/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4173 - acc: 0.7972 - val_loss: 0.5367 - val_acc: 0.7593\n",
      "Epoch 654/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4172 - acc: 0.7972 - val_loss: 0.5367 - val_acc: 0.7593\n",
      "Epoch 655/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4171 - acc: 0.7972 - val_loss: 0.5366 - val_acc: 0.7593\n",
      "Epoch 656/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4171 - acc: 0.7972 - val_loss: 0.5366 - val_acc: 0.7593\n",
      "Epoch 657/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4171 - acc: 0.7972 - val_loss: 0.5367 - val_acc: 0.7593\n",
      "Epoch 658/900\n",
      "429/429 [==============================] - 0s 99us/step - loss: 0.4171 - acc: 0.7972 - val_loss: 0.5367 - val_acc: 0.7593\n",
      "Epoch 659/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4171 - acc: 0.7972 - val_loss: 0.5368 - val_acc: 0.7593\n",
      "Epoch 660/900\n",
      "429/429 [==============================] - 0s 92us/step - loss: 0.4171 - acc: 0.7972 - val_loss: 0.5368 - val_acc: 0.7593\n",
      "Epoch 661/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4170 - acc: 0.7972 - val_loss: 0.5368 - val_acc: 0.7593\n",
      "Epoch 662/900\n",
      "429/429 [==============================] - 0s 94us/step - loss: 0.4170 - acc: 0.7972 - val_loss: 0.5369 - val_acc: 0.7593\n",
      "Epoch 663/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4170 - acc: 0.7972 - val_loss: 0.5369 - val_acc: 0.7593\n",
      "Epoch 664/900\n",
      "429/429 [==============================] - 0s 94us/step - loss: 0.4169 - acc: 0.7972 - val_loss: 0.5369 - val_acc: 0.7593\n",
      "Epoch 665/900\n",
      "429/429 [==============================] - 0s 99us/step - loss: 0.4169 - acc: 0.7972 - val_loss: 0.5369 - val_acc: 0.7593\n",
      "Epoch 666/900\n",
      "429/429 [==============================] - 0s 101us/step - loss: 0.4169 - acc: 0.7972 - val_loss: 0.5370 - val_acc: 0.7593\n",
      "Epoch 667/900\n",
      "429/429 [==============================] - 0s 92us/step - loss: 0.4168 - acc: 0.7972 - val_loss: 0.5371 - val_acc: 0.7593\n",
      "Epoch 668/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4168 - acc: 0.7972 - val_loss: 0.5372 - val_acc: 0.7593\n",
      "Epoch 669/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4167 - acc: 0.7972 - val_loss: 0.5371 - val_acc: 0.7593\n",
      "Epoch 670/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4167 - acc: 0.7972 - val_loss: 0.5372 - val_acc: 0.7593\n",
      "Epoch 671/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4167 - acc: 0.7972 - val_loss: 0.5372 - val_acc: 0.7593\n",
      "Epoch 672/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4167 - acc: 0.7972 - val_loss: 0.5373 - val_acc: 0.7593\n",
      "Epoch 673/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4167 - acc: 0.7972 - val_loss: 0.5372 - val_acc: 0.7593\n",
      "Epoch 674/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4166 - acc: 0.7972 - val_loss: 0.5373 - val_acc: 0.7593\n",
      "Epoch 675/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4166 - acc: 0.7972 - val_loss: 0.5374 - val_acc: 0.7593\n",
      "Epoch 676/900\n",
      "429/429 [==============================] - 0s 99us/step - loss: 0.4165 - acc: 0.7972 - val_loss: 0.5374 - val_acc: 0.7593\n",
      "Epoch 677/900\n",
      "429/429 [==============================] - 0s 94us/step - loss: 0.4165 - acc: 0.7972 - val_loss: 0.5375 - val_acc: 0.7593\n",
      "Epoch 678/900\n",
      "429/429 [==============================] - 0s 99us/step - loss: 0.4164 - acc: 0.7972 - val_loss: 0.5376 - val_acc: 0.7593\n",
      "Epoch 679/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4165 - acc: 0.7972 - val_loss: 0.5376 - val_acc: 0.7593\n",
      "Epoch 680/900\n",
      "429/429 [==============================] - 0s 94us/step - loss: 0.4164 - acc: 0.7972 - val_loss: 0.5375 - val_acc: 0.7593\n",
      "Epoch 681/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4164 - acc: 0.7972 - val_loss: 0.5376 - val_acc: 0.7593\n",
      "Epoch 682/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4164 - acc: 0.7972 - val_loss: 0.5376 - val_acc: 0.7593\n",
      "Epoch 683/900\n",
      "429/429 [==============================] - 0s 99us/step - loss: 0.4164 - acc: 0.7972 - val_loss: 0.5375 - val_acc: 0.7593\n",
      "Epoch 684/900\n",
      "429/429 [==============================] - 0s 97us/step - loss: 0.4163 - acc: 0.7972 - val_loss: 0.5376 - val_acc: 0.7593\n",
      "Epoch 685/900\n",
      "429/429 [==============================] - 0s 92us/step - loss: 0.4163 - acc: 0.7972 - val_loss: 0.5376 - val_acc: 0.7593\n",
      "Epoch 686/900\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.4163 - acc: 0.7972 - val_loss: 0.5377 - val_acc: 0.7593\n",
      "Epoch 687/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4162 - acc: 0.7972 - val_loss: 0.5377 - val_acc: 0.7593\n",
      "Epoch 688/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4162 - acc: 0.7972 - val_loss: 0.5377 - val_acc: 0.7593\n",
      "Epoch 689/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4162 - acc: 0.7972 - val_loss: 0.5377 - val_acc: 0.7593\n",
      "Epoch 690/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4161 - acc: 0.7972 - val_loss: 0.5377 - val_acc: 0.7593\n",
      "Epoch 691/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4162 - acc: 0.7972 - val_loss: 0.5379 - val_acc: 0.7593\n",
      "Epoch 692/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4161 - acc: 0.7972 - val_loss: 0.5380 - val_acc: 0.7593\n",
      "Epoch 693/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4160 - acc: 0.7972 - val_loss: 0.5380 - val_acc: 0.7593\n",
      "Epoch 694/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4160 - acc: 0.7972 - val_loss: 0.5380 - val_acc: 0.7593\n",
      "Epoch 695/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4160 - acc: 0.7972 - val_loss: 0.5379 - val_acc: 0.7593\n",
      "Epoch 696/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4160 - acc: 0.7972 - val_loss: 0.5378 - val_acc: 0.7593\n",
      "Epoch 697/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4159 - acc: 0.7972 - val_loss: 0.5378 - val_acc: 0.7593\n",
      "Epoch 698/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4159 - acc: 0.7995 - val_loss: 0.5379 - val_acc: 0.7593\n",
      "Epoch 699/900\n",
      "429/429 [==============================] - 0s 95us/step - loss: 0.4158 - acc: 0.7995 - val_loss: 0.5379 - val_acc: 0.7593\n",
      "Epoch 700/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4159 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7593\n",
      "Epoch 701/900\n",
      "429/429 [==============================] - 0s 98us/step - loss: 0.4158 - acc: 0.7972 - val_loss: 0.5380 - val_acc: 0.7593\n",
      "Epoch 702/900\n",
      "429/429 [==============================] - 0s 89us/step - loss: 0.4158 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7593\n",
      "Epoch 703/900\n",
      "429/429 [==============================] - 0s 90us/step - loss: 0.4157 - acc: 0.7995 - val_loss: 0.5379 - val_acc: 0.7593\n",
      "Epoch 704/900\n",
      "429/429 [==============================] - 0s 99us/step - loss: 0.4157 - acc: 0.7995 - val_loss: 0.5379 - val_acc: 0.7593\n",
      "Epoch 705/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4157 - acc: 0.7995 - val_loss: 0.5379 - val_acc: 0.7593\n",
      "Epoch 706/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4157 - acc: 0.7995 - val_loss: 0.5379 - val_acc: 0.7593\n",
      "Epoch 707/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4156 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7593\n",
      "Epoch 708/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4156 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7593\n",
      "Epoch 709/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4156 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7593\n",
      "Epoch 710/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4155 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7593\n",
      "Epoch 711/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4155 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7593\n",
      "Epoch 712/900\n",
      "429/429 [==============================] - 0s 103us/step - loss: 0.4155 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7593\n",
      "Epoch 713/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4154 - acc: 0.7995 - val_loss: 0.5379 - val_acc: 0.7593\n",
      "Epoch 714/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4154 - acc: 0.7995 - val_loss: 0.5379 - val_acc: 0.7593\n",
      "Epoch 715/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4154 - acc: 0.7995 - val_loss: 0.5379 - val_acc: 0.7593\n",
      "Epoch 716/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4153 - acc: 0.7995 - val_loss: 0.5379 - val_acc: 0.7593\n",
      "Epoch 717/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4153 - acc: 0.7995 - val_loss: 0.5379 - val_acc: 0.7593\n",
      "Epoch 718/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4153 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7593\n",
      "Epoch 719/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4153 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7593\n",
      "Epoch 720/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4152 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7593\n",
      "Epoch 721/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 75us/step - loss: 0.4152 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7593\n",
      "Epoch 722/900\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.4152 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7593\n",
      "Epoch 723/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4151 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7593\n",
      "Epoch 724/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4152 - acc: 0.7995 - val_loss: 0.5382 - val_acc: 0.7593\n",
      "Epoch 725/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4151 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7593\n",
      "Epoch 726/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4150 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7593\n",
      "Epoch 727/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4150 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7593\n",
      "Epoch 728/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4150 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7593\n",
      "Epoch 729/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4149 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 730/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4149 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 731/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4148 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7593\n",
      "Epoch 732/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4148 - acc: 0.7995 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 733/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4148 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 734/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4148 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7593\n",
      "Epoch 735/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4147 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7593\n",
      "Epoch 736/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4147 - acc: 0.7995 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 737/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4147 - acc: 0.7995 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 738/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4146 - acc: 0.7995 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 739/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4146 - acc: 0.7995 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 740/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4146 - acc: 0.7995 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 741/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4145 - acc: 0.7995 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 742/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4145 - acc: 0.7995 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 743/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4145 - acc: 0.7972 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 744/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4144 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 745/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4144 - acc: 0.7995 - val_loss: 0.5378 - val_acc: 0.7685\n",
      "Epoch 746/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4144 - acc: 0.7972 - val_loss: 0.5378 - val_acc: 0.7685\n",
      "Epoch 747/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4143 - acc: 0.7972 - val_loss: 0.5378 - val_acc: 0.7685\n",
      "Epoch 748/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4143 - acc: 0.7972 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 749/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4143 - acc: 0.7972 - val_loss: 0.5378 - val_acc: 0.7685\n",
      "Epoch 750/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4142 - acc: 0.7995 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 751/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4141 - acc: 0.7972 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 752/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4142 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 753/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4141 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 754/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4141 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 755/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4140 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 756/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4140 - acc: 0.7972 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 757/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4139 - acc: 0.7995 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 758/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4139 - acc: 0.7972 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 759/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4139 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 760/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4138 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 761/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4138 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 762/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4138 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 763/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4137 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 764/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4137 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 765/900\n",
      "429/429 [==============================] - 0s 93us/step - loss: 0.4137 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 766/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4136 - acc: 0.8019 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 767/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4136 - acc: 0.8019 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 768/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4135 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 769/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4135 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 770/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4135 - acc: 0.8019 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 771/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4134 - acc: 0.8019 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 772/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4134 - acc: 0.8019 - val_loss: 0.5378 - val_acc: 0.7685\n",
      "Epoch 773/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4133 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 774/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4133 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 775/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4133 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 776/900\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.4133 - acc: 0.8019 - val_loss: 0.5378 - val_acc: 0.7685\n",
      "Epoch 777/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4132 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 778/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4131 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 779/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4131 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 780/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4130 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 781/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4130 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 782/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4130 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 783/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4129 - acc: 0.8019 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 784/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4129 - acc: 0.8019 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 785/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4128 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 786/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4128 - acc: 0.8019 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 787/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4127 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 788/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4128 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 789/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4127 - acc: 0.8019 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 790/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4126 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 791/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4126 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 792/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4126 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 793/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4125 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 794/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4125 - acc: 0.8019 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 795/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4124 - acc: 0.8019 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 796/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4124 - acc: 0.8019 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 797/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4124 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 798/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4123 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 799/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4123 - acc: 0.8019 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 800/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4123 - acc: 0.8019 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 801/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4122 - acc: 0.8019 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 802/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4122 - acc: 0.8019 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 803/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4122 - acc: 0.8019 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 804/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4121 - acc: 0.8019 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 805/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4121 - acc: 0.8019 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 806/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4121 - acc: 0.8019 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 807/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4120 - acc: 0.7995 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 808/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4120 - acc: 0.7995 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 809/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4120 - acc: 0.8019 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 810/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4119 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 811/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4119 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 812/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4119 - acc: 0.8019 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 813/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4118 - acc: 0.7995 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 814/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4118 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 815/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4117 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 816/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4117 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 817/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4117 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 818/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4117 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 819/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4116 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 820/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4116 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 821/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4116 - acc: 0.7995 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 822/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4115 - acc: 0.7995 - val_loss: 0.5378 - val_acc: 0.7685\n",
      "Epoch 823/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4115 - acc: 0.7995 - val_loss: 0.5379 - val_acc: 0.7685\n",
      "Epoch 824/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4114 - acc: 0.7995 - val_loss: 0.5380 - val_acc: 0.7685\n",
      "Epoch 825/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4114 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 826/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4114 - acc: 0.7995 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 827/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4114 - acc: 0.7995 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 828/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4113 - acc: 0.7995 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 829/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4113 - acc: 0.7995 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 830/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4113 - acc: 0.7995 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 831/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4112 - acc: 0.7995 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 832/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4112 - acc: 0.8019 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 833/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4112 - acc: 0.7995 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 834/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4111 - acc: 0.7995 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 835/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4111 - acc: 0.7995 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 836/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4111 - acc: 0.7995 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 837/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4111 - acc: 0.7995 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 838/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4111 - acc: 0.8019 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 839/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4110 - acc: 0.7995 - val_loss: 0.5386 - val_acc: 0.7685\n",
      "Epoch 840/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4110 - acc: 0.7995 - val_loss: 0.5386 - val_acc: 0.7685\n",
      "Epoch 841/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 75us/step - loss: 0.4110 - acc: 0.7995 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 842/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4109 - acc: 0.8042 - val_loss: 0.5386 - val_acc: 0.7685\n",
      "Epoch 843/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4110 - acc: 0.7995 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 844/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4109 - acc: 0.8042 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 845/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4108 - acc: 0.8042 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 846/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4108 - acc: 0.8042 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 847/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4108 - acc: 0.8042 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 848/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4108 - acc: 0.8042 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 849/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4107 - acc: 0.8042 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 850/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4107 - acc: 0.8042 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 851/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4107 - acc: 0.8042 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 852/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4107 - acc: 0.8042 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 853/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4106 - acc: 0.8042 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 854/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4106 - acc: 0.8042 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 855/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4106 - acc: 0.8042 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 856/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4105 - acc: 0.8042 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 857/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4105 - acc: 0.8042 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 858/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4105 - acc: 0.8042 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 859/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4105 - acc: 0.8042 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 860/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4105 - acc: 0.8042 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 861/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4104 - acc: 0.8042 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 862/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4104 - acc: 0.8042 - val_loss: 0.5382 - val_acc: 0.7685\n",
      "Epoch 863/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4104 - acc: 0.8042 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 864/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4103 - acc: 0.8042 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 865/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4103 - acc: 0.8042 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 866/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4103 - acc: 0.8042 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 867/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4103 - acc: 0.8019 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 868/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4103 - acc: 0.8042 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 869/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4102 - acc: 0.8019 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 870/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4102 - acc: 0.8019 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 871/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4102 - acc: 0.8019 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 872/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4102 - acc: 0.8019 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 873/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4101 - acc: 0.8019 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 874/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4101 - acc: 0.8019 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 875/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4101 - acc: 0.8019 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 876/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4101 - acc: 0.8019 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 877/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4100 - acc: 0.8019 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 878/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4100 - acc: 0.8042 - val_loss: 0.5386 - val_acc: 0.7685\n",
      "Epoch 879/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4100 - acc: 0.8019 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 880/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4099 - acc: 0.8019 - val_loss: 0.5386 - val_acc: 0.7685\n",
      "Epoch 881/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4099 - acc: 0.8019 - val_loss: 0.5386 - val_acc: 0.7685\n",
      "Epoch 882/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4099 - acc: 0.8042 - val_loss: 0.5386 - val_acc: 0.7685\n",
      "Epoch 883/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4099 - acc: 0.8042 - val_loss: 0.5386 - val_acc: 0.7685\n",
      "Epoch 884/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4098 - acc: 0.8042 - val_loss: 0.5386 - val_acc: 0.7685\n",
      "Epoch 885/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4098 - acc: 0.8042 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 886/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4098 - acc: 0.8042 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 887/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4098 - acc: 0.8042 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 888/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4097 - acc: 0.8042 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 889/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4097 - acc: 0.8042 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 890/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4096 - acc: 0.8042 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 891/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4097 - acc: 0.8042 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 892/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4096 - acc: 0.8042 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 893/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4096 - acc: 0.8042 - val_loss: 0.5385 - val_acc: 0.7685\n",
      "Epoch 894/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4096 - acc: 0.8042 - val_loss: 0.5386 - val_acc: 0.7685\n",
      "Epoch 895/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4096 - acc: 0.8042 - val_loss: 0.5386 - val_acc: 0.7685\n",
      "Epoch 896/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4095 - acc: 0.8042 - val_loss: 0.5384 - val_acc: 0.7685\n",
      "Epoch 897/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4096 - acc: 0.8042 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 898/900\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.4095 - acc: 0.8042 - val_loss: 0.5383 - val_acc: 0.7685\n",
      "Epoch 899/900\n",
      "429/429 [==============================] - 0s 75us/step - loss: 0.4095 - acc: 0.8042 - val_loss: 0.5381 - val_acc: 0.7685\n",
      "Epoch 900/900\n",
      "429/429 [==============================] - 0s 84us/step - loss: 0.4094 - acc: 0.8042 - val_loss: 0.5381 - val_acc: 0.7685\n"
     ]
    }
   ],
   "source": [
    "#fitting and compiling the model with SGD optimizer\n",
    "nn_model_2.compile(SGD(lr = 0.005), 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_2 = nn_model_2.fit(x_train_nn3, y_train_nn3, validation_data = (x_val_3, y_val_3), epochs = 900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_2_predict_fs = nn_model_2.predict_classes(X_test_3)\n",
    "nn_2_proba_predict_fs = nn_model_2.predict(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Neural nets after feature selection is 0.745\n",
      "The roc-auc for the Neural nets after feature selection is 0.824\n"
     ]
    }
   ],
   "source": [
    "accuracy_nn_2 = accuracy_score(y_test_3,nn_2_predict_fs)\n",
    "\n",
    "print('The accuracy for the Neural nets after feature selection is {:.3f}'.format(accuracy_nn_2))\n",
    "print('The roc-auc for the Neural nets after feature selection is {:.3f}'.format(roc_auc_score(y_test_3,nn_2_proba_predict_fs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x478651d6a0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD3CAYAAADmBxSSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x47864c6710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the training and validation losses over the different epochs\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(history_2.history['loss'], 'r', marker = '.', label = 'Train_loss_2')\n",
    "\n",
    "ax.plot(history_2.history['val_loss'], 'g', marker = '.', label = 'Validation_loss_2')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    Validation loss stable from 320 epoches\n",
    "    training loss also stable \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models_Accuracies with feature_sel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear_svc</th>\n",
       "      <td>77.830189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_reg</th>\n",
       "      <td>77.830189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_rbf</th>\n",
       "      <td>76.897275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_forest</th>\n",
       "      <td>76.530398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural_nets</th>\n",
       "      <td>74.458874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Models_Accuracies with feature_sel\n",
       "linear_svc                              77.830189\n",
       "log_reg                                 77.830189\n",
       "svc_rbf                                 76.897275\n",
       "Random_forest                           76.530398\n",
       "Neural_nets                             74.458874"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracies_fs = pd.DataFrame(feature_sel_cross_val )\n",
    "Accuracies_fs.rename(columns = {\"cross_val with feature selection\" : \"Models_Accuracies with feature_sel\"}, inplace = True)\n",
    "Accuracies_fs.loc['Neural_nets'] = accuracy_nn_2*100\n",
    "Accuracies_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAHtCAYAAAAwQfbGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nETMg91M/RwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4783c55940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_probs_fs.append(nn_2_proba_predict_fs)\n",
    "all_models_names = ['log_reg', 'linear_svc', 'svc_rbf', 'Random_forest', 'Neural_nets']\n",
    "plot_multiple_roc(validation_probs_fs, y_test, all_models_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    support vector machine with rbf has the best accuracy. \n",
    "    \n",
    "    linear_support vector machine and logistic regression are tieed at 77.8% accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Models with their corresponding Roc_AUC_score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Roc_auc_scores with feat selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svc_rbf</th>\n",
       "      <td>83.761317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_forest</th>\n",
       "      <td>83.625514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_reg</th>\n",
       "      <td>83.432099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_svc</th>\n",
       "      <td>83.415638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural_nets</th>\n",
       "      <td>82.189300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Roc_auc_scores with feat selection\n",
       "svc_rbf                                 83.761317\n",
       "Random_forest                           83.625514\n",
       "log_reg                                 83.432099\n",
       "linear_svc                              83.415638\n",
       "Neural_nets                             82.189300"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_fs = RandomForestClassifier(n_estimators=200).fit(X_train_3, y_train_3)\n",
    "rf_proba_predict_fs = rf_model_fs.predict_proba(X_test_3)[:,1]\n",
    "rf_auc_fs = roc_auc_score(y_test_3, rf_proba_predict_fs)\n",
    "\n",
    "rbf_svc_fs = SVC(kernel ='rbf').fit(X_train_3, y_train_3)\n",
    "rbf_proba_predict_fs = rbf_svc_fs.decision_function(X_test_3)\n",
    "rbf_auc_fs = roc_auc_score(y_test_3, rbf_proba_predict_fs)\n",
    "\n",
    "lin_svc_fs = LinearSVC().fit(X_train_3, y_train_3)\n",
    "lsvc_proba_predict_fs = lin_svc_fs.decision_function(X_test_3)\n",
    "lsvc_auc_fs = roc_auc_score(y_test_3, lsvc_proba_predict_fs)\n",
    "\n",
    "log_reg_fs = LogisticRegression().fit (X_train_3, y_train_3)\n",
    "log_reg_proba_predict_fs = log_reg_fs.predict_proba(X_test_3)[:,1]\n",
    "log_reg_auc_fs = roc_auc_score(y_test_3, log_reg_proba_predict_fs)\n",
    "\n",
    "nn_auc_fs = roc_auc_score(y_test_3, nn_2_proba_predict_fs)\n",
    "\n",
    "AUCROC_scores_fs = [log_reg_auc_fs*100, lsvc_auc_fs*100, rbf_auc_fs*100, rf_auc_fs*100, nn_auc_fs*100]\n",
    "labels = ['log_reg', 'linear_svc', 'svc_rbf', 'Random_forest', 'Neural_nets']\n",
    "\n",
    "\n",
    "RocAuc_score_fs = pd.Series(AUCROC_scores_fs, index = labels).sort_values(ascending=False).to_frame()\n",
    "RocAuc_score_fs.rename(columns = {0: 'Roc_auc_scores with feat selection'}, inplace = True)\n",
    "print('\\nModels with their corresponding Roc_AUC_score')\n",
    "RocAuc_score_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a submission file\n",
    "\n",
    "# Pima_diabetes_submission = pd.DataFrame( {'Outcome': rbf_2_predict})\n",
    "# Pima_diabetes_submission.to_csv('Pima_Diabetes_Prediction.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
